---
title: '<center> The Exercises of Week 2 - Exploratory Data Analysis <center>'
author: '<center> Reza Mohammadi <center>'
date: '<center> `r Sys.Date()` <center>'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 5
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include = FALSE}
knitr::opts_chunk $ set( echo = TRUE, message = FALSE, warning = FALSE, 
                         comment = " ", error = FALSE, fig.align = 'center' )
```

```{css, echo=FALSE}
.answer_panel { margin-left: 40px; }

.sub_details { margin-left: 60px; }
```

**Full Name:** 
* Peter Molnar (11759216)
* Louren√ßo Santos Moitinho de Almeida (12636622)


**Online Assignments**: 
There is a new online-assignments at the [DataCamp](https://www.datacamp.com). This online exercise, related to data visualization in **R**, e.g., by using the [*ggplot2*](https://CRAN.R-project.org/package=ggplot2) package. These exercises are useful to prepare yourself for the computer-lab. *The online-assignments at the DataCamp are not mandatory*.

**Your task** is to answer the questions in this R-markdown file. Submit both your R-markdown (.Rmd) file and the HTML file on Canvas. 

**Note:** The exercise of this week has 100 points. Besides, the Bonus part has 30 extra points.  

# Exploratory Data Analysis for customer churn prediction (30 points)

Customer Churn is a topic that matters to organizations of all sizes. 
Customer churn occurs when customers stop doing business with a company, also known as customer attrition. Churn (loss of customers to competition) is a major problem for telecom companies because it is well known that it is more expensive to acquire a new customer than to keep an existing customer. Here, we use Exploratory Data Analysis to explore the *churn* dataset. Basically, we want to visualize and identify which factors contribute to customer churn.

**Dataset**: The *churn* data set is available in the **R** package [*liver*](https://CRAN.R-project.org/package=liver). The data set contains '5000' rows (customers) and 20 columns (features). The last column called *churn*  is the target variable which indicates whether customers churned (left the company) or not. If you want to know more about the dataset just type `?churn` in your **R** console. You also can find more information about this dataset [here](https://rdrr.io/cran/liver/man/churn.html).

Here we need to load the following **R** packages:

* [**ggplot2**](https://CRAN.R-project.org/package=ggplot2): we use this package to visualize our data in **R**.
* [**liver**](https://CRAN.R-project.org/package=liver): the *churn* dataset is in this package. 
* **GGally**: We use the `ggcorr()` function from this package.
* **psych**: We use the `pairs.panels()` function from this package.

**NOTE:** If you have not installed those two packages, you should first install them.

To load the packages:
```{r}
library( ggplot2 )  
library( liver   )  
library( GGally  )  
library( psych   )  
library( skimr   )  
library( Hmisc   )
library( plyr    )
library( ggpubr  )
```

## Business Understanding

Companies are interested to know who is gonna get churned so they can proactively go to the customer to provide them better services and turn customers' decisions in the opposite direction. Companies are interested to know:

* **What** customers are we losing?
* **Why** are we losing them?
* **How** do we stop them from leaving the company?

To answer these questions here, as a practical example, we use the *churn* data set is available in the **R** package [*liver*](https://CRAN.R-project.org/package=liver).

## Data Understanding 

This dataset comes from IBM Sample Data Sets. The data set contains 5000 rows (customers) and 20 columns (features). The "churn" column is our target which indicates whether the customer churned (left the company) or not.
The 20 variables are:

* `state`: Categorical, for the 51 states and the District of Columbia.
* `area.code`: Categorical.
* `account.length`: count, how long account has been active.
* `voice.plan`: Categorical, yes or no, voice mail plan.
* `voice.messages`: Count, number of voice mail messages.
* `intl.plan`: Categorical, yes or no, international plan.
* `intl.mins`: Continuous, minutes customer used service to make international calls.
* `intl.calls`: Count, total number of international calls.
* `intl.charge`: Continuous, total international charge.
* `day.mins`: Continuous, minutes customer used service during the day.
* `day.calls`: Count, total number of calls during the day.
* `day.charge`: Continuous, total charge during the day.
* `eve.mins`: Continuous, minutes customer used service during the evening.
* `eve.calls`: Count, total number of calls during the evening.
* `eve.charge`: Continuous, total charge during the evening.
* `night.mins`: Continuous, minutes customer used service during the night.
* `night.calls`: Count, total number of calls during the night.
* `night.charge`: Continuous, total charge during the night.
* `customer.calls`: Count, number of calls to customer service.
* `churn`: Categorical, yes or no. Indicator of whether the customer has left the company (yes or no).

We import the dataset in **R** as follows:
```{r}
data( churn ) # load the "churn" dataset
``` 

To see the overview of the dataset in **R** we could use the following functions: 

* `str`  to see a compact display of the structure of the data. 
* `View` to see spreadsheet-style data. 
* `head` to see the first part of the data (first 6 rows of the data).
* `summary` to see the summary of each variable.

To see the overview of the dataset in **R** we are using function `str` as follows:
```{r}
str( churn )   # Compactly display the structure of the data
```

It shows that data are as a *data.frame* object in **R** with `r nrow(churn)` observations and `r ncol(churn)` variables. The last column (with name *churn*) is the *target variable* that indicates whether customers churned (left the company) or not.

By using the function `summary` in **R**, we can see the summary of the dataset as follows

```{r}
summary( churn )
```
It shows the summary of all the `r ncol(churn)` variables. 

**a. For each variable in the churn dataset, specify its type.**

<details class="answer_panel">
  <summary>Answer a</summary>

|     Variable     |  R Datatype  |  Statistical Datatype   |
|        :-        |      :-:     |          :-             |
| `state`          | `Factor`     | categorical - nominal   |
| `area.code`      | `Factor`     | categorical - nominal   |
| `account.length` | `int`        | numerical - discrete    |
| `voice.plan`     | `Factor`     | categorical - binary    |
| `voice.messages` | `int`        | numerical - discrete    |
| `intl.plan`      | `Factor`     | categorical - binary    |
| `intl.mins`      | `num`        | numerical - continuous  |
| `intl.calls`     | `int`        | numerical - discrete    |
| `intl.charge`    | `num`        | numerical - continuous  |
| `day.mins`       | `num`        | numerical - continuous  |
| `day.calls`      | `int`        | numerical - discrete    |
| `day.charge`     | `num`        | numerical - continuous  |
| `eve.mins`       | `num`        | numerical - continuous  |
| `eve.calls`      | `int`        | numerical - discrete    |
| `eve.charge`     | `num`        | numerical - continuous  |
| `night.mins`     | `num`        | numerical - continuous  |
| `night.calls`    | `int`        | numerical - discrete    |
| `night.charge`   | `num`        | numerical - continuous  |
| `customer.calls` | `int`        | numerical - discrete    |
| `churn`          | `Factor`     | categorical - binary    |

</details>

**b. Based on the output of the `summary` function for the churn dataset, what is the number of customers who have an international plan (`intl.plan = "yes"`)?**

<details>
  <summary>Answer b</summary>
  
```{r}
intl_plan_holder = length(which(churn $ intl.plan == "yes"))
intl_plan_holder
```
  
  The customer churn rate is `r intl_plan_holder`.

</details>

## Investigate the target variable *churn* 

Here we report a bar plot for the target variable `churn` by using function `ggplot()` from the **R** package **ggplot2** as follows:

```{r fig.align = 'center', fig.height=5, fig.width=5}
ggplot( data = churn ) + 
    geom_bar( aes( x = churn ), fill = c( "red", "blue" ) ) +
    labs( title = "Bar plot for the target variable 'churn'" )  
```

Summary for the target variable `churn`
```{r}
summary( churn $ churn )
```

**Based on the above output, what is the proportion of the churner (customer churn rate)?**

<details>
  <summary>Answer</summary>
  
  $P(churn = no) = 4293$
  
  $P(churn = yes) = 707$
  
  $n = P(churn = no) + P(churn = yes) = 4293 + 707 = 5000$
  
  $P(churn = yes) = \frac{P(churn = yes)}{n} = \frac{707}{5000} = 0.1414 = 14.14\%$
  
  The proportion of churners is $14.14\%$.
</details>

## Investigate variable *International Plan*

Here we first report a contingency table of International Plan (`intl.plan`) with `churn`
```{r}
table( churn $ churn, churn $ intl.plan, dnn = c( "Churn", "International Plan" ) )
```

Here is the above contingency table with margins
```{r}
addmargins( table( churn $ churn, churn $ intl.plan, dnn = c( "Churn", "International Plan" ) ) )
```

Bar chart for International Plan

```{r fig.align = 'default', fig.show = "hold", out.width = "50%"}
ggplot( data = churn ) + 
  geom_bar( aes( x = intl.plan, fill = churn ) ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 

ggplot( data = churn ) + 
  geom_bar( aes( x = intl.plan, fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

**What would be your interpretation of the above plots?**

<details>
  <summary>Answer</summary>
  
The first plot depicts a bar chart of `intl.plan`, with `churn` overlay. The chart shows that approximately 500 customers have an international plan, while the rest do not. The proportions of churners is not clearly readable, but approximately half of the customers who have an international plan tend to churn. The churn rate is much smaller for customers who do not have international plan.

The right chart is the standardised version of the bar chart on the left. The standardised chart's y-axis ranges between 0 and 1, and it shows the proportions of churners in each `intl.plan` category. This chart allows for more precision; we read that approximately 42% of international plan holders change to a different company, while this number is around 11% for those not having an international plan. 

Conclusively, international plan holders churn rate is about four times higher than for non subscribers. The variable in question may bear with explanatory power, hence it would not come as a surprise if the data mining algorithm would use `intl.plan` in the prediction model.

</details>

## Investigate variable "*voice mail plan*"

Make a table for counts of Churn and Voice Mail Plan

```{r}
addmargins(table( churn $ churn, churn $ voice.plan, dnn = c( "Churn", "Voice Mail Plan" ) ))
```

Bar chart for Voice Mail Plan

```{r fig.align = 'default', fig.show="hold", out.width="50%"}
ggplot( data = churn ) + 
  geom_bar( aes( x = voice.plan, fill = churn ) ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 

ggplot( data = churn ) + 
  geom_bar( aes( x = voice.plan, fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

**What would be your interpretation of the above plots?**

<details>
  <summary>Answer</summary>

The left plot depicts a bar chart for `voice.plan`, with `churn` overlay, grouped by `voice.plan` categories. Those of voice plan holders represent themselves with 1300 customers, while those of non-holders about 3700 customers.

The right plot is a standardised bar chart, and shows that approximately 8% of voice mail plan holders churn. For those who did not opt for voice mail plan, the churn rate is approximately twice as much, 16%.

Conclusively, churn rate is higher among customers who do not have voice mail plan, than for those who do have. `voice.plan` may have some explanation for the 14.14% churn rate, and hence we expect that the data mining algorithm will include it in prediction model.
  
</details>

## Investigate variable "*customer service calls*" 

Here, we are interested to investigate the relationship between variable "*customer service calls*" and the target variable "*churn*". First, we report the histogram of the variable "*customer service calls*" by using function `ggplot` as follows

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = factor( customer.calls ) ) ) 
```

To see the relationship between variable "*customer service calls*" and the target variable "*churn*", we report the histogram of the variable "*customer service calls*" including "churn" overlay as follows

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = factor( customer.calls ), fill = churn ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

We also report the *Normalized* histogram of variable "*customer service calls*" including "churn" overlay as follow

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = factor( customer.calls ), fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

**What would be your interpretation of the above plots?**

<details>
  <summary>Answer</summary>

The first plot is a regular bar chart of `customer.calls`, and it shows positively a skewed distribtuion, whit a mean of `r mean(churn $ customer.calls)` number of calls. The skewness of the data may be explained by that the majority of customers who contacts the customer service desk had their issue resolved within one call, and hence there was no need for further calls.

The second plot is similar to the first chart, however, it adds `churn` overlay. The overlay expresses the count of the specific `customer.calls` bar, how many have versus have not churned. Since it is challenging to read the proportions of the histogram we turn to the standardised chart, which is the last plot of this section.

The standardised chart depicts the proportions of churners vs non-churners for each customer call counts. We observe that that churn rate is nearly constant at around 11% for customers who had 3 or less customer service calls. The churn rate, however, at least quadruples for those contacting the customer service desk at least 4 times. It seems, that customers tolerance or satisfaction drops significantly as soon as they need to call at least 4 times the customer service.

It is worth to note, that the standardised and non-standardised plots must be used together, otherwise it may lead to misleading observations. Such as, had we not taken into account the non-stardardised bar chart, then we would have concluded that customers calling the service desk 9 times churn with certainty. However, for this observation, the data is not representative, because of the low sample size - i.e, there are only a few customers with 9 customer services calls.

Given the strong graphical evidence of predictive importance of `customer.calls`, it is expected that the data mining algorithm will include `customer.calls` in the model.

</details>

## Investigate variable "*Day Minutes*"

Here, we are interested to investigate the relationship between variable Day Minutes and the target variable *Churn*. First, we report the ‚ÄúNormalized‚Äù histogram of Day Minutes including Churn overlay:

```{r}
ggplot( data = churn ) +
  geom_histogram( aes( x = day.mins, fill = churn ), position = "fill", binwidth = 25, color="white" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

Another way to see the relationship between variable Day Minutes and the target variable *churn*, would be by using the boxplot as follows

```{r}
ggplot( data = churn ) +
  geom_boxplot( aes( x = churn, y = day.mins ), fill = c( "red", "blue" ) ) 
```

**What would be your interpretation of the above boxplot?**

<details>
  <summary>Answer</summary>

The above boxplots depict the locality, spread and skewness of `day.mins` grouped by `churn` categories.

**Comparison of location:** For both `churn` categories, that is for churners and non-churners, the distribution is approximately symmetric. This finding bears with the advantage, that we can state that the distributions' mean and median are approximately at the same location. Knowing this, allows us to draw that the daily length of calls for churners is approximately on average 215 minutes. The length of the calls for those of non-churners is on average around 190 minutes a day.

To allow for a more precise analysis, we need to plot the data as frequency density plot; the below code performs that.

```{r}
ggplot( data = churn) + 
  geom_density( aes( x = day.mins, fill = churn ), alpha = 0.3)
```


We observe, that churners show bimodality; at 160 minutes, and 270 minutes. That is, customers with daily phone calls of 160, and 270 minutes churn with the highest rate. Furthermore, we can read that customer churn rate increases as `day.mins` exceeds 200 minutes.

**Comparison of dispersion:** From the boxplots we read that the interquartile range for churners is approximately twice as large than for non-churners. Additionally, we read from the width of the whiskers, that the range of `day.mins` for churners is wider than for non-churners.

**Comparison of skewness:** `day.mins` for churners is skewed to the left - churners spend more time on average on phone calls, than non-churners.

**Comparison of potential outliers:** `day.mins`'s whisker spreads from the minima of the data to the maxima, and hence it does not have any outliers, or unusual values. This cannot be stated for non-churners, since its boxplot reports potential outliers beyond the lower and upper whiskers.

`day.minutes` seem to hold relevant information, and therefore we should expect the data mining algorithm to select this variable into the model.

</details>


## Investigate variable "*International Calls*" 

Here, we are interested to investigate the relationship between variable International Calls and the target variable `churn`. First, we report the histogram of the variable International Calls as follows:

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = intl.calls ) ) 
```

To see the relationship between variable International Calls and the target variable *churn*, we report the histogram of variable International Calls including Churn overlay as follow

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = intl.calls, fill = churn ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

We also report the *Normalized* histogram of variable International Calls including Churn overlay as follow

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = intl.calls, fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

To see the relationship between variable International Calls and the target variable *churn*, we report the boxplot as follow

```{r}
ggplot( data = churn ) +
  geom_boxplot( aes( x = churn, y = intl.calls ), fill = c( "red", "blue" ) ) 
```

**What would be your interpretation of the above boxplot?**

<details>
  <summary>Answer</summary>
  
The above boxplots depict the locality, spread and skewness of `intl.calls` grouped by `churn` categories.
  
**Comparison of location:** Based on the boxplots, we see that the median count of internatinal calls made by churners and non-churners are approximately the same.

**Comparison of dispersion:** The interquartile range for churners versus non-churners are reasonably similar, as well as the overall range of the data, seen by measuring the whisker lengths.

**Comparison of skewness:** Both batch of data are positively skewed, however, for churners it is more than for non-churners. Meaning, that churners have a lower count of international calls than that of non-churners.

**Comparison of potential outliers:** Both data contains outliers beyond the upper whisker, however, nothing deterministic may be drawn from this observation.

As a general conclusion, the above plots do not indicate strong graphical evidence of the predictive importance of international calls. Therefore, it may be that the data mining algorithm would not include it in the model.

</details>

## Detect Correlated Variables 

To visualize the correlation matrix between the "day.mins", "Day.Calls", "Day.Charge", "Eve.Mins", "Eve.Calls", "Eve.Charge", "Night.Mins", "Night.Calls", and "Night.Charge", we could use the `ggcorr` function as follows

```{r message = FALSE, warning = FALSE, fig.align='center' }
variable_list = c( "intl.mins",  "intl.calls",  "intl.charge", 
                   "day.mins",   "day.calls",   "day.charge",
                   "eve.mins",   "eve.calls",   "eve.charge",
                   "night.mins", "night.calls", "night.charge" )

ggcorr( data = churn[ , variable_list ], label = TRUE ) 
```

```{r fig.align = 'default', fig.show="hold", out.width="50%"}
pairs.panels( churn[ , c( "intl.mins", "intl.calls", "intl.charge" ) ] ) 

pairs.panels( churn[ , c( "day.mins", "day.calls", "day.charge" ) ] ) 

pairs.panels( churn[ , c( "eve.mins", "eve.calls", "eve.charge" ) ] ) 

pairs.panels( churn[ , c( "night.mins", "night.calls", "night.charge" ) ] ) 
```

**What would be your interpretation of the above correlation matrix plots?**

<details>
  <summary>Answer</summary>
  
From the above correlation matrix we see that there are 4 problematic variables that shows perfect correlation (r=1.0) with another variable.

Namely, `night.charge` is perfectly linearly correlated with `night.mins`, which does not come as surprise, since the former is a function of `night.mins`. The same holds true for `eve.mins` and `eve.charge`, `day.mins` and `day.charge`, and lastly `intl.mins` and `intl.charge`.

<<<<<<< HEAD
Using correlated variables will overemphasize one data component, or at worst the data may become unstable and deliver unreliable results. Therefore we need to retain only one of the correlated variables. Furthermore, including highly correlated variables would result in multicollinearity which would result in unreliable regression model coefficients. 
=======
Using correlated variables will overemphasize one data component, or at worst the data may become unstable and deliver unreliable results. Therefore we need to retain only one of the correlated variables.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf

</details>

# Exploratory Data Analysis for Bank direct marketing dataset  (70 points)

In this part, we want to use Exploratory Data Analysis to explore the *bank* dataset that is available in the **R** package [**liver**](https://CRAN.R-project.org/package=liver). You could find more information about the *bank* dataset at the following link on pages 4-5: [manual of the liver package](https://cran.r-project.org/web/packages/liver/liver.pdf); Or  [here](https://rdrr.io/cran/liver/man/bank.html).

## Business Understanding

Find the best strategies to improve for the next marketing campaign. How can the financial institution have greater effectiveness for future marketing campaigns? To make a data-driven decision, we need to analyze the last marketing campaign the bank performed and identify the patterns that will help us find conclusions to develop future strategies.

### Bank direct marketing info

Two main approaches for enterprises to promote products/services are: 

* *mass campaigns*: targeting general indiscriminate public,
* *directed marketing*, targeting a specific set of contacts. 

In general, positive responses to mass campaigns are typically very low (less than 1%). On the other hand, direct marketing focuses on targets that are keener to that specific product/service, making this kind of campaign more effective. However, direct marketing has some drawbacks, for instance, it may trigger a negative attitude towards banks due to the intrusion of privacy.

Banks are interested to increase financial assets. One strategy is to offer attractive long-term deposit applications with good interest rates, in particular, by using directed marketing campaigns. Also, the same drivers are pressing for a reduction in costs and time. Thus, there is a need for an improvement in efficiency: lesser contacts should be done, but an approximate number of successes (clients subscribing to the deposit) should be kept.

### What is a Term Deposit?

A Term Deposit is a deposit that a bank or a financial institution offers with a fixed rate (often better than just opening a deposit account), in which your money will be returned at a specific maturity time. For more information with regards to Term Deposits please check [here](https://www.investopedia.com/terms/t/termdeposit.asp).

## Data Undestanding

The *bank* dataset is related to direct marketing campaigns of a Portuguese banking institution. You can find more information related to this dataset at: [https://rdrr.io/cran/liver/man/bank.html](https://rdrr.io/cran/liver/man/bank.html)

The marketing campaigns were based on phone calls. Often, more than one contact (to the same client) was required, to access if the product (bank term deposit) would be (or not) subscribed. The classification goal is to predict if the client will subscribe to a term deposit (variable deposit).

We import the *bank* dataset:
```{r}
data( bank )      
```

We can see the structure of the dataset by using the `str` function:
```{r}
str( bank )
```

It shows that the *bank* dataset as a `data.frame` has `r ncol( bank )` variables and `r nrow( bank )` observations. The dataset has `r ncol( bank ) - 1` predictors along with the target variable `deposit` which is a binary variable with 2 levels "yes" and "no". The variables in this dataset are:

* `age`: numeric.
* `job`: type of job; categorical: "admin.", "unknown", "unemployed", "management", "housemaid", "entrepreneur", "student", "blue-collar, "self-employed", "retired", "technician", "services".
* `marital`: marital status; categorical: "married", "divorced", "single"; note: "divorced" means divorced or widowed.
* `education`: categorical: "secondary", "primary", "tertiary", "unknown".
* `default`: has credit in default?; binary: "yes","no".
* `balance`: average yearly balance, in euros; numeric.
* `housing`: has housing loan? binary: "yes", "no".
* `loan`: has personal loan? binary: "yes", "no".

Related with the last contact of the current campaign:

* `contact`: contact: contact communication type; categorical: "unknown","telephone","cellular". 
* `day`: last contact day of the month; numeric.
* `month`: last contact month of year; categorical: "jan", "feb", "mar", ..., "nov", "dec".
* `duration`: last contact duration, in seconds; numeric.

Other attributes:

* `campaign`: number of contacts performed during this campaign and for this client; numeric, includes last contact.
* `pdays`: number of days that passed by after the client was last contacted from a previous campaign; numeric, -1 means client was not previously contacted.
* `previous`: number of contacts performed before this campaign and for this client; numeric.
* `poutcome`: outcome of the previous marketing campaign; categorical: "success", "failure", "unknown", "other".

Target variable:

* `deposit`: Indicator of whether the client subscribed a term deposit; binary: "yes" or "no".

**Following Part 1, first, report the summary of the dataset then apply the Exploratory Data Analysis.**

<details class="answer_panel">
  <summary>Answer</summary>
  
  <details class="sub_details">
    <summary>Summary of the `bank` dataset</summary>

<h3>Summary of the `bank` dataset</h3>
The below code reports a descriptive statistics of the `bank` dataset.    
    
```{r}
summary(bank)
```
  
  </details>
  
  <details class="sub_details">
    <summary>EDA of the target variable, `deposit`</summary>
    
<h3>EDA of the target variable, `deposit`</h3>

The variable `deposit` is the target variable, and an indicator of whether the client subscribed to a term deposit or not.

First, `deposit` is concluded in a table, and then plotted on a bar chart.

```{r}
addmargins( table( bank $ deposit, dnn = c( "Deposit" ) ) )
```

```{r}
ggplot( data = bank ) + 
    geom_bar( aes( x = deposit ), fill = c( "red", "blue" ) ) +
    labs( title = "Bar plot for the target variable 'deposit'" )  
```

<<<<<<< HEAD
The table and bar chart above reports, that total number of customers that were reached out to was 4521 customers, which is the sum of the height of the bars. Out of the contacted customers, 521 subscribed, and 4000 did not. This comes down to a `r round(521 / 4521 * 100, 2)`% campaign success rate.
=======
The table and bar chart above reports, that total number of customers that were reached out to is 4521 customers, which is the sum of the height of the bars. Out of the contacted customers, 521 subscribed, and 4000 did not. This comes down to a `r round(521 / 4521 * 100, 2)`% campaign success rate.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf


  </details>
  
  <details class="sub_details">
    <summary>EDA of `age`</summary>
    
<h3>EDA of `age`</h3>

`age` is a discrete numerical variable, representing the age of the customer in the dataset. Below `age`is plotted as a bar chart, so that we can observe the age distribution of those the campaign targeted. 

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = factor( age ) ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```
We can report that the target group of the campaign was that of age between 23 and 60. However, we notice that the bank targeted the age range of 30 to 40 the most.

Next, we plot `age` as a regular bar chart, with `deposit` overlay, and as a standardised bar chart with the same overlay.

```{r}
ggplot( data = bank ) + 
  geom_bar( aes( x = age, fill = deposit ) ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 

ggplot( data = bank ) + 
  geom_bar( aes( x = age, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

<<<<<<< HEAD
From the above plot we read that the target group specifically those between age of 23 and 60 produced very similar outcomes. Even the mainly targeted age group of 30 to 40 years of age did not stand out with its high subscription rate. That is, on average the subscription rate is approximately 10%, which is only 1% point apart from the overall subscription rate of the campaign.
=======
From the above plot we read that, that the target group specifically (those between age of 23 and 60) produced very similar outcomes. Even the mainly targeted age group of 30 to 40 years of age did not stand out with it high subscription rate. That is, on average the subscription rate is approximately 10%, which is only 1% point apart from the overall subscription rate of the campaign.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf

Outside the target group, the campaign was more successful. Meaning, that under the age of 23 and beyond 60, the campaign shows at least 37.5% success rate on average. Meaning, if a customer falls in the age range of less than 23 or more than 60, the more likely he/she will subscribe.

Next we plot the data as a boxplot, grouped by `deposit`.

```{r}
ggplot( data = bank ) +
  geom_boxplot( aes( x = deposit, y = age ), fill = c( "red", "blue" ) ) 
```

<<<<<<< HEAD
**Comparison of location:** The central location of the two boxplots are approximately shared at 40 years of age. It shows, that the median age for depositors, as well as non-depositors are approximately the same.

**Comparison of dispersion:** The interquartile range of non-depositors are smaller than that of depositors, and this in general holds for the overall age range as well. That is, the age range for no depositors is narrower than for depositors.

**Comparison of skewness:** Per above, it was stated that for both groups, the data is positively skewed.

**Comparison of potential outliers:** Both categeories report some outliers, however, non-depositors have about twice as many outliers than that of depositors.

Based on the above two graphs, we see significant graphical indication of the importance of `age`'s predictive importance. Therefore, we expect the data mining model to include this variable into the model.
=======
**Comparison of location:** The central location of the two boxplots are approximately shared at 40 years. It shows, that the median age for depositors, as well as non-depositors are approximately the same.

**Comparison of dispersion:** The interquartile range of non-depositors are smaller than that of depositors, and this in general holds for the overall age range as well. That is, the age range for no depositors is narrower than for depositors.

**Comparison of skewness:** Per above, it was stated that for both groups, the data is positively skewed, that is the bulk of the data is towards the

**Comparison of potential outliers:** Both categeories report some outliers, however, non-depositors have about twice as many outliers than that of depositors.

Based on the above two graphs, we see significant graphical indication of the importance of `age`'s predictive importance. Therefore, we expect the data mining model to select this variable into the model.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf

  </details>

  <details class="sub_details">
    <summary>EDA of `job`</summary>

<h3>EDA of `job`</h3>

`job` is a categorical variable and describes the type of job the customers have at the time of the campaign.

We first plot `job` categories as a bar chart with `deposit` overlay, so that we can identify the specific target groups per occupation, and see their corresponding deposit rate. 
```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = factor( job ), fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

<<<<<<< HEAD
From the above bar chart we can distinguish 3 occupations that stand out in terms of frequency from the dataset. These are jobs of total count greater than 750. Namely, blue-collar workers, management personnel, and technicians. The second largest group has more than 375 counts in the dataset and are of administrative workers, and those working in the service sector. The third group is of every other occupation that represent themselves with less than 250 people.

We standardise the barchart above and replotted it below.
=======
From the above bar chart we can distinguish 3 occupations that stand out in terms of frequency from the dataset. These are jobs of total count greater than 750. Namely, blue-collar workers, management personnel, and technicians. The second largest group are more than 375 counts in the dataset and are of administrative workers, and those working in the service sector. The third group is of every other occupation that represent themselves with less than 250 people.

We standardise the barchart above and replot it per below.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = factor( job ), fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

From the standardised plot we read that the campaign was most effective among the following job categories: retired, students, and those with unknown occupation. This finding coincides with the previous variable, `age`, whereby we saw, that the subscription rate was high age below 23 and beyond 60 years of age, which tends to be those who are students and elderly people.

We further note, that the 3 most targeted job groups do not necessarily produce a favourable outcome for the campaign. That is, their subscription rate is low for blue-collar workers at around 5%, 12.5% for management personel and around 11% for those working in services. The latter two job categories do not deviate a significantly from the overall success rate of the campaign.

For the rest of the occupations, we see deposit rate ranging between 6% and 12%. Since we deemed `age` an important predictor, we claim that there is strong graphical indication for `job` being a relevant explanatory variable for target variable `deposit`. Therefore, we expect `job` to be included in the data mining model too. 


  </details>

  <details class="sub_details">
    <summary>EDA of `marital`</summary>

<h3>EDA of `marital`</h3>

<<<<<<< HEAD
The variable `marital` stands for marital status of the customer. The attribute can take either of the following stautses "married‚Äù, ‚Äúdivorced‚Äù, ‚Äúsingle‚Äù, ‚Äúdivorced‚Äù which means divorced or widowed.

We first plot marital status with a `deposit` overlay, and then standardised in a bar chart to observe it there are any noticeable patterns.
=======
The variable `marital` stands for marital status of the customer. The attribut can take either of the following stautses "married‚Äù, ‚Äúdivorced‚Äù, ‚Äúsingle‚Äù, ‚Äúdivorced‚Äù which means divorced or widowed.

We first plot marital status with `deposit` overlay, and then as a standardised bar chart to observe it there is any noticable pattern.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = marital, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 

ggplot( data = bank ) +
  geom_bar( aes( x = marital, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

From the above plots we see that those with married status are over-represented in the dataset with a count of approximately 2800. The dataset contains approximately 1200 singles, while the rest statuses are approximately 500 that are either divorced or widowed.

<<<<<<< HEAD
The standardised plot allows us to read the deposit proportions among marital statuses; we read that the success rate of the campaign across different marital statuses are similar with ranges between 10% and 12%. We further interpret, that married customers are less keen on subscribing than those with either of the other marital statuses.

Since the variable `martial` does not show strong graphical indication of predictive importance, it is likely that the data mining algorithm will not include it in the model.
=======
The standardised plot allows us to read the deposit proportions among marital statuses; we read that the success rate of the campaign across different marital statuses are of similar, and ranges between 10% and 12%. We further interpret, that married customers are less keen on subscribing that those with either of the other marital statuses.

Since the the variable `martial` does not show strong graphical indication of predictive importance, it is likely that the data mining algorithm will not include it in the model.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf


  </details>

  <details class="sub_details">
    <summary>EDA of `education`</summary>
    
<h3>EDA of `education`</h3>

The `education` variable has four categories; "primary", "secondary", "tertiary" and an "unknown".

* Primary education or elementary education is typically the first stage of formal education.
* Secondary education typically takes place after six years of primary education and is followed by higher education, vocational education or employment.
* Tertiary education refers to all formal post-secondary education, including public and private universities, colleges, technical training institutes, and vocational schools.

We explore `education` by means of regular bar chart and standardised barchart with `deposit` overlay.

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = education, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = education, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

The above bar charts show that customers with secondary educations are represented the most in the data set followed by tertiary education, and primary education participants.

Upon analysing the standardised chart, we report that those with tertiary education tend to subscribe with higher likelihood than customers with different educational level. Additionally, we notice that the success rate of the campaign is almost identical for those with primary, secondary and unknown education.

<<<<<<< HEAD
Although, the graphical evidence is not strong it is difficult to conclude whether or not the variable `education` is significant enough to include in the model.
=======
Although, the graphical evidence is not strong, but may  be significant enough to consider `education` as having predictive importance in the model.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf

  </details>

  <details class="sub_details">
    <summary>EDA of `default`</summary>

<h3>EDA of `default`</h3>

<<<<<<< HEAD
The `default` variable is a binary attribute that stands for whether the customer has defaulted on his/her credit or not.

We explore the `default` through bar charts: first as a regular chart with a `deposit` overlay, and then as a standardised bar chart.
=======
The `default` variable is a binary attribute that stands for whether the customer has defaulted on hi/her credit or not.

We explore the `default` through bar charts: first as a regular chart with `deposit` overlay, and then as standardised one.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = default, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = default, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

<<<<<<< HEAD
We read from the regular bar chart that those who did not default on their credit are over-represented in the dataset by 4445 customers, and only 76 have defaulted. It is understandable from the standpoint of the bank that they target those with good credit history since those customers tend to be more reliable and have the necessary financial means to subscribe for the deposit.
=======
We read from the regular bar chart that those who did not default on their credit are over-represented in the dataset by 4445 customers, and only 76 have defaulted. It is understandable from the standpoint of the bank that they target those with good credit history, since those customers tend to be more reliable, and have the relevan financial means to subscribe for the deposit.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf

The standardised chart reveals that there is no difference in the deposit rate between the two groups, therefore, the EDA of `default` is inconclusive. I.e., `default` does not indicate strong graphical evidence of any predictive importance. Therefore it is likely that the data mining algorithm will not include that in the prediction model.

  </details>

  <details class="sub_details">
    <summary>EDA of `balance`</summary>
    
<h3>EDA of `balance`</h3>

The `balance` attribute represents the average balance of the customer's account annually.

```{r}
ggplot( bank ) +
    geom_histogram( mapping = aes( x = balance ))
```

One's balance is closely related to their income. The general consensus over income distribution is that it is positively skewed, we expect balance to be similarly shaped.

<<<<<<< HEAD
From the above histogram we can confirm that balance is indeed positively skewed, with a mean balance of ‚Ç¨1423. The wide range of balances gives away that the dataset contains unusually high balances, i.e., chances are that there are outliers in the dataset. Furthermore, we report that balance may also be negative, representing an overdraft, which occurs when money is withdrawn in excess of what is in a current account.
=======
From the above histogram we can confirm that balance is indeed positively skewed, with mean balance of ‚Ç¨1423. The wide range of balances gives away that the dataset contains unusually high balances, i.e., chances are that there are outliers in the dataset. Furthermore, we report that balance may also be negative, representing an overdraft, which occurs when money is withdrawn in excess of what is in a current account.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf

Balances around 0 dominate the data, but to see that rest of the distribution in more details we zoom into it by adjusting the limit of the y-axis to [0, 1000].

```{r}
ggplot( bank ) + 
  geom_histogram( mapping = aes( x = balance )) +
  coord_cartesian( ylim = c( 0, 1000 ) )
```

Unfortunately the zoomed in part does not provide necessarily more information but confirms the existence of outliers between the range of ‚Ç¨40000 and ‚Ç¨70000. To see the potential outliers, we plot `balance` as a boxplot.

```{r}
ggplot( data = bank ) +
  geom_boxplot( aes( x = balance))
```

We identify the outliers represented by the dots in the above plot. To draw any meaningful interpretation, we need to handle outliers by means of imputation, and then replot the graph.

```{r}
q1 = boxplot(bank $ balance)$stats[2, ]
q3 = boxplot(bank $ balance)$stats[4, ]
iqr = q3 - q1
whisker_lower = q1 - 1.5 * iqr
whisker_upper = q3 + 1.5 * iqr

bank = mutate( bank, balance = ifelse( balance < whisker_lower | balance > whisker_upper, NA, balance ) ) 

bank $ balance = impute( bank $ balance, 'random' )

ggplot( data = bank) + 
  geom_histogram( aes( x = balance, fill = deposit ), position = "stack") + 
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

The plotting of the imputed data shows symmetry. Also, we read from the chart above, that the count for the deposit follows the shape of the overall histogram, from which we infer that the deposit rate across the several balances is approximately constant. To confirm that, we plot it as a standardised histogram.

```{r}
ggplot( data = bank) + 
  geom_histogram( aes( x = balance, fill = deposit ), position = "fill") + 
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

<<<<<<< HEAD
The above expectation set is confirmed. The subscription rate of the campaign is between 9% and 12% and is approximately constant over the difference account balances. Therefore, there is no strong graphical evidence that `balance` is an important factor in determining `deposit`. Therefore, we do not expect the data mining algorithm to incorporate the `balance` variable in the model.
=======
The above expectation set, is confirmed. The subscription rate of the campaign is between 9% and 12% and is approximately constant over the difference account balances. Therefore, there is no strong graphical evidence that `balance` is an important factor in determining `deposit`. Therefore, we do not expect the data mining algorithm to incorporate this `balance` in the model.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf
  
  
  </details>


  <details class="sub_details">
    <summary>EDA of `housing`</summary>

<h3>EDA of `housing`</h3>

<<<<<<< HEAD
Given that the `housing` is a binary variable, that stands for whether the person has a mortgage, we can first make a contingency table with the target variable, as well as plot `housing` as a regular bar chart then standardised it with a `deposit` overlay.
=======
Given that the `housing` is a binary variable, that stands for whether the person has a mortgage, we can first make a contingency table with the target variable, as well as plot `housing` as a regular bar chart and a standardised one with `deposit` overlay.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf

```{r}
addmargins( table( bank $ deposit, bank $ housing, dnn = c( "Deposit", "Housing" ) ) )
```

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = housing, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

Both the contingency table, and the bar chart gives away that those with housing loan represent the majority of customers. To be able to judge the proprtions between loan takers and deposit subscribers, we move on to the standardised bar chart.

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = housing, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

<<<<<<< HEAD
We see that approximately 15% of those without a mortgage subscribe for the deposit deal, while only 8% of loan holders subscribe. The difference between subscribers with and without housing loan is approximately two fold, which constitute to a significant difference. Therefore, it is reasonable to assume that the data mining algorithm will incorporate `housing` into the model.
=======
We see that approximately, 15% of those without a mortgage subscribe for the deposit deal, while only on 8% of loan holders the campaign is effective. The difference between subscribers with and without housing loan is approximately two fold, which constitute to a significant difference. Therefore, it is reasonable to assume that the data mining algorithm will incorporate `housing` into the model.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf

  </details>

  <details class="sub_details">
    <summary>EDA of `loan`</summary>

<h3>EDA of `loan`</h3>
Similar to `housing`, `loan` is a binary variable as well, therefore we can follow the exact same analysis that we did for `housing`.

That is, first we report a contingency table, and then plot the data on a bar chart.

```{r}
addmargins( table( bank $ deposit, bank $ loan, dnn = c( "Deposit", "Loan" ) ) )
```

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = loan, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

From the above chart we see that approximately 3800 customers do not have a personal loan, which represents a significant majority of the customers, while the rest 700 do have a loan.

The proportions from the regular bar chart is not clear, therefore, we look at the standardised equivalent of the above chart.

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = loan, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

<<<<<<< HEAD
We read, that the success rate of the campaign among customers without a personal loan is about 12.5%, while it is only 6% for those with a personal loan. In this case the difference is more than two fold between the success rates for the two groups, hence we shall expect the data mining algorithm to include `loan` in the model.
=======
We read, that the success rate of the campaign among customers without personal loan is about 12.5%, while it is only 6% for those with personal loan. In this case the difference is more than two fold between the success rates for the two groups, hence we shall expect the data mining algorithm to count `loan` in the model.
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf

  </details>

  <details class="sub_details">
    <summary>EDA of `contact`</summary>

<h3>EDA of `contact`</h3>

The `contact` variable describes the device on which the customer was contacted. There are 3 categories, that we interpret as follows: the cellular phone refers to the customers' wireless mobile phone, while telephone to landline phone. The third category is unknown, which may be via indirect ways, such as brochures, billboards etc.

It is a categorical variable, hence we can plot it on bar chart.

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = contact, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

We see that the majority  of customers were reached out to by their cellular phone, or an unknown way.

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = contact, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```


The standardised chart shows that there is technically no difference between the success rate of cellular and mobile phones, however, the campaign was is not deemed successful on the unknown group.

Cellular and telephone performed beyond the overall campaign's success rate, therefore, it may be advised to the campaign team to allocate the resources from the unknown contact way to cellular of telephone to elevate the subscription rate.

The above plot indicates strong graphical evidence of the predictive importance of the device, therefore, the data mining algorithm may as well select `contact` into the model.

  </details>

  <details class="sub_details">
    <summary>EDA of `day`</summary>

<h3>EDA of `day`</h3>

The `day` variable represent the given day in a month. When plotted as a bar chart, we see the last contact day's frequency.

```{r}
  ggplot( data = bank) +
    geom_bar(aes( x = day, fill = deposit ), position = "stack" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```

We see that the contact points are more frequent in the first 2/3 of the month compared with the last 1/3 of it. We standardise the plot to be able to read the proportions of subscription rate precisely.

```{r}
  ggplot( data = bank) +
    geom_bar(aes( x = day, fill = deposit ), position = "fill" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```

From the standardised plot, we see little to no pattern that would allude graphical evidence that `day` may have predictive importance in `deposit`. There are few days, that stand out in terms of success, but it may very well be just random noise.

  </details>

  <details class="sub_details">
    <summary>EDA of `month`</summary>

<h3>EDA of `month`</h3>

The `month` variable indicates the last contact point in terms of month. First we plot it as a regular bar chart to identify the number of contact points made per month.

```{r}
  ggplot( data = bank) +
    geom_bar(aes( x = month, fill = deposit ), position = "stack" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```

We see, that there are 5 months that are significantly different in terms of the number of contacts reached out to, and these are May, June, July, August, and November. These are the months, where the campaign was the most aggressive and reached out to many contacts. Next we standardise the chart to see the success rate of the campaign per month.

```{r}
  ggplot( data = bank) +
    geom_bar(aes( x = month, fill = deposit ), position = "fill" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```

We see from the above plot that March, September, October and December were the most successful months, and were able to campaign with more than 40% success rate on average. With a little bit lower subscription rate are February and April; their respective success rate are 15% to 20%. We see that the above plot indicates strong graphical evidence of the predictive importance of `month`.


  </details>

  <details class="sub_details">
    <summary>EDA of `duration`</summary>

<h3>EDA of `duration`</h3>

The `duration` variable is the last contact's duration expressed in seconds. We plot the data as a histogram with bin size of 60 seconds, so that each bar in the chart would represent a minute of duration.

```{r}
ggplot( bank ) +
    geom_histogram( mapping = aes( x = duration ), binwidth = 60 )
```
The wide range of the x-axis tells that the data has some outliers. Furthermore, the distribution of `duration` is positively skewed, which is expected, since most of the customer tend to keep promotional/marketing calls as short as possible.

Next we query some descriptive statistics on the variable in question.

```{r}
summary(bank $ duration)
```

We can report that the mean duration of the phone calls were 264 seconds. We can see that 25% of customers kept the phone call under 104 seconds, 50% of them under 185 seconds while 75% just under 329 seconds.

To identify outliers of the data, we will plot it as a boxplot groupped by `deposit`.

```{r}
ggplot( data = bank ) +
  geom_boxplot( aes(y = duration ) ) 
```

The above boxplot identifies outliers beyond `r 329 + 1.5 * (329 - 104)` seconds. Any observation beyond that duration is deemed an outlier. Next, to deal with the outliers, we replace the outliers with NA, impute data, and finally re-plot the graph groupped by `deposit`.

```{r}
q1 = boxplot(bank $ duration)$stats[2, ]
q3 = boxplot(bank $ duration)$stats[4, ]
iqr = q3 - q1

whisker_lower = q1 - 1.5 * iqr
whisker_upper = q3 + 1.5 * iqr

bank = mutate( bank, duration = ifelse( duration < whisker_lower | duration > whisker_upper, NA, duration ) ) 

bank $ duration = impute( bank $ duration, 'random' )

ggplot( data = bank) + 
    geom_histogram( mapping = aes( x = duration, fill = deposit) , binwidth = 60 ) + 
    scale_fill_manual( values = c( "red", "blue" ) )
```
It is worth to note, that the imputed data held its positively skewed shape, however, the the number of successful contacts per minute follows a symmetric distribution, with a peak at approximately 220 seconds.

Next we standardise the above histogram.

```{r}
ggplot( data = bank) + 
    geom_histogram( mapping = aes( x = duration, fill = deposit) , position = "fill", binwidth = 60 ) + 
    scale_fill_manual( values = c( "red", "blue" ) )
```

From the standardised histogram we clearly identify that the longer the duration of the call, the higher the proportion of subscribers for deposit.

Therefore, there is a strong graphical evidence of the predictive importance of `duration`, so we expect the data mining algorithm to incorporate this variable into the model.

  </details>

  <details class="sub_details">
    <summary>EDA of `campaign`</summary>

<h3>EDA of `campaign`</h3>

The `campaign` variable stands for the number of contacts performed during the campaign for specific contacts.

First, we plot the data as a bar chart.

```{r}
ggplot( data = bank) +
  geom_bar(aes( x = campaign, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```
We identify, that number of times customers were contacted is heavily positively skewed. That is, most of the targeted people were only contacted a few times. Furthermore, based on the width of the x-axis, we see a clear indication of outliers.
To deal with the outliers, we first plot the data on a boxplot, confirm the existense of outliers, and only then mutate and impute the data and finally re-plot it.

```{r}
ggplot( data = bank ) +
  geom_boxplot( aes( x = campaign) ) 
```

The above boxplot confirms the existene of outliers, represented by the dots beyond the right whisker.

```{r}
q1 = boxplot(bank $ campaign)$stats[2, ]
q3 = boxplot(bank $ campaign)$stats[4, ]
iqr = q3 - q1

whisker_lower = q1 - 1.5 * iqr
whisker_upper = q3 + 1.5 * iqr

bank = mutate( bank, campaign = ifelse( campaign < whisker_lower | campaign > whisker_upper, NA, campaign ) ) 

bank $ campaign = impute( bank $ campaign, 'random' )

ggplot( data = bank) +
  geom_bar(aes( x = campaign, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```
We report that observations beyond count 6 contact points are eliminated, yet the original distribution skewness kept its shape. That it, after the imputation, the data shows that the majority of customers were reached out only a few times.

Next we standardise the above distribution to report the subscription rate per the number of contact points in the campaign.

```{r}
ggplot( data = bank) +
  geom_bar(aes( x = campaign, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```
The above plot shows that the subscription rate is approximately constant during the first 4 contact points, at around 10% on average. To be more precise, we see that the first contact point yield a bit over 12.5% success rate, while it drops to around 10% for the second and third call, and eventually picks up to again 12.5% for the fourth call.

The major drop is after the fifth contact point, where the success rate is consistently below 10%

Although there are some learning of the above graphs, the plot does not indicate strong graphical evidence of predictive importance of `campaign`.

  </details>

  <details class="sub_details">
    <summary>EDA of `pday`</summary>

<h3>EDA of `pday`</h3>

`pday` stands for the number of days passed since the customer was last contacted. The field value may take on `-1`, which means that the customer was not contacted previously, and the current campaign contact is the first.

First, we report the frequency of each day passed as a bar chart.

```{r}
  ggplot( data = bank) +
    geom_bar(aes( x = pdays, fill = deposit ), position = "stack" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```

We not only see that the values along the x-axis spreads out on a wide range but also, that there are a significant overweight of `-1` observations, referring to that the the majority of customers were not contacted previously.

It is an advised to filter out those contacts from the data who were not reached out earlier, otherwise we areunable to draw a meaningful conclusion whether the `pday` is deterministic for the outcome for `deposit`

We achieve this by plotting `pdays` only for those who were reached out in the previous campaign.

```{r}
  ggplot( data = bank) +
    geom_bar( data = subset( bank, pdays != -1 ), aes( x = pdays, fill = deposit ), position = "stack" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```

Next, we plot a boxplot for the same observations, to see the outliers.

```{r}
ggplot( data = bank ) +
  geom_boxplot( data = subset( bank, pdays != -1 ), aes(y = pdays )) 
```

The boxplot identifies some outliers, that we first replace by NA values and then impute them, and finally re-plot it as a bar chart.

```{r}
bank2 = mutate( bank, pdays = ifelse( pdays == -1, NA, pdays ) ) 

q1 = boxplot(bank2 $ pdays)$stats[2, ]
q3 = boxplot(bank2 $ pdays)$stats[4, ]
iqr = q3 - q1

whisker_lower = q1 - 1.5 * iqr
whisker_upper = q3 + 1.5 * iqr

bank2 = mutate( bank2, pdays = ifelse( pdays < whisker_lower | pdays > whisker_upper, NA, pdays ) ) 


bank2 $ pdays = impute( bank2 $ pdays, 'random' )

ggplot( data = bank2) +
  geom_bar( aes( x = pdays, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

From the imputed data we see, that the majority of customers who were contacted previously, were contacted again for a follow up call between 35 and 375 days.

To see the success rate of each of the `pdays`, we plot it as a bar chart grouped by `deposit`.

```{r}
ggplot( data = bank2) +
  geom_bar(aes( x = pdays, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

Based on the above standardised graph, we see no strong graphical evidence of the predictive importance of `pdays`. Therefore, we do not expect the data mining algorithm to include `pdays` in the model.

  </details>

  <details class="sub_details">
    <summary>EDA of `previous`</summary>

<h3>EDA of `previous`</h3>

The variable `previous` stands for the number of contacts performed before the current campaign. First we plot it as a bar chart.

```{r}
  ggplot( data = bank) +
    geom_bar(aes( x = previous, fill = deposit ), position = "stack" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```

We see that the majority of the customers were not contacted previously. This observation coincides with the findings in `pdays`, where these observations were denoted by the value of `-1`.

Next, we standardise the data.

```{r}
  ggplot( data = bank) +
    geom_bar(aes( x = previous, fill = deposit ), position = "fill" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```

From the above plot we read, that the more the customer were contacted in the previous campaign but less than 10 times, then on average the likelihood of subscribing is higher for the current campaign. Although there are some valleys in the deposit rate for `previous` within the range of [0, 10], but the overall trend is upward sloping.

In this case, we find strong enough graphical evidence that previous is may serve as a good predictor for `deposit`, and hence expect the data mining algorithm to incorporate `previous` in the model.


  </details>

  <details class="sub_details">
    <summary>EDA of `poutcome`</summary>
    
<h3>EDA of `poutcome`</h3>

`poutcome` represents the outcome of the previous campaign, and can take on either of the following 4 values: "failure", "success", "unknown", "other".

We first plot it as a bar chart. 

```{r}
  ggplot( data = bank) +
    geom_bar(aes( x = poutcome, fill = deposit ), position = "stack" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```
We see that the unknown category has the highest count, which again is likely to represent the customers that were not contacted previously, and thereby coincides with data of `pdays` and `previous`.

Next, we plot `poutcome` as a standardised bar chart.

```{r}
  ggplot( data = bank) +
    geom_bar(aes( x = poutcome, fill = deposit ), position = "fill" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```

We interpret the above graph as that those previously subscribed for the deposit are more likely to subscribe again in the current campaign. The above plot indicates strong graphical evidence of the predictive importance of `poutcome`, and so the data mining algorithm will include `poutcome` in the model.

  </details>
  
<<<<<<< HEAD
  <details class="sub_details">
=======
  <details>
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf
    <summary>Conclusion</summary>
    <h3>Conclusion</h3>
    
In the above exploratory data analysis we analysed 17 variables, out of which we found the following ones graphically indicative enough to consider as a relevant predictor for `deposit`.

* `age`: Customers under age of 23 or above 60 are more likely to subscribe.
* `job`: Customers with unknown, student or retired occupation are the most likely to deposit. Next to that, customers with administrative, housemaid, management, or technician occupation are the second most likely to deposit.
<<<<<<< HEAD
* `education`: Customers with a tertiary educational background are the most likely to subscribe for the deposit deal.
* `housing`: Customers with a mortgage tend to subscribe twice as likely as those without a mortgage.
* `loan`: Customers with a personal loan tend to subscribe twice as likely as those without a personal loan.
=======
* `education`: Customers with tertiary educational background are the most likely to subscribe for the deposit deal.
* `housing`: Customers with mortgage tend to subscribe twice as likely as those without a mortgage.
* `loan`: Customers with personal loan tend to subscribe twice as likely as those without a personal loan
>>>>>>> 4f22e2b7d827f2dbb51c578f85fbe5741678b0bf
* `contact`: Customers reached out via cellular or telephone tend to be a subscriber more than those reached by unknown means. 
* `month`: Customers that were contacted last in March, September, October or December are the most likely to respond positively to the campaign and subscribe.
* `duration`: The higher the duration of the phone call, the more likely the customer subscribes.
* `previous`: The more times the customer was contacted in the previous campaign (but less than 10 times), the more likely he/she will subscribe in the current campaign.
* `poutcome`: If the customer subscribed for the deal in the previous campaign, it is likely the he/she will do it again in the current campaign.
    
  </details>

</details>

# **Bonus**: Exploratory Data Analysis for your own dataset (30 points)

In this part, you could apply Exploratory Data Analysis to explore your own dataset. You could follow the same steps as in part 1 (above) of these exercises.
