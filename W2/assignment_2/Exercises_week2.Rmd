---
title: '<center> The Exercises of Week 2 - Exploratory Data Analysis <center>'
author: '<center> Reza Mohammadi <center>'
date: '<center> `r Sys.Date()` <center>'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 5
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include = FALSE}
knitr::opts_chunk $ set( echo = TRUE, message = FALSE, warning = FALSE, 
                         comment = " ", error = FALSE, fig.align = 'center' )
```

**Full Name:** Peter Molnar (11759216)

**Online Assignments**: 
There is a new online-assignments at the [DataCamp](https://www.datacamp.com). This online exercise, related to data visualization in **R**, e.g., by using the [*ggplot2*](https://CRAN.R-project.org/package=ggplot2) package. These exercises are useful to prepare yourself for the computer-lab. *The online-assignments at the DataCamp are not mandatory*.

**Your task** is to answer the questions in this R-markdown file. Submit both your R-markdown (.Rmd) file and the HTML file on Canvas. 

**Note:** The exercise of this week has 100 points. Besides, the Bonus part has 30 extra points.  

# Exploratory Data Analysis for customer churn prediction (30 points)

Customer Churn is a topic that matters to organizations of all sizes. 
Customer churn occurs when customers stop doing business with a company, also known as customer attrition. Churn (loss of customers to competition) is a major problem for telecom companies because it is well known that it is more expensive to acquire a new customer than to keep an existing customer. Here, we use Exploratory Data Analysis to explore the *churn* dataset. Basically, we want to visualize and identify which factors contribute to customer churn.

**Dataset**: The *churn* data set is available in the **R** package [*liver*](https://CRAN.R-project.org/package=liver). The data set contains '5000' rows (customers) and 20 columns (features). The last column called *churn*  is the target variable which indicates whether customers churned (left the company) or not. If you want to know more about the dataset just type `?churn` in your **R** console. You also can find more information about this dataset [here](https://rdrr.io/cran/liver/man/churn.html).

Here we need to load the following **R** packages:

* [**ggplot2**](https://CRAN.R-project.org/package=ggplot2): we use this package to visualize our data in **R**.
* [**liver**](https://CRAN.R-project.org/package=liver): the *churn* dataset is in this package. 
* **GGally**: We use the `ggcorr()` function from this package.
* **psych**: We use the `pairs.panels()` function from this package.

**NOTE:** If you have not installed those two packages, you should first install them.

To load the packages:
```{r}
library( ggplot2 )  
library( liver   )  
library( GGally  )  
library( psych   )  
library( skimr   )  
library( Hmisc   )
library( plyr    )
library( ggpubr  )
```

## Business Understanding

Companies are interested to know who is gonna get churned so they can proactively go to the customer to provide them better services and turn customers' decisions in the opposite direction. Companies are interested to know:

* **What** customers are we losing?
* **Why** are we losing them?
* **How** do we stop them from leaving the company?

To answer these questions here, as a practical example, we use the *churn* data set is available in the **R** package [*liver*](https://CRAN.R-project.org/package=liver).

## Data Understanding 

This dataset comes from IBM Sample Data Sets. The data set contains 5000 rows (customers) and 20 columns (features). The "churn" column is our target which indicates whether the customer churned (left the company) or not.
The 20 variables are:

* `state`: Categorical, for the 51 states and the District of Columbia.
* `area.code`: Categorical.
* `account.length`: count, how long account has been active.
* `voice.plan`: Categorical, yes or no, voice mail plan.
* `voice.messages`: Count, number of voice mail messages.
* `intl.plan`: Categorical, yes or no, international plan.
* `intl.mins`: Continuous, minutes customer used service to make international calls.
* `intl.calls`: Count, total number of international calls.
* `intl.charge`: Continuous, total international charge.
* `day.mins`: Continuous, minutes customer used service during the day.
* `day.calls`: Count, total number of calls during the day.
* `day.charge`: Continuous, total charge during the day.
* `eve.mins`: Continuous, minutes customer used service during the evening.
* `eve.calls`: Count, total number of calls during the evening.
* `eve.charge`: Continuous, total charge during the evening.
* `night.mins`: Continuous, minutes customer used service during the night.
* `night.calls`: Count, total number of calls during the night.
* `night.charge`: Continuous, total charge during the night.
* `customer.calls`: Count, number of calls to customer service.
* `churn`: Categorical, yes or no. Indicator of whether the customer has left the company (yes or no).

We import the dataset in **R** as follows:
```{r}
data( churn ) # load the "churn" dataset
``` 

To see the overview of the dataset in **R** we could use the following functions: 

* `str`  to see a compact display of the structure of the data. 
* `View` to see spreadsheet-style data. 
* `head` to see the first part of the data (first 6 rows of the data).
* `summary` to see the summary of each variable.

To see the overview of the dataset in **R** we are using function `str` as follows:
```{r}
str( churn )   # Compactly display the structure of the data
```

It shows that data are as a *data.frame* object in **R** with `r nrow(churn)` observations and `r ncol(churn)` variables. The last column (with name *churn*) is the *target variable* that indicates whether customers churned (left the company) or not.

By using the function `summary` in **R**, we can see the summary of the dataset as follows

```{r}
summary( churn )
```
It shows the summary of all the `r ncol(churn)` variables. 

**a. For each variable in the churn dataset, specify its type.**

<details class="answer_panel">
  <summary>Answer a</summary>

|     Variable     |  R Datatype  |  Statistical Datatype   |
|        :-        |      :-:     |          :-             |
| `state`          | `Factor`     | categorical - nominal   |
| `area.code`      | `Factor`     | categorical - nominal   |
| `account.length` | `int`        | numerical - discrete    |
| `voice.plan`     | `Factor`     | categorical - binary    |
| `voice.messages` | `int`        | numerical - discrete    |
| `intl.plan`      | `Factor`     | categorical - binary    |
| `intl.mins`      | `num`        | numerical - continuous  |
| `intl.calls`     | `int`        | numerical - discrete    |
| `intl.charge`    | `num`        | numerical - continuous  |
| `day.mins`       | `num`        | numerical - continuous  |
| `day.calls`      | `int`        | numerical - discrete    |
| `day.charge`     | `num`        | numerical - continuous  |
| `eve.mins`       | `num`        | numerical - continuous  |
| `eve.calls`      | `int`        | numerical - discrete    |
| `eve.charge`     | `num`        | numerical - continuous  |
| `night.mins`     | `num`        | numerical - continuous  |
| `night.calls`    | `int`        | numerical - discrete    |
| `night.charge`   | `num`        | numerical - continuous  |
| `customer.calls` | `int`        | numerical - discrete    |
| `churn`          | `Factor`     | categorical - binary    |

</details>

**b. Based on the output of the `summary` function for the churn dataset, what is the number of customers who have an international plan (`intl.plan = "yes"`)?**

<details>
  <summary>Answer b</summary>
  
```{r}
intl_plan_holder = length(which(churn $ intl.plan == "yes"))
intl_plan_holder
```
  
  The customer churn rate is `r intl_plan_holder`.

</details>

## Investigate the target variable *churn* 

Here we report a bar plot for the target variable `churn` by using function `ggplot()` from the **R** package **ggplot2** as follows:

```{r fig.align = 'center', fig.height=5, fig.width=5}
ggplot( data = churn ) + 
    geom_bar( aes( x = churn ), fill = c( "red", "blue" ) ) +
    labs( title = "Bar plot for the target variable 'churn'" )  
```

Summary for the target variable `churn`
```{r}
summary( churn $ churn )
```

**Based on the above output, what is the proportion of the churner (customer churn rate)?**

<details>
  <summary>Answer</summary>
  
  $P(churn = no) = 4293$
  
  $P(churn = yes) = 707$
  
  $n = P(churn = no) + P(churn = yes) = 4293 + 707 = 5000$
  
  $P(churn = yes) = \frac{P(churn = yes)}{n} = \frac{707}{5000} = 0.1414 = 14.14\%$
  
  The proportion of churners is $14.14\%$.
</details>

## Investigate variable *International Plan*

Here we first report a contingency table of International Plan (`intl.plan`) with `churn`
```{r}
table( churn $ churn, churn $ intl.plan, dnn = c( "Churn", "International Plan" ) )
```

Here is the above contingency table with margins
```{r}
addmargins( table( churn $ churn, churn $ intl.plan, dnn = c( "Churn", "International Plan" ) ) )
```

Bar chart for International Plan

```{r fig.align = 'default', fig.show = "hold", out.width = "50%"}
ggplot( data = churn ) + 
  geom_bar( aes( x = intl.plan, fill = churn ) ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 

ggplot( data = churn ) + 
  geom_bar( aes( x = intl.plan, fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

**What would be your interpretation of the above plots?**

<details>
  <summary>Answer</summary>
  
The first plot depicts a bar chart of `intl.plan`, with `churn` overlay. The chart shows that approximately 500 customers have an international plan, while the rest do not. The proportions of churners is not clearly readable, but approximately half of the customers who have an international plan tend to churn. The churn rate is much smaller for customers who do not have international plan.

The right chart is the standardised version of the bar chart on the left. The standardised chart's y-axis ranges between 0 and 1, and it shows the proportions of churners in each `intl.plan` category. This chart allows for more precision; we read that approximately 42% of international plan holders change to a different company, while this number is around 11% for those not having an international plan. 

Conclusively, international plan holders churn rate is about four times higher than for non subscribers. The variable in question may bear with explanatory power, hence it would not come as a surprise if the data mining algorithm would use `intl.plan` in the prediction model.

</details>

## Investigate variable "*voice mail plan*"

Make a table for counts of Churn and Voice Mail Plan

```{r}
addmargins(table( churn $ churn, churn $ voice.plan, dnn = c( "Churn", "Voice Mail Plan" ) ))
```

Bar chart for Voice Mail Plan

```{r fig.align = 'default', fig.show="hold", out.width="50%"}
ggplot( data = churn ) + 
  geom_bar( aes( x = voice.plan, fill = churn ) ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 

ggplot( data = churn ) + 
  geom_bar( aes( x = voice.plan, fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

**What would be your interpretation of the above plots?**

<details>
  <summary>Answer</summary>

The left plot depicts a barchart for `voice.plan`, with `churn` overlay, groupped by `voice.plan` categories. Those of voice plan holders represent themselves with 1300 customers, while those of non-holders with about 3700 customers.

The right plot is a standardised bar chart, and shows that approximately 8% of voice mail plan holders churn. For those who did not opt for voice mail plan, the churn rate is roughly twice as much, 16%.

Conclusively, churn rate is higher amongst customers who do not have voice mail plan, than for those who do have. `voice.plan` may have some explanation for the 14.14% churn rate, and hence we should expect that the data mining algorithm will include it in prediction model.
  
</details>

## Investigate variable "*customer service calls*" 

Here, we are interested to investigate the relationship between variable "*customer service calls*" and the target variable "*churn*". First, we report the histogram of the variable "*customer service calls*" by using function `ggplot` as follows

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = factor( customer.calls ) ) ) 
```

To see the relationship between variable "*customer service calls*" and the target variable "*churn*", we report the histogram of the variable "*customer service calls*" including "churn" overlay as follows

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = factor( customer.calls ), fill = churn ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

We also report the *Normalized* histogram of variable "*customer service calls*" including "churn" overlay as follow

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = factor( customer.calls ), fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

**What would be your interpretation of the above plots?**

<details>
  <summary>Answer</summary>

The first plot is a histogram of `customer.calls`, and it is positively skewed, whit a mean of `r mean(churn $ customer.calls)` call(s). The skewness of the data may be explained by that the majority of customers who contacts the customer service desk have their matter solved within one call, and hence there is no need for further calls.

The second plot is similar to the first histogram, however, it adds `churn` overlay. Since it is challenging to read the proportions of the histogram we turn to the standardised histogram, that is the last plot.

The standardised histogram depicts the proportions of churners vs non-churners for each histogram bar. We observe that that churn rate is fairly stable at around 11% for customers who had less than 3 customer service calls. The churn rate, however, at least quadruples for those contacting the customer service desk at least 4 times. It seems, that customers tolerance or satisfaction drops significantly as soon as they need to call at least 4 times the customer service.

It is worth to note, that the standardised and non-standardised plots must be used together, otherwise it may lead to misleading observations. Such as, if we did not take into account the non-stardardised histogram, then we would conclude that customers calling the service desk 9 times churn wiht certainty. However, this would be misleading, since there are only just a handful of 9 count observations.

Given the strong graphical evidence of predictive importance, it is expected that the data mining algorithm will include `service.calls` in the model.

</details>

## Investigate variable "*Day Minutes*"

Here, we are interested to investigate the relationship between variable Day Minutes and the target variable *Churn*. First, we report the “Normalized” histogram of Day Minutes including Churn overlay:

```{r}
ggplot( data = churn ) +
  geom_histogram( aes( x = day.mins, fill = churn ), position = "fill", binwidth = 25, color="white" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

Another way to see the relationship between variable Day Minutes and the target variable *churn*, would be by using the boxplot as follows

```{r}
ggplot( data = churn ) +
  geom_boxplot( aes( x = churn, y = day.mins ), fill = c( "red", "blue" ) ) 
```

**What would be your interpretation of the above boxplot?**

<details>
  <summary>Answer</summary>

The above boxplots depict the locality, spread and skewness of `day.mins` grouped by `churn` categories.

**Comparison of location:** For both `churn` categories, that is for churners and non-churners, the distribution is approximately symmetric. This finding bears with the advantage, that we can state that the distributions' mean and median are approximately at the same location. Knowing this, allows us to draw that the daily length of calls for churners is approximately on average 215 minutes. This number, is somewhat lower for those of non-churners — they spent on average around 190 minutes on phone calls daily.

To allow for a more precise analysis, we need to plot the data as frequency density plot; the below code performs that.

```{r}
ggplot( data = churn) + 
  geom_density( aes( x = day.mins, fill = churn ), alpha = 0.3)
```


We observe, that churners show bimodality at two locations; at 160 minutes, and 270 minutes. That is, customers with daily phone calls of 160, and 270 minutes churn with the highest rate. Furthermore, we can read that customer churn rate increases as `day.mins` exceeds 200 minutes.

**Comparison of dispersion:** From the boxplots we read that the interquartile range for churners is approximately twice as large than for non-churners. Additionally, we read from the width of the whiskers, that the range of `day.mins` for churners is wider than for non-churners.

**Comparison of skewness:** `day.mins` for churners is skewed to the left - churners spend more on phone calls, than non churners.

**Comparison of potential outliers:** `day.mins`'s whisker spreads from the minima of the data to the maxima of it, and hence it does not have any outliers, or unusual values. This cannot be stated for non-churners, since they have potential outliers beyond the lower and upper whiskers.

`day.minutes` seem to hold relevant information, and therefore we should expect the data mining algorithm to select this variable into the model.

</details>


## Investigate variable "*International Calls*" 

Here, we are interested to investigate the relationship between variable International Calls and the target variable `churn`. First, we report the histogram of the variable International Calls as follows:

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = intl.calls ) ) 
```

To see the relationship between variable International Calls and the target variable *churn*, we report the histogram of variable International Calls including Churn overlay as follow

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = intl.calls, fill = churn ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

We also report the *Normalized* histogram of variable International Calls including Churn overlay as follow

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = intl.calls, fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

To see the relationship between variable International Calls and the target variable *churn*, we report the boxplot as follow

```{r}
ggplot( data = churn ) +
  geom_boxplot( aes( x = churn, y = intl.calls ), fill = c( "red", "blue" ) ) 
```

**What would be your interpretation of the above boxplot?**

<details>
  <summary>Answer</summary>
  
The above boxplots depict the locality, spread and skewness of `intl.calls` grouped by `churn` categories.
  
**Comparison of location:** Based on the boxplots, we see that the median count of internatinal calls made by churners and non-churners are approximately the same.

**Comparison of dispersion:** The interquartile range for churners versus non-churners are reasonably similar, as well as the overall range of the data, seen by measuring the whisker lengths.

**Comparison of skewness:** Both batches of data are positively skewed, however, for churners it is more severe than for non-churner. Meaning, that churners have a lower count of international calls than that of non-churners.

**Comparison of potential outliers:** Both data contains upper outliers, however, nothing deterministic may be drawn from this observation.

As a general conclusion, the above plots do not indicate strong graphical evidence of the predictive importance of international calls. Therefore, it may be that the data mining algorithm would not include it in the model.

```{r}
ggplot( data = churn) + 
  geom_density( aes( x = intl.calls, fill = churn ), alpha = 0.3)
```
  
</details>

## Detect Correlated Variables 

To visualize the correlation matrix between the "day.mins", "Day.Calls", "Day.Charge", "Eve.Mins", "Eve.Calls", "Eve.Charge", "Night.Mins", "Night.Calls", and "Night.Charge", we could use the `ggcorr` function as follows

```{r message = FALSE, warning = FALSE, fig.align='center' }
variable_list = c( "intl.mins",  "intl.calls",  "intl.charge", 
                   "day.mins",   "day.calls",   "day.charge",
                   "eve.mins",   "eve.calls",   "eve.charge",
                   "night.mins", "night.calls", "night.charge" )

ggcorr( data = churn[ , variable_list ], label = TRUE ) 
```

```{r fig.align = 'default', fig.show="hold", out.width="50%"}
pairs.panels( churn[ , c( "intl.mins", "intl.calls", "intl.charge" ) ] ) 

pairs.panels( churn[ , c( "day.mins", "day.calls", "day.charge" ) ] ) 

pairs.panels( churn[ , c( "eve.mins", "eve.calls", "eve.charge" ) ] ) 

pairs.panels( churn[ , c( "night.mins", "night.calls", "night.charge" ) ] ) 
```

**What would be your interpretation of the above correlation matrix plots?**

<details>
  <summary>Answer</summary>
  
From the above correlation matrix we see that there are 4 problematic variables that shows perfect correlation (r=1.0) with another variable.

Namely, `night.charge` is perfectly linearly correlated with `night.mins`, which does not come as surprise, since the former is a function of `night.mins`. The same holds true for `eve.mins` and `eve.charge`, `day.mins` and `day.charge`, and lastly `intl.mins` and `intl.charge`.

Using correlated variables will overemphasize one data component, or at worst the data may become unstable and deliver unreliable results. Therefore we need to retain only one of the correlated ones.

</details>

# Exploratory Data Analysis for Bank direct marketing dataset  (70 points)

In this part, we want to use Exploratory Data Analysis to explore the *bank* dataset that is available in the **R** package [**liver**](https://CRAN.R-project.org/package=liver). You could find more information about the *bank* dataset at the following link on pages 4-5: [manual of the liver package](https://cran.r-project.org/web/packages/liver/liver.pdf); Or  [here](https://rdrr.io/cran/liver/man/bank.html).

## Business Understanding

Find the best strategies to improve for the next marketing campaign. How can the financial institution have greater effectiveness for future marketing campaigns? To make a data-driven decision, we need to analyze the last marketing campaign the bank performed and identify the patterns that will help us find conclusions to develop future strategies.

### Bank direct marketing info

Two main approaches for enterprises to promote products/services are: 

* *mass campaigns*: targeting general indiscriminate public,
* *directed marketing*, targeting a specific set of contacts. 

In general, positive responses to mass campaigns are typically very low (less than 1%). On the other hand, direct marketing focuses on targets that are keener to that specific product/service, making this kind of campaign more effective. However, direct marketing has some drawbacks, for instance, it may trigger a negative attitude towards banks due to the intrusion of privacy.

Banks are interested to increase financial assets. One strategy is to offer attractive long-term deposit applications with good interest rates, in particular, by using directed marketing campaigns. Also, the same drivers are pressing for a reduction in costs and time. Thus, there is a need for an improvement in efficiency: lesser contacts should be done, but an approximate number of successes (clients subscribing to the deposit) should be kept.

### What is a Term Deposit?

A Term Deposit is a deposit that a bank or a financial institution offers with a fixed rate (often better than just opening a deposit account), in which your money will be returned at a specific maturity time. For more information with regards to Term Deposits please check [here](https://www.investopedia.com/terms/t/termdeposit.asp).

## Data Undestanding

The *bank* dataset is related to direct marketing campaigns of a Portuguese banking institution. You can find more information related to this dataset at: [https://rdrr.io/cran/liver/man/bank.html](https://rdrr.io/cran/liver/man/bank.html)

The marketing campaigns were based on phone calls. Often, more than one contact (to the same client) was required, to access if the product (bank term deposit) would be (or not) subscribed. The classification goal is to predict if the client will subscribe to a term deposit (variable deposit).

We import the *bank* dataset:
```{r}
data( bank )      
```

We can see the structure of the dataset by using the `str` function:
```{r}
str( bank )
```

It shows that the *bank* dataset as a `data.frame` has `r ncol( bank )` variables and `r nrow( bank )` observations. The dataset has `r ncol( bank ) - 1` predictors along with the target variable `deposit` which is a binary variable with 2 levels "yes" and "no". The variables in this dataset are:

* `age`: numeric.
* `job`: type of job; categorical: "admin.", "unknown", "unemployed", "management", "housemaid", "entrepreneur", "student", "blue-collar, "self-employed", "retired", "technician", "services".
* `marital`: marital status; categorical: "married", "divorced", "single"; note: "divorced" means divorced or widowed.
* `education`: categorical: "secondary", "primary", "tertiary", "unknown".
* `default`: has credit in default?; binary: "yes","no".
* `balance`: average yearly balance, in euros; numeric.
* `housing`: has housing loan? binary: "yes", "no".
* `loan`: has personal loan? binary: "yes", "no".

Related with the last contact of the current campaign:

* `contact`: contact: contact communication type; categorical: "unknown","telephone","cellular". 
* `day`: last contact day of the month; numeric.
* `month`: last contact month of year; categorical: "jan", "feb", "mar", ..., "nov", "dec".
* `duration`: last contact duration, in seconds; numeric.

Other attributes:

* `campaign`: number of contacts performed during this campaign and for this client; numeric, includes last contact.
* `pdays`: number of days that passed by after the client was last contacted from a previous campaign; numeric, -1 means client was not previously contacted.
* `previous`: number of contacts performed before this campaign and for this client; numeric.
* `poutcome`: outcome of the previous marketing campaign; categorical: "success", "failure", "unknown", "other".

Target variable:

* `deposit`: Indicator of whether the client subscribed a term deposit; binary: "yes" or "no".

**Following Part 1, first, report the summary of the dataset then apply the Exploratory Data Analysis.**

<details>
  <summary>Answer</summary>
  
```{r}
summary(bank)
```
  
```{r}
skim(bank)
```
  
```{r}
variable_list = c( "age", "job", "marital", "education", "default", "balance",
                   "housing", "loan", "contact", "day", "month",  "duration",
                   "campaign", "pdays", "previous", "poutcome", "deposit")

ggcorr( data = bank[ , variable_list ], label = TRUE ) 

```

<h3>EDA of `deposit`</h3>

```{r}
ggplot( data = bank ) + 
    geom_bar( aes( x = deposit ), fill = c( "red", "blue" ) ) +
    labs( title = "Bar plot for the target variable 'deposit'" )  
```

From the above bar chart and descriptive statistics we read that the deposit rate after the conducted marketing campaign is about 11.5%. Below we conduct an Exploratory Data Analysis as an attempt to find patterns and explanation for the target variable `deposit`.

We start the exploration of the `age` variable to see if age is deterministic of the deposit rate, and whether there is any focus group that the bank needs to focus on for the next campaign.

<h3>EDA of `age`</h3>

`age` is a discrete numerical variable, representing the age of the customer in the dataset. Below `age`is plotted as a density function groupped by `deposit` categories.

```{r}
ggplot( data = bank) + 
  geom_density( aes( x = age, fill = deposit ), alpha = 0.3)
```

The above graph shows similar characterisitcs for both depositors as well as non-depositors. We read that, customers under 30 and beyond 60 years of age are more likely to become a depositors than those of between 30 and 60 years of age.

To see if we are dealing with any unusual or outlier values, we plot `age` as boxplots for both `deposit` categories.

```{r}
ggplot( data = bank ) +
  geom_boxplot( aes( x = deposit, y = age ), fill = c( "red", "blue" ) ) 
```

**Comparison of location:** The central location of the two boxplots are approximately shared at 40 years. It shows, that the median age for depositors, and non-depositors are approximately the same.

**Comparison of dispersion:** The interquartile range of non-depositors are shorter than that of depositors, and this in general holds for the overall range of age as well. That is, the age range for no depositors is narrower than for depositors.

**Comparison of skewness:** Per above, it was stated that for both groups, the data is positively skewed, that is the bulk of the data is towards range of data where customers are considered older.

**Comparison of potential outliers:** Both categeories report some outliers, however, non-depositors have about twice as many outliers than that of depositors.

Based on the above two graphs, it is advised to include age in our data mining model, and specifically focus on age range of 30 to 60 years old customers as they tend to deposit less likely.

<h3>EDA of `job`</h3>

We first plot `job` categories as a histogram with `deposit` overlay.
```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = factor( job ), fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

From the above histogram we can distinguish 3 group of workers based on their frequency in the dataset. Those of total count greater than 750 are blue-collar workers, management personnel, and technicians. The second largest group are more than 375 in the dataset and of administrative workers, and those working in the service sector (to be revised!!). The third group is of every other occupation that represent themselves with less than 250 people.

Given that the proportions are difficult to read, we standardise the histogram and replot it.

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = factor( job ), fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

From the standardised plot we read that the campaign was most effective amongst the following job categories: elderly people, students, and those of unknown occupation. This finding is confirmed by the previous variable, `age`, whereby we saw, that the depositor curve was above non-depositors for age below 30 and beyond 60 years of age.

For the rest of the occupations, we see deposit rate ranging between 6% and 12%, however, the plot does not indicate strong graphical evidence of `job` being a general predictor for target variable `deposit`. (revise!)

Next, we move on to `marital` status.

<h3>EDA of `marital`</h3>

We first plot marital status with `deposit` overlay, and then as a standardised histogram.

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = marital, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 

ggplot( data = bank ) +
  geom_bar( aes( x = marital, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

From the above plots we see that the married customers are over-represented in the dataset with a count of approximately 2800. Singles are around 1200 in the dataset, while the rest approximately 500 customers are either divorced or widowed.

The standardised plot allows us to read the deposit proportions among marital statuses; we read that the success rate of the campaign accross different relationship statuses are of similar, and ranges between 10% and 12%.

The variable `martial` does not hold strong graphical indiciation of the predictive importance of marital status. Therefore it is likely that the data mining algorithm will not include in the making predictions with it.

Next, we move on to `education`.

<h3>EDA of `education`</h3>

The `education` variable has four categories; "primary", "secondary", "tertiary" and an "unknown" category.

* Primary education or elementary education is typically the first stage of formal education.
* Secondary education typically takes place after six years of primary education and is followed by higher education, vocational education or employment.
* Tertiary education refers to all formal post-secondary education, including public and private universities, colleges, technical training institutes, and vocational schools.

We explore `education` by means of regular bar chart and standardised barchart with `deposit` overlay.

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = education, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = education, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

The above 2 bar charts shows that customers with secondary educations are represented the most in the data set followed by that of tertiary education participants. The deposit rate is not clear from the regular bar chart, therefore, we analyse the standardised graph.

We report that those of tertiary education participants tend to deposit with 15% likelihood after the conducted campaign. The other 3 groups, `primary`, `secondary` and `unknown`, we see almost identical deposit rates, at around 10%.

Next we move on to `default`.

<h3>EDA of `default`</h3>

We explore the `default` through bar charts with `deposit` overlay.

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = default, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) ) 
```

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = default, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

We read from the regular bar chart that those who did not default on their credit are over-represented in the dataset by 4445 customers, and only 76 defaulted.

The standardised chart reveals that there is no difference in the deposit rate between the two groups, therefore, the EDA of `default` is inconclusive. I.e., `default` does not indicate strong graphical evidence of any predictive importance. Therefore it is likely that the data mining algorithm will not include that in the prediction model.

Next we move on to `balance`.


<h3>EDA of `balance`</h3>

`balance` is a continuous numeric variable, hence it is plotted as a histogram. 

```{r}
ggplot( bank ) +
    geom_histogram( mapping = aes( x = balance ))
```

One's balance is closely related to their income, and since we know that income is a positively skewed distribution in general, we expect balance to be similar.

From the above histogram we can confirm that balance is indeed positively skewed, with mean balance of €1423. The wide range of balances gives away that the dataset contains unusually high balances. Therefore chances are that there are outliers in the dataset. Furthermore, we report that balance may also be negative, representing overdraft, which occurs when money is withdrawn in excess of what is in a current account.

Balances around 0 dominate the data, but to see that rest of the distribution in more details we zoom into it by adjusting the limit of the y-axis to [0, 1000].

```{r}
ggplot( bank ) + 
  geom_histogram( mapping = aes( x = balance )) +
  coord_cartesian( ylim = c( 0, 1000 ) )
```

Unfortunately the zoomed in part does not provide necessarily more information but confirms the existence of outliers around €40000 and and €70000. To see the potential outliers, we plot `balance` as a boxplot.

```{r}
ggplot( data = bank ) +
  geom_boxplot( aes( x = balance))
```

We recognise plenty of outliers, so to be able to interpret it, we need to handle outliers by means of imputation, and then replot the grap.

```{r}
ggplot( data = bank) + 
  geom_density( aes( x = balance, fill = deposit ), alpha = 0.3)


q1 = boxplot(bank $ balance)$stats[2, ]
q3 = boxplot(bank $ balance)$stats[4, ]
iqr = q3 - q1
whisker_lower = q1 - 1.5 * iqr
whisker_upper = q3 + 1.5 * iqr

bank = mutate( bank, balance = ifelse( balance < whisker_lower | balance > whisker_upper, NA, balance ) ) 

bank $ balance = impute( bank $ balance, 'random' )

ggplot( data = bank) + 
  geom_density( aes( x = balance, fill = deposit ), alpha = 0.3)
```

```{r}

```

From the above graph we see that the deposit rate is higher on customers who have at least approximately €400 euros in their bank account. The campaign is the least successful on customers with slight overdraft (-€200) and balance below €400.

There is sufficient graphical evidence of the predictive importance of balance, therefore, we can expect the data mining algorithm incorporate the `balance` variable in a model.

Next, we move on `housing`.

<h3>EDA of `housing`</h3>

Given that the `housing` is a binary variable, that stands for whether the person has a mortgage, we can first make a contingency table with the target variable, as well as plot `housing` as a barchart with `deposit` overlay.

```{r}
addmargins( table( bank $ deposit, bank $ housing, dnn = c( "Deposit", "Housing" ) ) )
```

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = housing, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

Both the contingency table, and the bar chart gives away that those with housing loan represent the majority of customers. To be able to judge the proprtions between loan takers and deposit subscribers, we need to standardise the barchart.

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = housing, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

We see that approximately, 15% of those without housing loan subscribe for the deposit deal, while only on 8.5% of loan holders the campaign is effective. The difference between subscribers with and without housing loan is approximately two fold, which constitute to a significant difference. Therefore, it is reasonable to assume that the data mining algorithm will incorporate `housing` into the model.

Next, we move on with `loan`.

<h3>EDA of `loan`</h3>
Similar to `housing`, `loan` is a binary variable as well, therefore we can follow the exact same analysis that we did for `housing`.

That is, first we report a contingency table, and then plot the data on a bar chart.

```{r}
addmargins( table( bank $ deposit, bank $ loan, dnn = c( "Deposit", "Loan" ) ) )
```

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = loan, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

From the above chart we see that approximately 3800 customers do not have a personal loan taken, which represents a significant majority of the customers, while the rest 700 do have a loan.

The proportions from the regular bar chart is not clear, therefore, we generate the standardised equivalent of it.

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = loan, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

We read, that the success rate of the campaign among customers without personal loan is about 12.5%, while it is only 6% for those with personal loan. In this case the difference is more than two fold between the success rates, so `loan` we shall expect the data mining algorithm to count this variable in the model.

Next we move on with variables related to the last contact of the current campaign.

<h3>EDA of `contact`</h3>

The `contact` variable describes the device on which the customer was contacted. There are 3 categories, that we interpret as follows: the cellular phone refers to the customers wireless mobile phone, while telephone to landline phone. The third category is unknown, which may be via indirect ways, such as brochures, billboards. 

It is a categorical variable, hence we can plot it on barchart.

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = contact, fill = deposit ), position = "stack" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```

We see that the majority  of customers were reached out to by their cellular phone, or an unknown way.

```{r}
ggplot( data = bank ) +
  geom_bar( aes( x = contact, fill = deposit ), position = "fill" ) +
  scale_fill_manual( values = c( "red", "blue" ) )
```


The standardised chart shows that there is technically no difference between the success rate of cellular and mobile phones, however, the unknown category does not perform well.

The above plot indicates strong graphical evidence of the predictive importance of the device, therefore, the data mining algorithm may as well select `contact` into the model.

We continue the analysis with `day` and `month`.

<h3>EDA of `day`</h3>

The `day` variable represent the given day in a month. When plotted as a barchart, we see the last contact day's frequency. We see that the contacts are the most frequent in the first 2/3 of the month. Towards the end of the month the campaign tunes down a bit. From the grap we cannot see the success rate precised, therefore, we next plot it as a standardised barchart.

```{r}
  ggplot( data = bank) +
    geom_bar(aes( x = day, fill = deposit ), position = "stack" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```

```{r}
  ggplot( data = bank) +
    geom_bar(aes( x = day, fill = deposit ), position = "fill" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```
We see little to no strong graphical evidence from the standardised chat that day may have predictive importance in `deposit`. It is also worth to note, the `day` is uniformly distributed only until the curernt month's 28th day. This is because, every month is at least 28 days, however, not every month have 30 days. Therefore, this distorts the above data, though it does not change on the verdict, according to which it has little to no predictive importance.

<h3>EDA of `month`</h3>

The `month` variable tells the last contact date in terms of month. First we plot it as a regual barchart to identify which month were the most aggressive from the viewpoint of the campaign. That is, which month has the highest frequency of contacts.

```{r}
  ggplot( data = bank) +
    geom_bar(aes( x = month, fill = deposit ), position = "stack" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```

We see, that There are 5 months that stand out clearly from the rest in terms of contact counts. These are namely May, June, July, August, and November. Next we standardise the chart to see the success rate of the campaign per month. 

```{r}
  ggplot( data = bank) +
    geom_bar(aes( x = month, fill = deposit ), position = "fill" ) +
    scale_fill_manual( values = c( "red", "blue" ) )
```

We see from the above plot that March, October and November were the most successful months, and were able to campaign with nearly 50% success rate. A little bit behind are April and September with success rate of 20% and 30% respectively. The above plot indicates strong graphical evidence of the predictive importance of `month`.

<h3>EDA of `day` and `month` together</h3>

First we take a look at distribution of each month, and try to see if there is any pattern followed. Therefore we plot each plot `day` groupped by `month`

```{r}
month = c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")
month_plots = list()

for (cur_month in month)
{
  month_plots[[cur_month]] = ggplot( data = bank) +
    geom_bar(data = subset(bank, month == cur_month), aes( x = day, fill = deposit ), position = "stack" ) +
    scale_fill_manual( values = c( "red", "blue" ) ) + 
    ggtitle(paste("last contact day in", as.character(cur_month)))
}

ggarrange(plotlist=month_plots, nrow=4, ncol=3)
```

We can see from the above plots, that the most intensive period for the campaign was running from May until August. The campaign is less aggressive in the following months: March, September, October and December. Finally, the campaign is in the lowest gear in the following months: January, February, April, November.

It is difficult to see the proportional success rate of the campaigns from the above graphs, so they need to be standardised.

```{r}
month = c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")
month_plots = list()

for (cur_month in month)
{
  month_plots[[cur_month]] = ggplot( data = bank) +
    geom_bar(data = subset(bank, month == cur_month), aes( x = day, fill = deposit ), position = "fill" ) +
    scale_fill_manual( values = c( "red", "blue" ) ) + 
    ggtitle(paste(as.character(cur_month)))
}

ggarrange(plotlist=month_plots, nrow=4, ncol=3)
```

The standardised graph we see that February, March, April, June, August, September October and November performed the best. There is enough graphical indication that a day in the month

</details>

# **Bonus**: Exploratory Data Analysis for your own dataset (30 points)

In this part, you could apply Exploratory Data Analysis to explore your own dataset. You could follow the same steps as in part 1 (above) of these exercises.