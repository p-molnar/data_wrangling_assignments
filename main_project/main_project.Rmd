---
title: '<center> How to increase employee retention in the field of Data Science <center>'
author: '<center> Peter Molnar <center>'
date: '<center> `r Sys.Date()` <center>'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 5
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk $ set( echo = TRUE, message = FALSE, warning = FALSE, error = FALSE, fig.align = 'center'  )
```

```{r}
# dependencies
library( liver )          # For dataset 'churn'

library( ggplot2 )        # For visualization
library( GGally )         # For correlation plots
library( psych )          # For correlation plots  

library( rpart )          # For the "CART" algorithm
library( rpart.plot )     # To plot decision trees
library( C50 )            # For the "C5.0" algorithm
library( randomForest )   # For the "Random Forest" algorithm

library( pROC )           # For ROC plot

library(readr)            # For the read_csv function

library( naniar  )        # for missing value plotting
library( Hmisc  )         # for imputation
library( dplyr  )         # for select function
data(churn)
```

```{r results = FALSE, echo = FALSE }
# To ensure consistent formatting of the plots, we are using a colour theme:
theme_new = theme( panel.background = element_rect( fill = "white", colour = "white", size = 0.5, linetype = "solid" ),
                   panel.grid.major = element_line( size = 0.2, linetype = 'solid', colour = "gray77" ), 
                   panel.grid.minor = element_line( size = 0.1, linetype = 'solid', colour = "gray90" ),
                   axis.text  = element_text( size = 11 ), 
                   axis.title = element_text( size = 12, face = "bold" ),
                   title = element_text( size = 14, face = "bold" )
                  )
```

# Business Understanding Stage

## General understanding of the problem

Employee turnover refers to the event of replacing current employees with new ones. Employee acquisition is a long and costly procedure, and hence unwanted turnover is one of the most persistent and frustrating problems that organisations have long been facing.

Whether it is involuntary, such as termination due to poor performance, or voluntary, such as resignations, turnover is extremely costly. According to a conservative estimates by the Bureau of Labor Statistics, on average an employee replacement costs approximately \$13,996 per employee. However, this amount for the Information Technology (IT) sector on average may reach the \$20,000 per employee.  As the economy grows, more jobs, and therefore opportunities are created, and thereby voluntary turnover also increases. Despite these figures, organisations tend to underestimate the true cost of turnover. This may be because, it is not an accountable line-item in most profit and loss statements, nor is it typically adequately defined in the budget, and no one submits an invoice at the end of the month for turnover. 

In addition to the explicit replacement fees, there are implicit costs as well, such as productivity loss, workplace safety issues, and morale damage to the company.

Since there is not much organisations can do to dramatically reduce the costs associated with turnover, the best measure is to reduce turnover directly by an improved selection process that assesses candidates' turnover risk, motivational fit early in the hiring process. Such hiring process helps to reduce turnover, and can lead to a safer, more productive and profitable work place.

## Dataset objective

A Big Data and Data Science specialised company wants to hire data scientists among people who successfully pass training courses which is conducted by the company. Given the vast amount of sign-ups for the training, the company wants to know which of the candidates want to work for the company after training, and which one is looking for a new employment.

This paper aims to identify factors associated with employee turnover and addresses the following questions:

* What talents organisations lose?
* What are the main reasons of losing them?
* What to do differently to retain talents?

To answer these questions, I use a human resource [dataset](https://raw.githubusercontent.com/RongSong1110/WDQ7004/main/aug_train.csv) for Data Scientist positions.

# Data Understanding Stage

Below, we import the dataset into the environment by using the `read_csv` function.
```{r}
data = read_csv("hr_dataset.csv")
``` 

Next we report some descriptive statistics and the structure of the dataset.
```{r}
summary(data)
str(data)
```


The above output shows, that data is imported as a data.frame object, and that it consists of `r nrow(data)` observations and `r ncol(data)` variables, which includes the target variable, called `target`.

The dataset comes with some explanation on the `r ncol(data)` and are as follows:

| feature | feature description |
| :- | :- |
| `enrollee_id` |  Unique ID for candidate |
| `city` |  City code |
| `city_development_index` |  Development index of the city (scaled) |
| `gender` |  Gender of candidate |
| `relevent_experience` |  Relevant experience of candidate |
| `enrolled_university` |  Type of University course enrolled if any |
| `education_level` |  Education level of candidate |
| `major_discipline` |  Education major discipline of candidate |
| `experience` |  Candidate total experience in years |
| `company_size` |  No of employees in current employer's company |
| `company_type` |  Type of current employer |
| `lastnewjob` |  Difference in years between previous job and current job |
| `training_hours` |  training hours completed |
| `target` |  0 – Not looking for job change, 1 – Looking for a job change |

Although the above summary on the variables gives some understanding about what variables stand for, we further want to explore them.

Per the above structure output we see that the variables were imported as either character or numerical variables. First we want to gain understanding on the potential unique values each of the character variables may take on, so that in a later section we can convert them their appropriate and corresponding data type.

## Exploring the character variables

```{r}
categorical_vars = names(Filter(is.character, data))
categorical_data = data[,c(categorical_vars)]

lapply(categorical_data, unique)
```

### `city` {.unlisted .unnumbered}

The `city` variable holds `r length(unique(categorical_data $ city))` unique values, which are identifiers of cities of the current employer. Each value follows the same convention; "city_\<id\>", whereby id stands a unique identifier of the city. In such format, the `city` variable is anonymised, and since the dataset does not provide any information on the geographical location of the city, we cannot attach existing geographical knowledge to it.

### `gender` {.unlisted .unnumbered}

The `gender` variable holds `r length(unique(categorical_data $ gender))` unique values, and stand for the gender of the candidate. The variable takes on the following unique values: `r unique(categorical_data $ gender)`.

### `relevent_experience` {.unlisted .unnumbered}

The `relevent_experience` variable holds `r length(unique(categorical_data $ relevent_experience))` unique values, and stand for whether the candidate has any relevant experience for the job or not. The variable takes on the following unique values: `r unique(categorical_data $ relevent_experience)`. As we can see, the variable in question is binary, a candidate can either have relevant experience or not.

Furthermore, it is worth to remark that both the variable name and the values contain a spelling mistake - this will be taken care of in the [data cleaning and preprocessing](#section_cleaning_preprocessing) section.

### `enrolled_university` {.unlisted .unnumbered}

The `enrolled_university` variable holds `r length(unique(categorical_data $ enrolled_university))` unique values, and stand for type the candidate is or has been enrolled at a university, if any.

The variable can take on the following unique values: `r unique(categorical_data $ enrolled_university)`.

It is also worth to note that the value "no_enrollment" is not consistent with the other 2 type for this variable, namely, it is delimited with underscore and non-capitalised. This inconsistency will be taken care of in the [data cleaning and preprocessing](#section_cleaning_preprocessing) section.

### `major_discipline` {.unlisted .unnumbered}

The `major_discipline` variable holds `r length(unique(categorical_data $ major_discipline))` unique values, and stand for the candidate's major subject, if there is any.

The variable can take on the following unique values: `r unique(categorical_data $ major_discipline)`.

### `experience` {.unlisted .unnumbered}

The `experience` variable holds `r length(unique(categorical_data $ experience))` unique values, and stand for the number of years of experience the candidate has, if any.

The variable can take on the following unique values: `r unique(categorical_data $ experience)`. Whereby, the observation "<1" means a experience less than a year, and ">20", more than 20 years.

### `company_size` {.unlisted .unnumbered}

The `company_size` variable holds `r length(unique(categorical_data $ company_size))` unique values, and stand for the headcount of the company the candidate currently is working for, if any.

The variable can take on the following unique values: `r unique(categorical_data $ company_size)`. Whereby, values such as "<10", stands for a company with less than 10 employees, and "100-500" for a company with headcount between 100 and 500 employees.

It is worth to note, that the values of this variable is inconsistent and deviates from the standard convention of the rest of the variables. This problem will be taken care of in the [data cleaning and preprocessing](#section_cleaning_preprocessing) section.

### `company_type` {.unlisted .unnumbered}

The `company_type` variable holds `r length(unique(categorical_data $ company_type))` unique values, and stand for the type of the company the candidate currently is working for, if any.

The variable can take on the following unique values: `r unique(categorical_data $ company_type)`.

### `last_new_job` {.unlisted .unnumbered}

The `last_new_job` variable holds `r length(unique(categorical_data $ last_new_job))` unique values, and stands for the difference in years between the previous job and current job.

The variable can take on the following unique values: `r unique(categorical_data $ last_new_job)`. Whereby "never" refers to no previous job, and ">4" to the last job being later than 4 years.

It is worth to note, that the value "never" does not necessarily make sense, in case of this variable, and therefore, this will be taken care of in the [data cleaning and preprocessing](#section_cleaning_preprocessing) section.

# Data cleaning and preprocessing {#section_cleaning_preprocessing}

In the previous section, for a few variables a remark was made that it needs to be handled in the current section.

## `relevent_experience` {.unlisted .unnumbered}

First we start correcting the spelling mistake of the column `relevent_experience` to `relevant_experience`.
```{r}
names(data)[names(data) == 'relevent_experience'] = "relevant_experience"
```

Furthermore, for such a binary variable we aim to use a clear notation, to indicate whether the candidate has relevant experience or not. We achieve this by replacing "Has relevent experience" with "yes" and "No relevent experience" with "no" values, so to make later interpretations easier.

```{r}
data $ relevant_experience[data $ relevant_experience == "Has relevent experience"] = "yes"
data $ relevant_experience[data $ relevant_experience == "No relevent experience"] = "no"
```

## `enrolled_university` {.unlisted .unnumbered}

In case of `enrolled_university`, the column values “no_enrollment” contains a mispelling and not consistent with the other 2 values for this variable, namely, it is delimited with underscore and non-capitalised. The below code replaces “no_enrollment” observations with “No enrolment” 

```{r}
data $ enrolled_university[data $ enrolled_university == "no_enrollment"] = "No enrolment"
```

## `company_size` {.unlisted .unnumbered}

The `company_size` variable contains inconsistent and overlapping observations., 

The column value "10/49", should represent an interval, instead of a quotient, and therefore it should be delimited with a dash, instead of forward slash.

Below we replace each "10/49" values with "10-49".
```{r}
data $ company_size[data $ company_size == "10/49"] = "10-49"
```

Furthermore, the intervals of `company_size` should be mutually exclusive values. However, in the case of the following 2 values, "100-500" and "500-999", the "500" is an overlap between the two categories. So, next we replace the "100-500" observations with "100-499". Additionally, the value "10000+" does not follow the convention too, therefore it is replaced with ">9999".

```{r}
data $ company_size[data $ company_size == "100-500"] = "100-499"
data $ company_size[data $ company_size == "10000+"] = ">9999"
```


## `last_new_job` {.unlisted .unnumbered}

The `last_new_job` column contains "never" observations, that expresses that the candidate does not have a previous job. For the sake of later interpretation this value is replaced with "0".

```{r}
data $ last_new_job[data $ last_new_job == "never"] = "0"
```

## `target` {.unlisted .unnumbered}

Lastly, we deal with the target variable, `target`, and change the column name to something more descriptive, e.g., `is_looking_for_job`, representing binary observations, whether the individual is looking to change job or not.

```{r}
names(data)[names(data) == 'target'] = "is_looking_for_job"
```

Furthermore, we replace the current numerical observations with character ones. More specifically, the current '1' values is replaced with "yes" and the '0' with "no".

```{r}
data $ is_looking_for_job[data $ is_looking_for_job == 1] = "yes"
data $ is_looking_for_job[data $ is_looking_for_job == 0] = "no"
```


## Dealing with missing values

The below code reports the percentage of missing values for each feature.

```{r}
(miss_var_summary( data ))
```

We see from the above output, that `company_type`, `company_size`, `gender`, `major_discipline` suffer from a large quantity of missing values. Given the vast amount of missing values, we cannot perform any reliable imputation methods, becuase it would lead to the distortion of data. Instead, we perform a more conservative approach, and that is replace the missing values for these 4 variables by a new value, "unknown".

For the rest of variables that also suffer from missing values, namely `education_level`, `last_new_job`, `enrolled_univeristy`, `experience` we impute them with values drawn randomly from the given variable's underlying distribution.

```{r}
severe_missing_val_cols = c("company_size", "company_type", "gender", "major_discipline")
# non_severe_missing_val_cols = c("education_level", "last_new_job", "enrolled_university", "experience")

for (col_name in severe_missing_val_cols)
{
  data[is.na(data[col_name]), col_name] = "Unknown"
}

# for (col_name in non_severe_missing_val_cols)
# {
#   data[col_name] = impute(select(data, col_name), "random")
# }

data $ education_level = impute(data $ education_level, "random")
data $ last_new_job = impute(data $ last_new_job, "random")
data $ enrolled_university = impute(data $ enrolled_university, "random")
data $ experience = impute(data $ experience, "random")
```
Finally, we report a summary on the imputed values.

Next we double-check if there is still any missing values left in the dataset.
```{r}
any( is.na(data) )
```

The above output shows, that there is no missing value in the dataset, so next we move on with converting the variables to an appropriate data type that suits the vairable best.

## Converting the variables

In this section, we convert the variables to their appropriate data types. The below table summarises the data types of the variables.

| Statistical type of variable | variable |
| :- | :- | 
| numerical continuous | `city_development_index` |
| numerical discrete | `experience`, `training_hours` |
| ordinal | `education_level`, `experience`,  `company_size`, `last_new_job`|
| binary  | `relevant_experience`, `is_looking_for_job` |
| nominal  | `enrollee_id`, `city`, `gender`, `enrolled_university`, `major_discipline`, `company_type` |

```{r}
# convert ordinal variables to ordered factor
educ_ordered_levels = c("Primary School", "High School", "Graduate", "Masters", "Phd")
data $ education_level = factor(data $ education_level, ordered = TRUE, levels = educ_ordered_levels)

experience_ordered_levels = c("<1", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", ">20")
data $ experience = factor(data $ experience, ordered = TRUE, levels = experience_ordered_levels)

comp_size_ordered_levels = c("Unknown", "<10", "10-49", "50-99", "100-499", "500-999", "1000-4999", "5000-9999", ">9999")
data $ company_size = factor(data $ company_size, ordered = TRUE, levels = comp_size_ordered_levels)

last_job_ordered_levels = c("0", "1", "2", "3", "4", ">4")
data $ last_new_job = factor(data $ last_new_job, ordered = TRUE, levels = last_job_ordered_levels)

# convert variables to factor
data $ relevant_experience = as.factor(data $ relevant_experience)
data $ is_looking_for_job = as.factor(data $ is_looking_for_job)

# convert nominal variables to factor
data $ enrollee_id = as.factor(data $ enrollee_id)
data $ city = as.factor(data $ city)
data $ gender = as.factor(data $ gender)
data $ enrolled_university = as.factor(data $ enrolled_university)
data $ major_discipline = as.factor(data $ major_discipline)
data $ company_type = as.factor(data $ company_type)
```

Now that the variables are cleaned up and in the right data type, we report a structure and summary again.

```{r}
summary(data)
str(data)
```


# Exploratory Data Analysis (EDA)

Here we use exploratory methods to delve into the HR dataset for Data Science candidates. We use graphs, plots, and tables to uncover important relationships that could indicate important areas for further investigation. Here we start with the categorical variables then numerical variables.

In this section by using EDA (and if it's need hypothesis testing) we aim to find out which of the `r ncol( churn ) - 1` predictors in the dataset has a relationship with the target variable `is_looking_for_job`. 

## Investigate the target variable `is_looking_for_job`

Here we report a bar plot and summary for the target variable `churn` as follows:

```{r fig.height = 5, fig.width = 5}
ggplot( data = data, aes( x = is_looking_for_job, label = scales::percent( prop.table( stat( count ) ) ) ) ) +
  labs( title = "Bar plot for the target variable 'is_looking_for_job'" ) +
  geom_bar( fill = c( "palevioletred1", "darkseagreen1" ) ) + 
  geom_text( stat = 'count', vjust = 0.2, size = 6 ) + 
  theme_new
```

Summary for the target variable `is_looking_for_job`
```{r}
summary( data $ is_looking_for_job )
```

$P(is\_looking\_for\_job = no) = 14381$

$P(is\_looking\_for\_job = yes) = 4777$

$n = P(is\_looking\_for\_job = no) + P(is\_looking\_for\_job = yes) = 14381 + 4777 = 19158$

$P(is\_looking\_for\_job = yes) = \frac{P(is\_looking\_for\_job = yes)}{n} = \frac{4777}{19158} = 0.1414 = 24.93\%$

Based on the above plot, and calculation, we can conclude that employee turnover after the training was given `r round( summary( data $ is_looking_for_job )[2] / nrow( data ), 4 ) * 100`%. Meaning, that the company is unable to withhold talents `r round( summary( data $ is_looking_for_job )[2] / nrow( data ), 4 ) * 100`% of the cases, and made the investment into the given candidate unnecessarily. 

We can also look the side of the coin, and compute the retention rate, which is the complement of the turnover rate. That is, number of candidates that wants to stay at the company after the training / Total number of candidates = `r round( summary( data $ is_looking_for_job )[1] / nrow( data ), 4 ) * 100`%.

Throught the analysis of below predictors we will try to understand the root causes of the 25% turnover by means of EDA.

## `city`

First we would like to understand which cities are the ones where candidates tend to sign-up for the training the most.

```{r}
summary(data $ city)
```

The above output reports that the dataset contains 123 different city identifiers, out of which the highest number of candidates came from city_103  city_21  city_16 city_114 city_160.

```{r, fig.show = "hold", out.width = "50%", fig.align = 'default' }
ggplot( data = data ) + 
  geom_bar( aes( x = city, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for the target variable 'is_looking_for_job'" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = city, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```

We do not see any clear sign that city clear predictor whether the candidate is going to stay after the training or not.

## `gender`

To understand whether gender is a predictor of whether the candidate is going to stay or not, we first plot it as a regular histogram, with `is_looking_for_job` overlay, and then standardise it, so that we can read the percentages.

```{r, fig.show = "hold", out.width = "50%", fig.align = 'default' }
addmargins( table( data $ is_looking_for_job, data $ gender, dnn = c( "is_looking_for_job", "gender" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = gender, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'gender', with 'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = gender, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

From the above output and plots we read that the gender ratio is mainly dominated by males. Given that the dataset is on Data Science, which technically is an engineering field, it comes as no surprise that it is male dominated, since STEM fields are usually male dominated.

The next group that leads gender is unknown, these are candidates of which gender we do not know, and lastly female and others come in place.

In order to see the turnover rate, we take a look at the standardise the plot from which we read that across the different genders the turn over rate does not deviate from one another. Conclusively, `gender` does not significantly explain the turnover rate, therefore, we do not expect the data mining algorithm to incorporate this into the prediction model.

Next we move on to `relevant_experience`

## `relevant_experience`

```{r}
addmargins( table( data $ is_looking_for_job, data $ relevant_experience, dnn = c( "is_looking_for_job", "relevant_experience" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = relevant_experience, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'relevant_experience', with 'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = relevant_experience, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

From the above contingency table we read, that 5366 candidates doesn't have any relevant experience on the field of data science, while the rest of the candidates (13792) do. This means, that there are approximately 2.5 more candidates signing up for the training with relevant experience than those without. This take away, is clear form the first bar plot as well, where those with relevant experience are 2.5 more than those without.

In order to see the tendency of a candidate to look for new opportunity, we read the standardised plot and conclude the tendency among those without experience to leave the job after the training is higher than for those with experience. More precisely, those without experience tend to leave the company approximately 35% of the times, while those with experience it is much smaller, approximately 20%.

Given that the 15% difference in the tendency is significant, we can expect the data mining algorithm to incorporate this variable into the prediction model.

Next we move on with the `enrolled_university` variable.

## `enrolled_univeristy`

```{r}
addmargins( table( data $ is_looking_for_job, data $ enrolled_university, dnn = c( "is_looking_for_job", "enrolled_university" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = enrolled_university, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'enrolled_university', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = enrolled_university, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

From the above contingency table we read, that those without any university qualification rule the dataset. Next, it is those with a full-time degree and lastly those who followed a part time course at university.

To see the difference in turnover rate between the different groups, we read the standardised bar plot, and report that those with a full time degree tend to leave the company the most with approximately 37.5% of the times. This result may be understandable, since employers still appreciate candidates with proper former education, and hence those with a full time degree has more opportunities than those without, or with part time degree.

The turnover rate is approximately the same for those without a degree and those with a part time one; that is, approximately 22-25%. Given the large deviation in turnover rate between those with full time degree and the rest of the dataset, we can expect the data mining algorithm to incorporate `enrolled_university` to the prediction model.

Next we move on with `education_level`.

## `education_level`

```{r}
addmargins( table( data $ is_looking_for_job, data $ education_level, dnn = c( "is_looking_for_job", "education_level" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = education_level, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'education_level', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = education_level, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```

From the above plots we read, that those with graduate degree (bachelor) has the highest weight in the dataset. Meaning, they have the highest frequency in the dataset. Next, those with Masters degree, and after it those with high school degree, and the rest are primary schoolers and Phds.

Given that `education_level` is an ordinal variable, it is peculiar to see the rough normality, and symmetry in the data. That is, most of the candidates in the dataset hold a graduate degree, while towards the tails of the distribution is of those with significantly lower and higher qualifications.

To see the proportion of turnover for each of the education levels, we read the standardised plot kept its approximate symmetric shape and see that those with graduate degree tend to change job most likely, by more than 25%, while the rest of them change with a likeliness of less than 25%. Those with High school degrees change jobs approximately with the same frequency as that of with Masters degree, that is approximately 20%. Similarly, those with primary school degree change jobs approximately as frequently as Phd degree holders, that is 13%.

We may argue why the standardised plot kept its symmetric shape in a way that those with a standard bachelor degree is fairly flexible to still specialise to a certain part of Data Science and hence has more opportunities to change job. Those with higher or lower qualifications, are fairly restricted/specialised to a certain field of Data Science, and hence has less opportunities, or higher remuneration and hence it is not worth to look for new opportunities.

Since, the above plots indicate strong graphical evidence of education level may be important for prediction, we can expect the data mining algorithm to incorporate it into the prediction model.

Next, we move on with the variable `major_discipline`.

## `major_discipline`

```{r}
addmargins( table( data $ is_looking_for_job, data $ major_discipline, dnn = c( "is_looking_for_job", "major_discipline" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = major_discipline, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'major_discipline', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = major_discipline, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```

From the above outputs we read, that those with STEM (Science, technology, engineering, and mathematics) qualification rules the dataset. This is expected, since Data Science is typically a STEM related field. The second largest group of candidates in terms of major discipline is those with unknown major discipline.

To see the turnover rate between different major disciplines, we read the standardised plot and find that there is hardly any difference between the turnover rate. Since there is no strong graphical evidence of the predictive importance of `major_discipline`, we do not expect this variable to be incorporated in the prediction model.

Next we move on with `experience`.

## `experience`

```{r}
addmargins( table( data $ is_looking_for_job, data $ experience, dnn = c( "is_looking_for_job", "experience" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = experience, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'experience', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = experience, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```
The above plots show, that those with experience between 2 to 7 years and those with more than 20 years of experience are in majority. To see the turnover rate between the difference experience level, we read the standardised plot. The standardised plot shows that the higher more experience the candidate has the less likely he/she will look for a new job. There is a strong graphical indication of `experience` being an important predictor of the turnover rate, therefore we can expect this variable to be included in the prediction model by the data mining algorithm.

Next we move on with `company_size`.

## `company_size`

```{r}
addmargins( table( data $ is_looking_for_job, data $ company_size, dnn = c( "is_looking_for_job", "company_size" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = company_size, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'company_size', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = company_size, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```

The above plots show that those with unknown current employer's size rule the data, alongside with companies of size 50-99, 100-499 and those of massive companies with headcount more than 9999.

To observe the turnover rate between the different categories, we read the standardised plot, and see that those with unknown company size tend to look for a job the most. Between the known headcount, those with 10-49 stand out from the rest, by tending to look for a job approximately 20% of the times.

We see no strong graphical indication of `company_size` would be an important predictor therefore, we do not expect it to be incorporated in the prediction model.

Next we move on with `company_type`.

## `company_type`

```{r}
addmargins( table( data $ is_looking_for_job, data $ company_type, dnn = c( "is_looking_for_job", "company_type" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = company_type, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'company_type', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = company_type, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```

The above plots shows that the majority of the candidate's currently employer are either unknown or of private limited company. To see the turnover rate per company type, we observe the standardised plot, and see that those with unkonwn company type tend to look for job. The rest of the company types are all below the whole dataset's turnover rate, therefore, we do not see strong indication of `company_type` being a predictor of turnover rate.

Next we move on with `last_new_job`.

## `last_new_job`
```{r}
addmargins( table( data $ is_looking_for_job, data $ last_new_job, dnn = c( "is_looking_for_job", "last_new_job" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = last_new_job, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'last_new_job', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = last_new_job, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```

The above plots show that those who never had a job before, and those who changed there job 1, 2 and more than years ago are in majority. The standardised graph shows, that the more one stays at a specific work place the less likely will change job. That is, there is a declining tendency of turnover rate as the last job is farther apart.


The above plots show that International Plan holders (`intl.plan="yes"`) tend to churn more frequently, but they do not *quantify* the relationship. The above contingency table quantify the relationship between International Plan holding and churning, Since both variables are categorical. We should consider using International Plan as one of the predictor variables in whatever machine learning algorithms we use to predict churn.

## Investigate variable "*voice mail plan*"

Make a table for counts of Churn and Voice Mail Plan

```{r}
table( churn $ churn, churn $ voice.plan, dnn = c( "Churn", "Voice Mail Plan" ) )
```

Bar chart for Voice Mail Plan

```{r, fig.show = "hold", out.width = "50%", fig.align = 'default' }
ggplot( data = churn ) + 
  geom_bar( aes( x = voice.plan, fill = churn ) ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new

ggplot( data = churn ) + 
  geom_bar( aes( x = voice.plan, fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

The results above indicate that:

* It seems that Voice Mail Plan increases customers' loyalty. Thus, we should consider enhancing our Voice Mail Plan.
* We should consider using Voice Mail Plan as one of the predictor variables in whatever machine learning algorithms we use to predict churn. Our confidence in this expectation is perhaps not as high as for the International Plan. 

## Detect Correlated Variables 

To visualize the correlation matrix between the numerical variables: `day.mins`, `day.calls`, `day.charge`, `eve.mins`, `eve.calls`, `eve.charge`, `night.mins`, `night.calls`, and `night.charge`, we could use the `ggcorr()` function as follows

```{r}
variable_list = c( "intl.mins",  "intl.calls",  "intl.charge", 
                   "day.mins",   "day.calls",   "day.charge",
                   "eve.mins",   "eve.calls",   "eve.charge",
                   "night.mins", "night.calls", "night.charge" )

ggcorr( data = churn[ , variable_list ], label = TRUE ) 
```

The correlation matrix plots indicate that there are strong positive correlation (`r=+1`) between the following variables:

* `day.mins` and `day.charge`;
* `eve.mins` and `eve.charge`;
* `night.mins` and `night.charge`.

And the rest of the correlations are zero. It indicates that we should *not* include the variables `day.charge`, `eve.charge`, and `night.charge` in whatever machine learning algorithms we use to predict churn.

## Investigate variable "*Day Minutes*"

To investigate the relationship between variable "*Day Minutes*", since the variable "*Day Minutes*" is numerical, we report the boxplot and density as follows

```{r}
ggplot( data = churn ) +
  geom_boxplot( aes( x = churn, y = day.mins ), fill = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

```{r}
ggplot( data = churn ) +
  geom_density( aes( x = day.mins, fill = churn ), alpha = 0.3 ) + 
  theme_new
```

The results above indicate that:

* We should carefully track customer Day Minutes as total exceeds 200. Investigate why those with high usage tend to leave.
* We should consider using variable "*Day Minutes*" as one of the predictor variables in whatever machine learning algorithms we use to predict churn.  

## Investigate variable "*Evening Minutes*"

To investigate the relationship between variable "*Evening Minutes*", since the variable "*Evening Minutes*" is numerical, we report the boxplot and density as follows

```{r}
ggplot( data = churn ) +
  geom_boxplot( aes( x = churn, y = eve.mins ), fill = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

```{r}
ggplot( data = churn ) +
  geom_density( aes( x = eve.mins, fill = churn ), alpha = 0.3 ) + 
  theme_new
```

The above plots do not indicate graphical evidence of the predictive importance of *Evening Minutes*. Thus, we apply the following hypothesis testing for dependency between variables *Evening Minutes* and *churn* 

```{r}
t.test( eve.mins ~ churn, data = churn )
```

Since the P-value = ```r t.test( intl.calls ~ churn, data = churn )$p.value``` is less than $\alpha$=0.05, thus we reject the $H_0$. 
It means the difference in the mean number of evening minutes for churners and non-churners is statistically significant. Thus, variable "*Evening Minutes*" is useful for predicting churn.

We applied the same Hypothesis testing for the variable "*Night Minutes*", to check its dependency with variables *churn*. And the result indicates that the variable "*Night Minutes*" is also useful for predicting churn.

## Investigate variable "*Day Calls*" 

Here, we are interested to investigate the relationship between variable Day Calls and the target variable `churn`. To investigate the relationship between variable "*Day Calls*", since the variable "*Day Calls*" is numerical, we report the boxplot and density as follows

```{r}
ggplot( data = churn ) +
  geom_boxplot( aes( x = churn, y = day.calls ), fill = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

```{r}
ggplot( data = churn ) +
  geom_density( aes( x = day.calls, fill = churn ), alpha = 0.3 ) + 
  theme_new
```

The above plots do not indicate graphical evidence of the predictive importance of Day Calls. However, a t-test (see below) for the difference in the mean number of day calls for churners and non-churners. Hypothesis testing for dependency between variables *Day Calls* and *churn* 

```{r}
t.test( day.calls ~ churn, data = churn )
```

Since the P-value = ```r t.test( day.calls ~ churn, data = churn )$p.value``` is higher than $\alpha$=0.05, thus we do not reject the $H_0$. 
It means the difference in the mean number of international calls for churners and non-churners is not statistically significant. Thus, variable "*Day Calls*" is not useful for predicting churn.

We applied the same Hypothesis testing for the variables "*Evening Calls*" and "*Night Calls*", to check their dependencies with variables *churn*. And the result indicates that these two variables also are not useful for predicting churn.

## Investigate variable "*International Calls*" 

Here, we are interested to investigate the relationship between variable International Calls and the target variable `churn`. To see the relationship between variable International Calls and the target variable *churn*, we report the histogram of variable International Calls including Churn overlay as follow

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = intl.calls, fill = churn ), position = "stack" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

We also report the *Normalized* histogram of variable International Calls including Churn overlay as follow

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = intl.calls, fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

To see the relationship between variable International Calls and the target variable *churn*, we report the boxplot as follow

```{r}
ggplot( data = churn ) +
  geom_boxplot( aes( x = churn, y = intl.calls ), fill = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

The above plots do not indicate strong graphical evidence of the predictive importance of International Calls. However, a t-test (see below) for the difference in the mean number of international calls for churners and non-churners is statistically significant (p-value = 0.003; p-values larger than, say, 0.10 are not considered significant), meaning that this variable is indeed useful for predicting churn: Churners tend to place a lower mean number of international calls. Thus, had we omitted International Calls from the analysis based on the seeming lack of graphical evidence, we would have committed a mistake, and our predictive model would not perform as well.

Hypothesis testing for dependency between variables *International Calls* and *churn* 

```{r}
t.test( intl.calls ~ churn, data = churn )
```

Since the P-value = ```r t.test( intl.calls ~ churn, data = churn )$p.value``` is less than $\alpha$=0.05, thus we reject the $H_0$. 
It means the difference in the mean number of international calls for churners and non-churners is statistically significant. Thus, variable "*International Calls*" is useful for predicting churn.

## Investigate variable "*customer service calls*" 

Here, we are interested to investigate the relationship between variable "*customer service calls*" and the target variable "*churn*". To see the relationship between variable "*customer service calls*" and the target variable "*churn*", we report the histogram of the variable "*customer service calls*" including "churn" overlay as follows

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = factor( customer.calls ), fill = churn ), position = "stack" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

We also report the *Normalized* histogram of variable "*customer service calls*" including "churn" overlay as follow

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = factor( customer.calls ), fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

The results above indicate that:

* We should carefully track the number of customer service calls made by each customer. By the third call, specialized incentives should be offered to retain customer loyalty, since, by the fourth call, the probability of churn substantially increases. 
* We should consider using variable "*customer service calls*" as one of the predictor variables in whatever machine learning algorithms we use to predict churn. 


# Data Preparation

In this stage we want to prepare the dataset for modeling. Here, we partition the *churn* dataset randomly into two groups: train set (80%) and test set (20%). Here, we use the `partition()` function from the *liver* package:

```{r}
set.seed( 5 )

data_sets = partition( data = churn, prob = c( 0.8, 0.2 ) )

train_set = data_sets $ part1
test_set  = data_sets $ part2

actual_test  = test_set $ churn
```
Note that here we are using the `set.seed()` function to create reproducible results. 

We validate the partition by testing whether the proportion of the target variable `churn` differs between the two data sets. We use a Two-Sample Z-Test for the difference in proportions. A Two-sample z-test is suitable here, mainly because we want to compare the proportion of the customers who paid for the *churn* between the two groups (“training set” and “test set”). The hypotheses are as follows
\[
\bigg\{
\begin{matrix}
          H_0:  \pi_{churner,\ train}   =  \pi_{churner,\ test} \\
          H_a:  \pi_{churner,\ train} \neq \pi_{churner,\ test}
\end{matrix}
\]

To validate the partitions, we run a hypothesis test to check the proportion of the target variable `churn` in the train and test sets. To run the test, we use the `prop.test` function in **R**:
```{r}
x1 = sum( train_set $ churn == "yes" )
x2 = sum( test_set  $ churn == "yes" )

n1 = nrow( train_set )
n2 = nrow( test_set  )

prop.test( x = c( x1, x2 ), n = c( n1, n2 ) )
```

We don't reject the $H_0$, since the *p*-value is higher than $\alpha=0.05$. Thus, the difference in the proportion of the costumers who paid for the *churn*  is not statistically significant between the two groups (“training set” and “test set”). **It indicates that the partition for the target variable `churn` is valid.**

# Modeling - Classification

The results form the "Exploratory Data Analysis (EDA)" section indicate that the following predictors from `r ncol( churn ) - 1` predictors in the *churn* dataset are important to predict churn.

`voice.plan`, `voice.messages`, `intl.plan`, `intl.mins`, `intl.calls`, `day.mins`, `eve.mins`, `night.mins`, and `customer.calls`. 

Thus, here, based on the training dataset, we want to apply different type of Machine Learning algorithms, by using above predictors in our model. We use the following formula:
```{r}
formula = churn ~ voice.plan + voice.messages + intl.plan + intl.mins + intl.calls +
                  day.mins + eve.mins + night.mins + customer.calls
```

## Classificaiton with the k-nearest neighbor algorithm

To find out the optimal value of `k` based on *Error Rate*, for the different values of k from 1 to 20, we run the k-nearest neighbor for the test set and compute the *Error Rate* for these models, by running `kNN.plot()` command 

```{r fig.align = 'center'}
kNN.plot( formula, train = train_set, test = test_set, transform = "minmax", k.max = 20, set.seed = 3 )
```

The plot shows that the minimum value of *Error Rate* is for the case that `k = 5`. Since the smaller values of *Error Rate* indicates better predictions, in this case, the optimal value of `k` would be `5`.

Now, to find the k-nearest neighbor for the test data set for the case `k = 5`, we use `kNN()` command: 
```{r}
predict_knn = kNN( formula, train = train_set, test = test_set, transform = "minmax", k = 5 )
```
Note that the `transform = "minmax"` input specifies that we are using min-max normalization to transfer the predictors.

## Classificaiton with Decision Tree by CART algorithm

We produce a decision tree based on the CART algorithm by using the `rpart` function from the [**rpart**](https://CRAN.R-project.org/package=rpart) package:

```{r}
tree_cart = rpart( formula, data = train_set, method = "class" )
```

To plot the decision tree, we use the `rpart.plot` function from the [**rpart.plot**](https://CRAN.R-project.org/package=rpart.plot) package:

```{r, fig.height=6, fig.width=10}
rpart.plot( tree_cart, type = 4, extra = 104 )
```

## Classificaiton with Decision Tree by C50 algorithm

We produce a decision tree based on the C5.0 algorithm by using the `C5.0` function from the [**C50**](https://CRAN.R-project.org/package=C50) package:

```{r}
tree_C50 = C5.0( formula, data = train_set ) 
```

Since the tree from the **C5.0 algorithm** is relatively large to visualize, we use the function `summary` as follows
```{r}
summary( tree_C50 )
```

## Classificaiton with Random Forest

*CART* and *C5.0* algorithms both produce a single decision tree based on all of the records, and the specified variables, in the training data set. On the other hand, *random forest* algorithm builds a series of decision trees and combine the trees disparate classifications of each record into one final classification. 

We run the *random forest* algorithm, using the `randomForest` function from the [**randomForest**](https://CRAN.R-project.org/package=randomForest) package:

```{r}
random_forest = randomForest( formula = formula, data = train_set, ntree = 100 )
```

Now, you may ask what would be a suitable value for the number of trees! In that case, in the following plot, you can see that if the number of trees is higher than around 40, we have a minimum error. 

```{r}
plot( random_forest )
```

We can visualize the dot-chart of variable importance as measured by the *random forest* algorithm as follow
```{r}
varImpPlot( random_forest )
```

## Classificaiton with Logistic Regression 

To run the logistic regression model, we will use the `glm()` command:
```{r}
logreg = glm( formula, data = churn, family = binomial )
```

To view the summary of the model, run the `summary()` command with the name of the saved model as the sole input. 
```{r}
summary( logreg )
```

# Model Evaluation

Based on our results so far, which of the above five classification algorithms are more suitable here for the *churn* dataset? To answer this question, here, we report the ROC curves as well as AUC for the above classification algorithms as follows:

```{r fig.align='center'}
prob_cart = predict( tree_cart, test_set, type = "prob" )[ , 1 ]
prob_C50  = predict( tree_C50,  test_set, type = "prob" )[ , 1 ]

prob_random_forest = predict( random_forest, test_set, type = "prob" )[ , 1 ]

prob_knn = kNN( formula, train = train_set, test = test_set, transform = "minmax", k = 13, type = "prob" )[ , 1 ]

prob_logreg  = predict( logreg,  test_set, type = "response" )

roc_knn = roc( actual_test, prob_knn )
roc_cart = roc( actual_test, prob_cart )
roc_C50 = roc( actual_test, prob_C50 )
roc_random_forest = roc( actual_test, prob_random_forest )
roc_logreg = roc( actual_test, prob_logreg )

ggroc( list( roc_knn, roc_cart, roc_C50, roc_random_forest, roc_logreg ), size = 0.8 ) + 
    theme_minimal() + ggtitle( "ROC plots with AUC for 4 outcomes") +
  scale_color_manual( values = 1:5, 
    labels = c( paste( "KNN; AUC=", round( auc( roc_knn ), 3 ) ),
                paste( "CART; AUC=", round( auc( roc_cart ), 3 ) ), 
                paste( "C50; AUC=", round( auc( roc_C50 ), 3 ) ), 
                paste( "Random Forest; AUC=", round( auc( roc_random_forest ), 3 ) ),
                paste( "Log Reg; AUC=", round( auc( roc_logreg ), 3 ) )
                ) ) +
  theme( legend.title = element_blank() ) +
  theme( legend.position = c( .7, .3 ), text = element_text( size = 17 ) )
```

Based on the above ROC curves and the values of AUC, the "*Random Forest*" algorithm has slightly better performance, since it has the highest value of AUC. 




