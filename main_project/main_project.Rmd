---
title: '<center> How to increase employee retention in the field of Data Science <center>'
author: '<center> Peter Molnar <center>'
date: '<center> `r Sys.Date()` <center>'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 5
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk $ set( echo = TRUE, message = FALSE, warning = FALSE, error = FALSE, fig.align = 'center'  )
```

```{r}
# dependencies
library( liver )          # For dataset 'churn'

library( ggplot2 )        # For visualization
library( GGally )         # For correlation plots
library( psych )          # For correlation plots  

library( rpart )          # For the "CART" algorithm
library( rpart.plot )     # To plot decision trees
library( C50 )            # For the "C5.0" algorithm
library( randomForest )   # For the "Random Forest" algorithm

library( pROC )           # For ROC plot

library(readr)            # For the read_csv function

library( naniar  )        # for missing value plotting
library( Hmisc  )         # for imputation
library( dplyr  )         # for select function
data(churn)
```

```{r results = FALSE, echo = FALSE }
# To ensure consistent formatting of the plots, we are using a colour theme:
theme_new = theme( panel.background = element_rect( fill = "white", colour = "white", size = 0.5, linetype = "solid" ),
                   panel.grid.major = element_line( size = 0.2, linetype = 'solid', colour = "gray77" ), 
                   panel.grid.minor = element_line( size = 0.1, linetype = 'solid', colour = "gray90" ),
                   axis.text  = element_text( size = 11 ), 
                   axis.title = element_text( size = 12, face = "bold" ),
                   title = element_text( size = 14, face = "bold" )
                  )
```

# Business Understanding Stage

## General understanding of the problem

Employee turnover refers to the event of replacing current employees with new ones. Employee acquisition is a long and costly procedure; a given position needs to be advertised, multiple candidates be selected and have to go through multiple rounds of interviews. Hence turnover is one of the most persistent and frustrating problems that organisations have long been facing.

Whether it is involuntary, such as termination due to poor performance, or voluntary, such as resignations, turnover is extremely costly.

According to a conservative estimates by the Bureau of Labor Statistics, on average an employee replacement costs approximately \$13,996 per employee. However, this amount for the Information Technology (IT) sector on average reaches \$20,000 per employee. As the economy grows, more jobs, and therefore opportunities are created, and therefore voluntary turnover also increases. 

Organisations tend to underestimate the true cost of turnover, and hence does not focus on employee retention probperly. This may be because, turnover is not an accountable line-item in most profit and loss statements, nor is it typically defined in the budget, not to mention that no one submits an invoice at the end of the month for turnover.

In addition to the explicit replacement fees, there are implicit costs as well, such as productivity loss, workplace safety issues, and morale damage to the company, that further deepens the severety of employee turnover.

Since there is not much organisations can do to dramatically reduce the costs associated with turnover, the best measure is to reduce turnover directly by an improved selection process that assesses candidates' turnover risk, motivational fit early in the hiring process. Such hiring process helps to reduce turnover, and can lead to a safer, more productive and profitable work place.

## Dataset description

The selected dataset, ["HR Analytics: Job Change of Data Scientists"](https://www.kaggle.com/datasets/arashnic/hr-analytics-job-change-of-data-scientists), is on a Big Data and Data Science specialised company, that seeks to hire candidates. The company implemented a series of training courses, that anyone could sign-up, and upon completion the candidate is offered a position. The dataset contains information about the candidates’ demographics, education, experience that are collected during the sign-up process for the training. By that, the company aims to narrow down candidates to only those who are really interested to work for the company, and identify those who are likely to opt out after the training was given.

This paper aims to identify factors associated with employee turnover, and employees who are likely to be open for new opportunities after the training given.

* What are the talents that the organisation attracted?
* What are the key factors of employee turnover?
* What to do differently to retain talents?

# Data Understanding Stage

Below, we import the dataset into the environment by using the `read_csv` function.
```{r}
data = read_csv("hr_dataset.csv")
``` 

Next we report some descriptive statistics and the structure of the dataset.
```{r}
summary(data) # descriptive statistics
str(data)     # structure of the data
```

The above outputs shows, that data is imported as a data.frame object, and that it consists of `r nrow(data)` rows and `r ncol(data)` columns/variables. The `r ncol(data)` variables includes the target variable, called identified by the variable called `target`.

The [official dataset](https://www.kaggle.com/datasets/arashnic/hr-analytics-job-change-of-data-scientists) delivers some explanation to the features:

| Feature | Feature description |
| :- | :- |
| `enrollee_id` |  Unique ID for candidate |
| `city` |  City code |
| `city_development_index` |  Development index of the city (scaled) |
| `gender` |  Gender of candidate |
| `relevent_experience` |  Relevant experience of candidate |
| `enrolled_university` |  Type of University course enrolled if any |
| `education_level` |  Education level of candidate |
| `major_discipline` |  Education major discipline of candidate |
| `experience` |  Candidate total experience in years |
| `company_size` |  No of employees in current employer's company |
| `company_type` |  Type of current employer |
| `lastnewjob` |  Difference in years between previous job and current job |
| `training_hours` |  training hours completed |
| `target` |  0 – Not looking for job change, 1 – Looking for a job change |

Although, the official summary on the variables gives some understanding about what the different variables stand for, in the coming section we further delve into them.

## Exploring variables

The above structure output reports that the following variables are imported as character variables:
`city`, `gender`, `relevent_experience`, `enrolled_university`, `education_level`, `major_discipline`, `experience`, `company_size`, `company_type`, `last_new_job`, and the followings as numerical variables: `city_development_index`, `enrollee_id`, `target`, `training_hours`.

In this section, first we aim to gain understanding on the potential unique values each of the character variables may take on. By knowing this, in a later section ([data cleaning and preprocessing](#section_cleaning_preprocessing)) can better clean up and convert the data to the corresponding data type.

```{r}
categorical_vars = names(Filter(is.character, data)) # filter out column names with type character
categorical_data = data[,c(categorical_vars)] # select columns of type character

lapply(categorical_data, unique) # iterate through the selected columns, and report the unique values
```

### `city` {.unlisted .unnumbered}

The `city` variable holds `r length(unique(categorical_data $ city))` unique values, which are identifiers of cities of the candidate's current employer. Each value follows the same naming convention; `city_<id>`, whereby id stands for a unique numerical identifier of the city. In such format, the `city` variable is anonymised, and since the dataset does not provide any information on the geographical location of the city, we cannot attach existing geographical knowledge to it.


### `gender` {.unlisted .unnumbered}

The `gender` variable holds `r length(unique(categorical_data $ gender))` unique values, and stand for the gender of the candidate. The variable takes on the following unique values: `r unique(categorical_data $ gender)`.

### `relevent_experience` {.unlisted .unnumbered}

The `relevent_experience` variable holds `r length(unique(categorical_data $ relevent_experience))` unique values, and stands for whether the candidate has any relevant experience for the job or not. The variable takes on the following unique values: `r unique(categorical_data $ relevent_experience)`.

Based on the above unique values, we classify `relevent_experience` as a binary variable; that is, a candidate can either have relevant experience or not. Therefore, in a later section, this variable will be converted into a factor of 2 levels.

Furthermore, it is worth to remark that both the variable name and the values contain a spelling mistake - this will be taken care of in the [data cleaning and preprocessing](#section_cleaning_preprocessing) section.


### `enrolled_university` {.unlisted .unnumbered}

The `enrolled_university` variable holds `r length(unique(categorical_data $ enrolled_university))` unique values, and stands for type of the university program the candidate was enrolled to, if any.

The variable can take on the following unique values: `r unique(categorical_data $ enrolled_university)`.

As a remark, the observations "no_enrollment" is not consistent with the rest of the values' naming convention. It is delimited with underscore and non-capitalised. Therefore, this inconsistency will be taken care of in the [data cleaning and preprocessing](#section_cleaning_preprocessing) section.


### `major_discipline` {.unlisted .unnumbered}

The `major_discipline` variable holds `r length(unique(categorical_data $ major_discipline))` unique values, and stands for the candidate's major studies, if any.

The variable can take on the following unique values: `r unique(categorical_data $ major_discipline)`.


### `experience` {.unlisted .unnumbered}

The `experience` variable holds `r length(unique(categorical_data $ experience))` unique values, and stands for the number of years of experience the candidate has, if any.

The variable can take on the following unique values: `r unique(categorical_data $ experience)`. As a clarification, the observation "<1" means less than a year of work experience, and ">20", more than 20 years in duty.


### `company_size` {.unlisted .unnumbered}

The `company_size` variable holds `r length(unique(categorical_data $ company_size))` unique values, and stands for the headcount of the company the candidate is currently working for, if any.

The variable can take on the following unique values: `r unique(categorical_data $ company_size)`. The values such as "<10", stands for a company with less than 10 employees, and "100-500" for an organisation with headcount between 100 and 500 employees.

It is worth to note, that the values of this variable is inconsistent and deviates from the standard convention of the rest of the variables. This problem will be addressed in the [data cleaning and preprocessing](#section_cleaning_preprocessing) section.

### `company_type` {.unlisted .unnumbered}

The `company_type` variable holds `r length(unique(categorical_data $ company_type))` unique values, and stand for the type of the company the candidate currently is working for, if any.

The variable can take on the following unique values: `r unique(categorical_data $ company_type)`.


### `last_new_job` {.unlisted .unnumbered}

The `last_new_job` variable holds `r length(unique(categorical_data $ last_new_job))` unique values, and stands for the difference in years between the previous job and current job.

The variable can take on the following unique values: `r unique(categorical_data $ last_new_job)`. Whereby "never" refers to no previous job, and ">4" to the last job being later than 4 years.

Here as well a remark to be made, that the value "never" does not necessarily align with the other numerical values, and therefore, this will be taken care of in the [data cleaning and preprocessing](#section_cleaning_preprocessing) section.



# Data cleaning and preprocessing {#section_cleaning_preprocessing}

## `enrollee_id`
Since `enrollee_id` is a unique identifier of each of the candidates that signed-up for the training, it carries no valuable information on the candidate, and therefore it is redundant in the dataset, hence it is removed.

```{r}
col_idx = match( "enrollee_id", names(data) ) # get column index position of 'enrollee_id'
data = data[, -col_idx]                       # remove enrollee_id column from dataset
```


## `relevent_experience` {.unlisted .unnumbered}

Per mentioned above, th `relevent_experience` contains a spelling mistake and hence is replaced with "relevant_experience".
```{r}
names(data)[names(data) == 'relevent_experience'] = "relevant_experience"
```

Furthermore, for such a binary variable we aim to use a clear notation, to indicate whether the candidate has relevant experience or not. We achieve this by replacing "Has relevent experience" with "Yes" and "No relevent experience" with "No" values, so to make later interpretations easier.

```{r}
data $ relevant_experience[data $ relevant_experience == "Has relevent experience"] = "Yes"
data $ relevant_experience[data $ relevant_experience == "No relevent experience"] = "No"
```


## `enrolled_university` {.unlisted .unnumbered}

In case of `enrolled_university`, the column values “no_enrollment”, not only contains a spelling mistake, but also inconsistent with the other 2 values for this variable. I.e., it is delimited with underscore and non-capitalised. The below code replaces “no_enrollment” observations with “No enrolment” 
```{r}
data $ enrolled_university[data $ enrolled_university == "no_enrollment"] = "No enrolment"
```


## `company_size` {.unlisted .unnumbered}

The `company_size` variable contains inconsistent and overlapping observations. The value "10/49", should represent an interval, instead of a quotient, and therefore it should be delimited with a dash, instead of forward slash.

Below we replace each "10/49" values with "10-49".
```{r}
data $ company_size[data $ company_size == "10/49"] = "10-49"
```

Furthermore, the intervals of `company_size` should be mutually exclusive values. However, in the case of the following 2 values, "100-500" and "500-999", the "500" overlaps between the two categories. So, next we replace the "100-500" observations with "100-499". Additionally, the value "10000+" does not follow the convention either, so it is replaced with ">9999".

```{r}
data $ company_size[data $ company_size == "100-500"] = "100-499"
data $ company_size[data $ company_size == "10000+"] = ">9999"
```


## `last_new_job` {.unlisted .unnumbered}

The `last_new_job` column contains the observation "never", that expresses that the candidate never had a job. For the sake of following the convention, and keep the data as numeric as possible, this value is replaced with "0".

```{r}
data $ last_new_job[data $ last_new_job == "never"] = "0"
```

## `target` {.unlisted .unnumbered}

Lastly, the target variable, `target`, is not explanatory for the dataset. Therefore, we change the column name to something more descriptive, e.g., `is_looking_for_job`, representing binary observations, whether the individual is looking to change job or not.

```{r}
names(data)[names(data) == 'target'] = "is_looking_for_job"
```

Furthermore, we replace the current numerical observations with character ones. More specifically, the '1' with "yes" and the '0' with "no".

```{r}
data $ is_looking_for_job[data $ is_looking_for_job == 1] = "yes"
data $ is_looking_for_job[data $ is_looking_for_job == 0] = "no"
```


## Dealing with missing values

The below code reports the percentage of missing values for each variable.

```{r}
(miss_var_summary( data ))
```

We see from the above output, that `company_type`, `company_size`, `gender`, `major_discipline` suffer from a large quantity of missing values. Given the vast amount of missing values, we cannot perform any reliable imputation methods, therefore, we perform a more conservative approach, and introduce a new value, "unknown".

```{r}
severe_missing_val_cols = c("company_size", "company_type", "gender", "major_discipline")

for (col_name in severe_missing_val_cols)
{
  data[is.na(data[col_name]), col_name] = "Unknown"
}
```

The other variables that also suffer from missing values, are  `education_level`, `last_new_job`, `enrolled_univeristy`, `experience` we impute them with values which is proportional to categories’ records.

```{r}
data $ education_level = impute(data $ education_level, "random")
data $ last_new_job = impute(data $ last_new_job, "random")
data $ enrolled_university = impute(data $ enrolled_university, "random")
data $ experience = impute(data $ experience, "random")
```

Next, we report a summary on the imputed values.
```{r}
imputed_vars = c("education_level", "last_new_job", "enrolled_university", "experience")

for (var in imputed_vars)
{
  print(var)
  summary(data[var])
}
```

Finally, we confirm if there is still any missing values left in the dataset.
```{r}
any( is.na(data) )
```

The above output shows, that there is no missing left in the dataset, so as a next step in the data cleaning and preprocessing, we move on with converting the variables to their appropriate data type.

## Converting the variables

Below the table summarises the data types of the variables.

| Statistical type of variable | variable |
| :- | :- | 
| numerical continuous | `city_development_index` |
| numerical discrete | `training_hours` |
| ordinal | `education_level`, `experience`, `company_size`, `last_new_job`|
| binary  | `relevant_experience`, `is_looking_for_job` |
| nominal  | `city`, `gender`, `enrolled_university`, `major_discipline`, `company_type` |

```{r}
# convert ordinal variables to ordered factor
educ_ordered_levels = c("Primary School", "High School", "Graduate", "Masters", "Phd")
data $ education_level = factor(data $ education_level, ordered = TRUE, levels = educ_ordered_levels)

experience_ordered_levels = c("<1", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", ">20")
data $ experience = factor(data $ experience, ordered = TRUE, levels = experience_ordered_levels)

comp_size_ordered_levels = c("Unknown", "<10", "10-49", "50-99", "100-499", "500-999", "1000-4999", "5000-9999", ">9999")
data $ company_size = factor(data $ company_size, ordered = TRUE, levels = comp_size_ordered_levels)

last_job_ordered_levels = c("0", "1", "2", "3", "4", ">4")
data $ last_new_job = factor(data $ last_new_job, ordered = TRUE, levels = last_job_ordered_levels)

# convert variables to factor
data $ relevant_experience = as.factor(data $ relevant_experience)
data $ is_looking_for_job = as.factor(data $ is_looking_for_job)

# convert nominal variables to factor
data $ city = as.factor(data $ city)
data $ gender = as.factor(data $ gender)
data $ enrolled_university = as.factor(data $ enrolled_university)
data $ major_discipline = as.factor(data $ major_discipline)
data $ company_type = as.factor(data $ company_type)
```

Now that the data is cleaned up and the variables are in the right type, we report the structure and summary again.

```{r}
summary(data)
str(data)
```
Next, we move on with exploring the data by means of Exploratory Data Analysis.

# Exploratory Data Analysis (EDA)

This section aims to identify useful predictors of `is_looking_for_job` target variable. We use graphs, plots, and tables to uncover important relationships that could indicate important areas for further investigation. Here we start with the categorical variables then numerical variables.

## Investigate the target variable `is_looking_for_job`

First we investigate the target variable, and report a bar plot and summary.

```{r fig.height = 5, fig.width = 5}
ggplot( data = data, aes( x = is_looking_for_job, label = scales::percent( prop.table( stat( count ) ) ) ) ) +
  labs( title = "Bar plot for the target variable" ) +
  geom_bar( fill = c( "palevioletred1", "darkseagreen1" ) ) + 
  geom_text( stat = 'count', vjust = 0.2, size = 6 ) + 
  theme_new

summary( data $ is_looking_for_job )
```


$P(is\_looking\_for\_job = no) = 14381$

$P(is\_looking\_for\_job = yes) = 4777$

$n = P(is\_looking\_for\_job = no) + P(is\_looking\_for\_job = yes) = 14381 + 4777 = 19158$

$P(is\_looking\_for\_job = yes) = \frac{P(is\_looking\_for\_job = yes)}{n} = \frac{4777}{19158} = 24.93\%$

We see above, that the majority of the candidates, after successful completion of the training tend to stay with the company. However, `r round( summary( data $ is_looking_for_job )[2] / nrow( data ), 4 ) * 100`% of the candidates look for opportunities outside of the training provider company. Although the `r round( summary( data $ is_looking_for_job )[2] / nrow( data ), 4 ) * 100`% retention rate sounds fairly good, the `r round( summary( data $ is_looking_for_job )[2] / nrow( data ), 4 ) * 100`% turnover rate does not. It means, that on average, every fourth candidate tends to leave the company after the training, and techincally exploits the training given.

Throught the analysis of below predictors we will try unveil important predictors of `is_looking_for_job` and understand what type of candidates are the ones who stay and those who do not at the company.


## Investigate the `city` variable {.unlisted .unnumbered}

With the `city` variable, we aim to understand which are the cities where the most candidates came from and the ones that were most successful in terms employment. Therefore, we plot the variable as an unstandardised and a standardised histogram.

```{r}
ggplot( data = data ) + 
  geom_bar( aes( x = city, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for the target variable 'is_looking_for_job'" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = city, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```

Although the x-axis' values are not readable, because of the large amount of unique observations for `city`, what we take away from the plot is that there are handful of cities that outperfom other in terms of candidate count. The top 5 of these cities are

```{r}
x = data %>% group_by(city) %>% summarise(candidate_count = n())

# sort(a $ candidate_count, decreasing = TRUE)
# ??? help needed.
```

Both the plots, and the above table indicate no strong graphical indication of `city` being an important predictor of `is_looking_for_job`. However, given the above outputs, the company should target specifically those cities where the retention rate is high.


## Investigate the `gender` variable {.unlisted .unnumbered}

To understand whether gender is a predictor of whether the candidate is going to stay or not, we first plot it as a regular histogram, with `is_looking_for_job` overlay, and then standardise it, so that we can read the the percentage rate of those who would like to stay with the company and those who do not.

```{r, fig.show = "hold", out.width = "50%", fig.align = 'default' }
addmargins( table( data $ is_looking_for_job, data $ gender, dnn = c( "is_looking_for_job", "gender" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = gender, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'gender', with 'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = gender, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

From the above table, we can quantify the relationship between the different gender categories and turnover rate. Namely, we see that the gender ratio is mainly dominated by males, 13221 observations (approx. 69%). While this number seems overly large, we have to remind ourselves that the data is on Data Science positions. So it hsould not come as a sruprise, that on an engineering field, males dominate. Females represent themselves by 1238 candidates (approx. 6.5%), and those of Unknown and Other gender types take up the rest 24.5%.

From the standardised plot we see that the Unknown category produces a worse turnover among the genders, while the different genders (Female, Male, Other) are about on the same level as the whole dataset's turnover rate. 

Since the above plot does not provide distinct graphical evidence `gender` being an important predictor of `is_looking_for_job`, we test the proportions of genders by a hypothesis test.

**Hypotheses:** 

\[
\left\{ \begin{array}{l}
         \mbox{$H_0:  \pi_{Femal, yes}  = \pi_{Male, yes} = \pi_{Other, yes} = \pi_{Unknown, yes}$} \\
         \mbox{$H_a:$ at least one of the claims under $H_0$ is wrong} \end{array} \right.
\] 

**Test results:**
```{r}
chisq.test( table( data $ is_looking_for_job, data $ gender ) )
```

**Test conclusion:**

Given significance level of $\alpha = 0.05$ , and p-value = $2.2*10^{-14}\%$ < $\alpha = 5\%$, there is sufficient evidence found to reject the $H_0$ in favour for $H_a$, and we infer that there is statistical relationship between `gender` and the target variable.

Therefore, we will use `gender` as a predictor of `is_looking_for_job`.


## Investigate the `relevant_experience` variable {.unlisted .unnumbered}

```{r}
addmargins( table( data $ is_looking_for_job, data $ relevant_experience, dnn = c( "is_looking_for_job", "relevant_experience" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = relevant_experience, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'relevant_experience', with 'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = relevant_experience, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

The above contingency table quantifies the relationship between `relevant_experience` and the target variable. We read that 13792 (71.9%) candidates have experience, and the rest 5366 (28.1%) do not. It means that approximately, the dataset contains approximately 2.5 times more of those candidates who have experience than those who do not.

The above plots, reinforces what we concluded from the contingency table. However, to learn about the tendency to look for new opportunities between the different experience categories, we need to look at the plot with `is_looking_for_job` overlay. We see that the turnover rate is higher for those without experience (approximately 30%) and lower for those with experience (approximately 20%). Given the visible difference in turnover rate, we do not need to carry out any hypothesis test to confirm the predictive importance of `relevant_experience`.


## Investigate the `enrolled_univeristy` variable {.unlisted .unnumbered}

```{r}
addmargins( table( data $ is_looking_for_job, data $ enrolled_university, dnn = c( "is_looking_for_job", "enrolled_university" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = enrolled_university, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'enrolled_university', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = enrolled_university, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

The contingency table shows that the majority of candidates (14105) are/were not enrolled to any higher education, while those who took either full or part time courses at the univeristy are in minority (5053).

Next, we analyse the standardised plot and report that those with a full time degree tend to leave the company approximately 37.5% of the times, while those of the other categories approximately at a rate of 20-25%. 

Given the large and clear difference between the university enrolment categories, there is no need for a hypothesis test to confirm this. Therefore, based one the strong graphical evidence, we can expect the data mining algorithm to incorporate `enrolled_university` to the prediction model.


## Investigate the `education_level` variable {.unlisted .unnumbered}

```{r}
addmargins( table( data $ is_looking_for_job, data $ education_level, dnn = c( "is_looking_for_job", "education_level" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = education_level, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'education_level', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = education_level, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```

The largest part of the dataset is represented by those with a graduate degree (bachelor). Meaning, they have the highest frequency in the dataset. The second and third largest representing group are those with Masters degree and High School diploma, respectively.

Given that `education_level` is an ordinal variable, we observe a rough normality, and symmetry in the data. That is, most of the candidates in the dataset hold a graduate degree, while towards the sides we find the rarer cases, that is those with Masters and High School qualifications. Towards the tails, we find the rarest observations, i.e., those with significantly lower and higher qualifications, such as Primary School diploma and Phd.

To see the proportion of turnover for each of the education levels, we read the standardised plot, and report that it kept its approximate symmetric shape. Furthermore, we see that those with a graduate degree tend to change job the most likely, by more than 25%, while the rest of the categories change with a likeliness of less than 25%. Those with High School degrees change jobs approximately with the same frequency as that of with Masters degree, which is approximately 20%. Similarly, those with Primary School degree wants to change job approximately as frequently as Phd degree holders, that is approximately 13%.

The above plots indicate strong graphical evidence of education level being an important predictor of the target variable, therefore, we can expect the data mining algorithm to incorporate it into the prediction model.


## Investigate the `major_discipline` variable {.unlisted .unnumbered}

```{r}
addmargins( table( data $ is_looking_for_job, data $ major_discipline, dnn = c( "is_looking_for_job", "major_discipline" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = major_discipline, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'major_discipline', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = major_discipline, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```

From the above plots we read, that those with STEM (Science, technology, engineering, and mathematics) qualification rule the dataset (14492 observations). The second largest group that represents themselves in terms of major discipline is those with unknown major (2813 observations). The rest 1853 observation spread out between Art, Business, Humanities and No Major categories. 

The fact the STEM rules the data was expected, since Data Science is a STEM field, therefore it comes as no surprise, that we such a staggering number of STEM candidates.

What we are also interested in is the turnover rate between different major disciplines. From the standardised plot, we learn that there is hardly any difference between the categories and the turnover rate between them. To confirm our claim, we will test it by hypothesis test.

**Hypotheses:** 

\[
\left\{ \begin{array}{l}
         \mbox{$H_0:  \pi_{Arts, yes}  = \pi_{Business, yes} = \pi_{Humanities, yes} = \pi_{NoMajor, yes} = \pi_{Other, yes} = \pi_{STEM, yes} = \pi_{Unknown, yes}$} \\
         \mbox{$H_a:$ at least one of the claims under $H_0$ is wrong} \end{array} \right.
\] 

**Test results:**
```{r}
chisq.test( table( data $ is_looking_for_job, data $ major_discipline ) )
```

**Test conclusion:**

Given significance level of $\alpha = 0.05$ , and p-value = $6.225*10^{-10}\%$ < $\alpha = 5\%$, there is sufficient evidence found to reject the $H_0$ in favour for $H_a$, and we infer that there is statistical relationship between `major_discipline` and the target variable.

Therefore, we will include `major_discipline` into the prediction model.


## Investigate the `experience` variable {.unlisted .unnumbered}

```{r}
addmargins( table( data $ is_looking_for_job, data $ experience, dnn = c( "is_looking_for_job", "experience" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = experience, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'experience', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = experience, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```

The above plots show, a multi-modal distribution. That is a distribution with multiple local modes; the first one is around experience of 4 years, the second one around experience of 10 years and lastly at 15 years. Additionally, we report that those with more than 20 years of experience represent the majority of the dataset.

To see the turnover rate between the difference experience level, we read the standardised plot. The standardised plot shows that the more experience the candidate has the less likely he/she will be open to new job opportunities. Meaning, that there is a strong graphical indication of `experience` being an important predictor of the turnover rate, therefore we can expect this variable to be included in the prediction model by the data mining algorithm.


## Investigate the `company_size` variable {.unlisted .unnumbered}


```{r}
addmargins( table( data $ is_looking_for_job, data $ company_size, dnn = c( "is_looking_for_job", "company_size" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = company_size, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'company_size', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = company_size, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```

The above plot shows that most of the candidates with unknown company size represent the majority of the data. Next to that, those who work for companies of size "50-99" and "100-499" and large organisation of size more than ">9999".

To observe the turnover rate between the different categories, we read the standardised plot; those with unknown company size tend to look for a job in the largest percentage. Next to this observation, only one category stands out as being significantly different from others and this is the candidates from company size of "10-49". These candidates tend to look for a job approximately 23% of the cases. 

Conclusively, we see strong graphical indication of `company_size` as an important predictor of `is_looking_for_job`, and hence expect it to be incorporated in the prediction model.

## `company_type`

```{r}
addmargins( table( data $ is_looking_for_job, data $ company_type, dnn = c( "is_looking_for_job", "company_type" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = company_type, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'company_type', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = company_type, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```

The above plots show that the majority of the candidates work for private limited (9817 observations) and unknown (6140 observations) employers. Next to these two large categories, the rest observations (3201) spread roughly evenly across Early Stage Startups, Funded Startups, NGOs, Other companies, and the Public Sector.

To see the turnover rate per company type, we observe the standardised plot, and see that those with unkonwn company type tend to look for a new job in the largest percentage. The second largest type in terms of turnover rate is the Early Stage Startup. Therefore, we see strong graphical indication of `company_type` being a predictor of the target variable, hence we can expect `company_type` to be included in the model by the data mining algorithm. 

Next we move on with `last_new_job`.

## Investigate the `last_new_job` variable {.unlisted .unnumbered}
```{r}
addmargins( table( data $ is_looking_for_job, data $ last_new_job, dnn = c( "is_looking_for_job", "last_new_job" ) ) )

ggplot( data = data ) + 
  geom_bar( aes( x = last_new_job, fill = is_looking_for_job ) ) +
  labs( title = "Bar plot for 'last_new_job', with 
        'is_looking_for_job' overlay" )  +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new

ggplot( data = data ) + 
  geom_bar( aes( x = last_new_job, fill = is_looking_for_job ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme_new
```

The above plots show that those who never had a job before, and those who changed job 1, 2 and more than 4 years ago are in majority. Those candidates who are their current job for 3 or 4 years are in minority in this dataset. The standardised graph clearly shows, that the more a candidate stays at a specific work place the less likely he/she will change job. That is, there is a declining tendency in the turnover rate as the last job is farther apart.


## Investigate the `training_hours` variable {.unlisted .unnumbered}
```{r}
ggplot( data ) +
     geom_histogram( aes( x = training_hours ), bins = 30, color = "blue", fill = "lightblue" )

ggplot( data ) +
     geom_histogram( aes( x = training_hours, fill=is_looking_for_job ), position="fill")

```

From the above plot we read that the training hours given to the candidates are positively skewed, with mean training hours of `r round(mean(data $ training_hours), 2)` hours.

When `training_hours` is plotted as a standardised graph with the target variable overlay, we see that those who spend more than 200 hours with the training tend to look for a job less likely than those who completes the training under 200 hours. Based on this, we see strong enough indication of the graphical importance of `training_hours`, and hence we would expect the data mining algorithm to incorporate that into the model.

## Investigate the `city_development_index` variable {.unlisted .unnumbered}

## Detect Correlated Variables 

To visualize the correlation matrix between the numerical variables: `training_hours` and `city_development_index` we use the `ggcorr()` function as follows:

```{r}
variable_list = c( "city_development_index", "training_hours" )

ggcorr( data = data[ , variable_list ], label = TRUE ) 
```

The above correlation matrix plot indicates that there is no relationship (`r=0`) between `training_hours` and `city_development_index`, therefore we do not need to eliminate either of them.


The above plots show that International Plan holders (`intl.plan="yes"`) tend to churn more frequently, but they do not *quantify* the relationship. The above contingency table quantify the relationship between International Plan holding and churning, Since both variables are categorical. We should consider using International Plan as one of the predictor variables in whatever machine learning algorithms we use to predict churn.

## Investigate variable "*voice mail plan*"

Make a table for counts of Churn and Voice Mail Plan

```{r}
table( churn $ churn, churn $ voice.plan, dnn = c( "Churn", "Voice Mail Plan" ) )
```

Bar chart for Voice Mail Plan

```{r, fig.show = "hold", out.width = "50%", fig.align = 'default' }
ggplot( data = churn ) + 
  geom_bar( aes( x = voice.plan, fill = churn ) ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new

ggplot( data = churn ) + 
  geom_bar( aes( x = voice.plan, fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

The results above indicate that:

* It seems that Voice Mail Plan increases customers' loyalty. Thus, we should consider enhancing our Voice Mail Plan.
* We should consider using Voice Mail Plan as one of the predictor variables in whatever machine learning algorithms we use to predict churn. Our confidence in this expectation is perhaps not as high as for the International Plan. 


## Investigate variable "*Day Minutes*"

To investigate the relationship between variable "*Day Minutes*", since the variable "*Day Minutes*" is numerical, we report the boxplot and density as follows

```{r}
ggplot( data = churn ) +
  geom_boxplot( aes( x = churn, y = day.mins ), fill = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

```{r}
ggplot( data = churn ) +
  geom_density( aes( x = day.mins, fill = churn ), alpha = 0.3 ) + 
  theme_new
```

The results above indicate that:

* We should carefully track customer Day Minutes as total exceeds 200. Investigate why those with high usage tend to leave.
* We should consider using variable "*Day Minutes*" as one of the predictor variables in whatever machine learning algorithms we use to predict churn.  

## Investigate variable "*Evening Minutes*"

To investigate the relationship between variable "*Evening Minutes*", since the variable "*Evening Minutes*" is numerical, we report the boxplot and density as follows

```{r}
ggplot( data = churn ) +
  geom_boxplot( aes( x = churn, y = eve.mins ), fill = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

```{r}
ggplot( data = churn ) +
  geom_density( aes( x = eve.mins, fill = churn ), alpha = 0.3 ) + 
  theme_new
```

The above plots do not indicate graphical evidence of the predictive importance of *Evening Minutes*. Thus, we apply the following hypothesis testing for dependency between variables *Evening Minutes* and *churn* 

```{r}
t.test( eve.mins ~ churn, data = churn )
```

Since the P-value = ```r t.test( intl.calls ~ churn, data = churn )$p.value``` is less than $\alpha$=0.05, thus we reject the $H_0$. 
It means the difference in the mean number of evening minutes for churners and non-churners is statistically significant. Thus, variable "*Evening Minutes*" is useful for predicting churn.

We applied the same Hypothesis testing for the variable "*Night Minutes*", to check its dependency with variables *churn*. And the result indicates that the variable "*Night Minutes*" is also useful for predicting churn.

## Investigate variable "*Day Calls*" 

Here, we are interested to investigate the relationship between variable Day Calls and the target variable `churn`. To investigate the relationship between variable "*Day Calls*", since the variable "*Day Calls*" is numerical, we report the boxplot and density as follows

```{r}
ggplot( data = churn ) +
  geom_boxplot( aes( x = churn, y = day.calls ), fill = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

```{r}
ggplot( data = churn ) +
  geom_density( aes( x = day.calls, fill = churn ), alpha = 0.3 ) + 
  theme_new
```

The above plots do not indicate graphical evidence of the predictive importance of Day Calls. However, a t-test (see below) for the difference in the mean number of day calls for churners and non-churners. Hypothesis testing for dependency between variables *Day Calls* and *churn* 

```{r}
t.test( day.calls ~ churn, data = churn )
```

Since the P-value = ```r t.test( day.calls ~ churn, data = churn )$p.value``` is higher than $\alpha$=0.05, thus we do not reject the $H_0$. 
It means the difference in the mean number of international calls for churners and non-churners is not statistically significant. Thus, variable "*Day Calls*" is not useful for predicting churn.

We applied the same Hypothesis testing for the variables "*Evening Calls*" and "*Night Calls*", to check their dependencies with variables *churn*. And the result indicates that these two variables also are not useful for predicting churn.

## Investigate variable "*International Calls*" 

Here, we are interested to investigate the relationship between variable International Calls and the target variable `churn`. To see the relationship between variable International Calls and the target variable *churn*, we report the histogram of variable International Calls including Churn overlay as follow

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = intl.calls, fill = churn ), position = "stack" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

We also report the *Normalized* histogram of variable International Calls including Churn overlay as follow

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = intl.calls, fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

To see the relationship between variable International Calls and the target variable *churn*, we report the boxplot as follow

```{r}
ggplot( data = churn ) +
  geom_boxplot( aes( x = churn, y = intl.calls ), fill = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

The above plots do not indicate strong graphical evidence of the predictive importance of International Calls. However, a t-test (see below) for the difference in the mean number of international calls for churners and non-churners is statistically significant (p-value = 0.003; p-values larger than, say, 0.10 are not considered significant), meaning that this variable is indeed useful for predicting churn: Churners tend to place a lower mean number of international calls. Thus, had we omitted International Calls from the analysis based on the seeming lack of graphical evidence, we would have committed a mistake, and our predictive model would not perform as well.

Hypothesis testing for dependency between variables *International Calls* and *churn* 

```{r}
t.test( intl.calls ~ churn, data = churn )
```

Since the P-value = ```r t.test( intl.calls ~ churn, data = churn )$p.value``` is less than $\alpha$=0.05, thus we reject the $H_0$. 
It means the difference in the mean number of international calls for churners and non-churners is statistically significant. Thus, variable "*International Calls*" is useful for predicting churn.

## Investigate variable "*customer service calls*" 

Here, we are interested to investigate the relationship between variable "*customer service calls*" and the target variable "*churn*". To see the relationship between variable "*customer service calls*" and the target variable "*churn*", we report the histogram of the variable "*customer service calls*" including "churn" overlay as follows

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = factor( customer.calls ), fill = churn ), position = "stack" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

We also report the *Normalized* histogram of variable "*customer service calls*" including "churn" overlay as follow

```{r}
ggplot( data = churn ) +
  geom_bar( aes( x = factor( customer.calls ), fill = churn ), position = "fill" ) +
  scale_fill_manual( values = c( "palevioletred1", "darkseagreen1" ) ) + 
  theme_new
```

The results above indicate that:

* We should carefully track the number of customer service calls made by each customer. By the third call, specialized incentives should be offered to retain customer loyalty, since, by the fourth call, the probability of churn substantially increases. 
* We should consider using variable "*customer service calls*" as one of the predictor variables in whatever machine learning algorithms we use to predict churn. 


# Data Preparation

In this stage we want to prepare the dataset for modeling. Here, we partition the *churn* dataset randomly into two groups: train set (80%) and test set (20%). Here, we use the `partition()` function from the *liver* package:

```{r}
set.seed( 5 )

data_sets = partition( data = churn, prob = c( 0.8, 0.2 ) )

train_set = data_sets $ part1
test_set  = data_sets $ part2

actual_test  = test_set $ churn
```
Note that here we are using the `set.seed()` function to create reproducible results. 

We validate the partition by testing whether the proportion of the target variable `churn` differs between the two data sets. We use a Two-Sample Z-Test for the difference in proportions. A Two-sample z-test is suitable here, mainly because we want to compare the proportion of the customers who paid for the *churn* between the two groups (“training set” and “test set”). The hypotheses are as follows
\[
\bigg\{
\begin{matrix}
          H_0:  \pi_{churner,\ train}   =  \pi_{churner,\ test} \\
          H_a:  \pi_{churner,\ train} \neq \pi_{churner,\ test}
\end{matrix}
\]

To validate the partitions, we run a hypothesis test to check the proportion of the target variable `churn` in the train and test sets. To run the test, we use the `prop.test` function in **R**:
```{r}
x1 = sum( train_set $ churn == "yes" )
x2 = sum( test_set  $ churn == "yes" )

n1 = nrow( train_set )
n2 = nrow( test_set  )

prop.test( x = c( x1, x2 ), n = c( n1, n2 ) )
```

We don't reject the $H_0$, since the *p*-value is higher than $\alpha=0.05$. Thus, the difference in the proportion of the costumers who paid for the *churn*  is not statistically significant between the two groups (“training set” and “test set”). **It indicates that the partition for the target variable `churn` is valid.**

# Modeling - Classification

The results form the "Exploratory Data Analysis (EDA)" section indicate that the following predictors from `r ncol( churn ) - 1` predictors in the *churn* dataset are important to predict churn.

`voice.plan`, `voice.messages`, `intl.plan`, `intl.mins`, `intl.calls`, `day.mins`, `eve.mins`, `night.mins`, and `customer.calls`. 

Thus, here, based on the training dataset, we want to apply different type of Machine Learning algorithms, by using above predictors in our model. We use the following formula:
```{r}
formula = churn ~ voice.plan + voice.messages + intl.plan + intl.mins + intl.calls +
                  day.mins + eve.mins + night.mins + customer.calls
```

## Classificaiton with the k-nearest neighbor algorithm

To find out the optimal value of `k` based on *Error Rate*, for the different values of k from 1 to 20, we run the k-nearest neighbor for the test set and compute the *Error Rate* for these models, by running `kNN.plot()` command 

```{r fig.align = 'center'}
kNN.plot( formula, train = train_set, test = test_set, transform = "minmax", k.max = 20, set.seed = 3 )
```

The plot shows that the minimum value of *Error Rate* is for the case that `k = 5`. Since the smaller values of *Error Rate* indicates better predictions, in this case, the optimal value of `k` would be `5`.

Now, to find the k-nearest neighbor for the test data set for the case `k = 5`, we use `kNN()` command: 
```{r}
predict_knn = kNN( formula, train = train_set, test = test_set, transform = "minmax", k = 5 )
```
Note that the `transform = "minmax"` input specifies that we are using min-max normalization to transfer the predictors.

## Classificaiton with Decision Tree by CART algorithm

We produce a decision tree based on the CART algorithm by using the `rpart` function from the [**rpart**](https://CRAN.R-project.org/package=rpart) package:

```{r}
tree_cart = rpart( formula, data = train_set, method = "class" )
```

To plot the decision tree, we use the `rpart.plot` function from the [**rpart.plot**](https://CRAN.R-project.org/package=rpart.plot) package:

```{r, fig.height=6, fig.width=10}
rpart.plot( tree_cart, type = 4, extra = 104 )
```

## Classificaiton with Decision Tree by C50 algorithm

We produce a decision tree based on the C5.0 algorithm by using the `C5.0` function from the [**C50**](https://CRAN.R-project.org/package=C50) package:

```{r}
tree_C50 = C5.0( formula, data = train_set ) 
```

Since the tree from the **C5.0 algorithm** is relatively large to visualize, we use the function `summary` as follows
```{r}
summary( tree_C50 )
```

## Classificaiton with Random Forest

*CART* and *C5.0* algorithms both produce a single decision tree based on all of the records, and the specified variables, in the training data set. On the other hand, *random forest* algorithm builds a series of decision trees and combine the trees disparate classifications of each record into one final classification. 

We run the *random forest* algorithm, using the `randomForest` function from the [**randomForest**](https://CRAN.R-project.org/package=randomForest) package:

```{r}
random_forest = randomForest( formula = formula, data = train_set, ntree = 100 )
```

Now, you may ask what would be a suitable value for the number of trees! In that case, in the following plot, you can see that if the number of trees is higher than around 40, we have a minimum error. 

```{r}
plot( random_forest )
```

We can visualize the dot-chart of variable importance as measured by the *random forest* algorithm as follow
```{r}
varImpPlot( random_forest )
```

## Classificaiton with Logistic Regression 

To run the logistic regression model, we will use the `glm()` command:
```{r}
logreg = glm( formula, data = churn, family = binomial )
```

To view the summary of the model, run the `summary()` command with the name of the saved model as the sole input. 
```{r}
summary( logreg )
```

# Model Evaluation

Based on our results so far, which of the above five classification algorithms are more suitable here for the *churn* dataset? To answer this question, here, we report the ROC curves as well as AUC for the above classification algorithms as follows:

```{r fig.align='center'}
prob_cart = predict( tree_cart, test_set, type = "prob" )[ , 1 ]
prob_C50  = predict( tree_C50,  test_set, type = "prob" )[ , 1 ]

prob_random_forest = predict( random_forest, test_set, type = "prob" )[ , 1 ]

prob_knn = kNN( formula, train = train_set, test = test_set, transform = "minmax", k = 13, type = "prob" )[ , 1 ]

prob_logreg  = predict( logreg,  test_set, type = "response" )

roc_knn = roc( actual_test, prob_knn )
roc_cart = roc( actual_test, prob_cart )
roc_C50 = roc( actual_test, prob_C50 )
roc_random_forest = roc( actual_test, prob_random_forest )
roc_logreg = roc( actual_test, prob_logreg )

ggroc( list( roc_knn, roc_cart, roc_C50, roc_random_forest, roc_logreg ), size = 0.8 ) + 
    theme_minimal() + ggtitle( "ROC plots with AUC for 4 outcomes") +
  scale_color_manual( values = 1:5, 
    labels = c( paste( "KNN; AUC=", round( auc( roc_knn ), 3 ) ),
                paste( "CART; AUC=", round( auc( roc_cart ), 3 ) ), 
                paste( "C50; AUC=", round( auc( roc_C50 ), 3 ) ), 
                paste( "Random Forest; AUC=", round( auc( roc_random_forest ), 3 ) ),
                paste( "Log Reg; AUC=", round( auc( roc_logreg ), 3 ) )
                ) ) +
  theme( legend.title = element_blank() ) +
  theme( legend.position = c( .7, .3 ), text = element_text( size = 17 ) )
```

Based on the above ROC curves and the values of AUC, the "*Random Forest*" algorithm has slightly better performance, since it has the highest value of AUC. 
