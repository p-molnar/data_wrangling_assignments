
---
title: '<center> The Exercises of Week 5 - Decision Trees <center>'
author: '<center> Reza Mohammadi <center>'
date: '<center> `r Sys.Date()` <center>'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 5
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include = FALSE}
knitr::opts_chunk $ set( echo = TRUE, message = FALSE, warning = FALSE, 
                         comment = " ", error = FALSE, fig.align = 'center'  )
```

```{css, echo=FALSE}
.answer_panel { margin-left: 40px; }

.sub_details { margin-left: 60px; }
```

**Full Name:** 

* Peter Molnar (11759216)
   
**Online Assignment**: There is a new online-assignment at the [DataCamp](https://www.datacamp.com) with the name “*Chapter 4: Classification Trees*” which is a part of the online course “Supervised Learning in R: Classification” at the DataCamp. *The online-assignments at the DataCamp are not mandatory*.

**Your task** is to answer the following questions in *Part 1* and *Part 2* in this R-markdown file. Please upload both your R-markdown ( .Rmd file) and the HTML files separately on Canvas. 

# Who can earn more than 50K per year? (40 points)

We want to explore the Income Prediction problem associated with the Adult Income Census dataset which is available in the [**liver**](https://CRAN.R-project.org/package=liver) package as the *adult* dataset. The prediction task is to determine whether a person makes over $50K a year. For this classification task, we are going to apply the *Decision Tree* using the *CART* and *C5.0* algorithms as well as the *Random Forest* algorithm by using the following R packages:

* **rpart**: we use the `rpart()` function in this package for the *CART* algorithm.
* **rpart.plot**: we use the `rpart.plot()` function in this package to plotting a decision tree.
* **C50**: we use the `C5.0()` function in this package for the *C5.0* algorithm.
* **randomForest**: we use the `randomForest()` function in this package for the *Random Forest* algorithm.
* **liver**: the *adult* dataset is in this package. We also use the `partition()` function in this package.
* **pROC**: to create ROC curve with AUC, we use the `plot.roc()` function in this package.

If it’s needed, install these packages on your computer. Here we load them:

```{r}
library( rpart )         # For the "CART" algorithm
library( rpart.plot )    # To plot decision trees
library( C50 )           # For the "C5.0" algorithm
library( randomForest )  # For the "Random Forest" algorithm
library( liver )         # For the "adult" dataset & the "partition" function
library( pROC )          # For ROC plot using "plot.roc" function
library( ggplot2 )       # For ggroc plot
library( caret )         # For confusion matrix metrics
```

## Data Understanding

The *adult* dataset is from the [US Census Bureau](https://www.census.gov) with the primary task to predict whether a given adult makes more than $50K a year based on attributes such as education, hours of work per week, etc. The target feature is *income* with two levels "`<=50K`" and "`>50K`", and the remaining 14 variables are predictors.

We import the dataset and report the structure of the dataset:

```{r}
data( adult ) 

str( adult )
```

It shows the dataset contains `r nrow( adult )` records and `r ncol( adult )` variables/features. The dataset has `r ncol( adult ) - 1` predictors along with a target variable `income` as a binary variable with two levels "`<=50K`" and "`>50K`". The variables/features (columns) are:

* `age`: age in years (numerical).
* `workclass`: a factor with 6 levels (categorical-nominal). 
* `demogweight`: the demographics to describe a person (categorical-nominal).
* `education`: a factor with 16 levels (categorical-nominal).
* `education.num`: number of years of education (numerical-discrete).
* `marital.status`: a factor with 5 levels (categorical-nominal).
* `occupation`: a factor with 15 levels (categorical-nominal).
* `relationship`: a factor with 6 levels (categorical-nominal).
* `race`: a factor with 5 levels (categorical-nominal).
* `gender`: a factor with levels "Female","Male" (categorical-binary).
* `capital.gain`: capital gains  (numerical-discrete).
* `capital.loss`: capital losses  (numerical-discrete).
* `hours.per.week`: number of hours of work per week (numerical-discrete).
* `native.country`: a factor with 42 levels (categorical-nominal).
* `income`: yearly income as a factor with levels "`<=50K`" and "`>50K`" (categorical-binary).

You can find more information related to this dataset at:

[https://www.rdocumentation.org/packages/liver/versions/1.3/topics/adult](https://www.rdocumentation.org/packages/liver/versions/1.3/topics/adult)

## Data Preparation

We partition the *adult* dataset randomly into two groups as a train set (80%) and a test set (20%). Here, we use the `partition()` function from the *liver* package:

```{r}
set.seed( 6 )

data_sets = partition( data = adult, prob = c( 0.8, 0.2 ) )

train_set = data_sets $ part1
test_set  = data_sets $ part2

actual_test  = test_set $ income
```

Note that here we are using the `set.seed()` function to create reproducible results. 

## Decision tree using CART algorithm

Here, we want to classify whether or not a person’s income is less than $50K, based on the following set of predictor fields: 

`age`, `education.num`, `capital.gain`, `capital.loss`, `hours.per.week`, `marital.status`, `workclass`, `race`, and `gender`. 

So, we produce a decision tree based on the CART algorithm. Here, we use the `rpart()` function from the [**rpart**](https://CRAN.R-project.org/package=rpart) package:

```{r}
formula = income ~ age + education.num + capital.gain + capital.loss + 
                   hours.per.week + marital.status + workclass + race + gender

tree_cart = rpart( formula = formula, data = train_set, method = "class" )

print( tree_cart )
```

To plot the decision tree, we use the `rpart.plot()` function from the [**rpart.plot**](https://CRAN.R-project.org/package=rpart.plot) package:

```{r fig.height = 6, fig.width = 10}
rpart.plot( tree_cart, type = 4, extra = 104 )
```

Based on the output, answer the following questions: 

a. **What is the number of decision nodes? What is the number of leaves?** 

<details class="answer_panel">
  <summary>Answer</summary>

* Number of decision nodes: 6
* Number of leaves: 7

</details>

b. **Interpret the first leaf on the left (bottom left).**

<details class="answer_panel">
  <summary>Answer</summary>

The left most leaf consists of a subset of observation that are of unmarried with capital gain less than \$7056 a year, and represents 52% of the whole dataset. The leaf in question classifies as low income  with 95% accuracy, and 5% error rate. Or in other words, 95% of the unmarried with `capital.gain` < \$7056 a year classifies as low income and the rest 5% as high income household.
  
</details>

c. **In general, how do you interpret the above decision tree?**

<details class="answer_panel">
  <summary>Answer</summary>
  
In general a CART decision tree is interpreted as follows:

1. we start with the top decision node (root node), and follow along an edge, whereby the next nodes and the edges tell which subsets we are looking at
2. once a leaf node is reached, it tells the predicted outcome
3. all the edges are connected by ‘AND’.

* The root node represents 100% of the whole dataset, out of which 76% classify as low income, and the rest 24% as high income. This node is a decision node, and splits on `marital.status`.
  * Those of unmarried represent 53% of the whole dataset, out of which 94% classifies as low income, and the rest 6% as high income. This node is a decision node, and splits on `capital.gain`.
    * Those of unmarried with `capital.gain` < 7056 represent 52% of the whole dataset, out of which 95% classify as low income and the rest 5% as high income.
    * Those of unmarried with `capital.gain` >= 7056 represent 1% of the whole dataset, out of which 97% classify as high income and the rest 3% as low income.
  * Those of married, represent 47% of the whole dataset, out of which 57% classify as low income and 43% as high income. This node is a decision node, and splits on `education.num`
    * Those of married, with `education.num` < 13 represents 33% of the whole dataset, out of which 68% are of low income earners, and the rest 32% are high income earners. This node is a decision node, and splits on `capital.gain`
      * Those of married, with `education.num` < 13 and `capital.gain` < 5096 represents 32% of the whole dataset, out of which 71% classify as low income and the rest 29% as high income. This node is a decision node and splits on `education.num`
        * Those of married, with `education.num` < 9 and `capital.gain` < 5096 represent 6% of the whole dataset, out of which 90% classify as low income and the rest 10% as high income
        * Those of married, with 9 <= `education.num` < 13 represents 26% of the whole dataset, out of which 67% classify as low income, and the rest 33% as high income. This node is a decision node, and splits on `capital.loss`
          * Those of married with 9 <= `education.num` < 13, and `capital.gain` < 5096, and `capital.loss` < 1821 represent 25% of the whole dataset, out of which 69% classify as low income and the rest 31% as high income
          * Those of married with 9 <= `education.num` < 13, and `capital.gain` < 5096, and `capital.loss` >= 1821 represent 1% of the whole dataset, out of which 75% classify as high income and the rest 25% as low income
      * Those of married with `education.num` < 13 with `capital.gain` >= 5096 represents 2% of the whole dataset, out of which 98% classify as high income and the rest 2% as low income
    * Those of married with `education.num` >=13 represents 14% of the whole dataset, out of which 70% classify as high income earners, and the rest 30% are of low income earners.

</details>

## Decision tree using C5.0 algorithm

By using the C5.0 algorithm, we want to classify whether or not a person’s income is less than $50K. Here, first, for simplicity, we use only two predictors: `marital.status` and `education.num`. We produce a decision tree based on the C5.0 algorithm by using the `C5.0()` function from the [**C50**](https://CRAN.R-project.org/package=C50) package:

```{r}
tree_C50_small = C5.0( income ~ marital.status + education.num, data = train_set ) 

plot( tree_C50_small )
```

Based on the output, answer the below questions:

**What is the number of decision nodes? What is the number of leaves?**

<details class="answer_panel">
  <summary>Answer</summary>
* Number of decision nodes: 2
* Number of leaves: 3
  
</details>

**Interpret the first leaf on the right (bottom right).**

<details class="answer_panel">
  <summary>Answer</summary>
* 5306 observations are of `married` and has more than 12 years of education, out of which approximately 70% classify as high income earners and the rest 30% as low income.
  
</details>

**In general, how do you interpret the above decision tree?**

<details class="answer_panel">
  <summary>Answer</summary>

* The root node represents 38782 observations (100%). This node is a decision node, and splits on `marital.status` into 2 groups, married and unmarried.
  * Those of unmarried represent 20543 observations, 52.97% of the whole dataset, out of which approximately 95% classify as low income and the rest 5% as high income.
  * Those of married represent 18239 observations, 47.03% of the whole dataset. This node is a decision node, and splits on `education.num`.
    * Those of married with `education.num` <= 12 represent 12933 observations, 33.35% of the whole dataset, out of which approximately 70% classify as low income and the rest 30% as high income.
    * Those of married with `education.num` > 12 represent 5306 observations, 13.68% of the whole dataset, out of which approximately 70% classify as high income and the rest 30% as low income.


  
</details>

## Random Forest

*CART* and *C5.0* algorithms both produce a single decision tree based on all of the records, and the specified variables, in the training data set. On the other hand, *random forest* algorithm builds a series of decision trees and combine the trees disparate classifications of each record into one final classification. 

Here, we want to classify whether or not a person’s income is less than $50K, based on the following set of predictor fields: `age`, `education.num`, `capital.gain`, `capital.loss`, `hours.per.week`, `marital.status`, `workclass`, `race`, and `gender`. By considering these set of predictors, we run the *random forest* algorithm, using the `randomForest()` function from the [**randomForest**](https://CRAN.R-project.org/package=randomForest) package:

```{r}
random_forest = randomForest( formula = formula, data = train_set, ntree = 10 )
```

We can visualize the dot-chart of variable importance as measured by the *random forest* algorithm as follow

```{r}
varImpPlot( random_forest )
```

```{r  fig.height = 3, fig.width = 3}
predict_random_forest = predict( random_forest, test_set )

conf.mat( predict_random_forest, actual_test )

conf.mat.plot( predict_random_forest, actual_test, main = "Random Forest n=10" )

mse( predict_random_forest, actual_test )
```

Based on the output, answer the following questions: 

**You see that in the `randomForest()` function we set the number of trees to 10 (`ntree = 10`). Change this value to 100 and run the code for this case (`ntree = 100`). Explain what conclusion you will draw.**

<details>
  <summary>Answer</summary>

* There are 2 possible predicted classes: “<=50K” and “>50K”
* “<=50K” meaning that the model predicted that the person earns maximum of $50.000 annually.
* “>50K” meaning that the model predicted that the person earns more than $50.000 annually.
* In total the classifier made 9816 predictions


<h3>n=10</h3>

The classifier

* predicted “<=50K” for 7981 people, out of which 7043 was correctly predicted, while 938 was incorrectly.
* predicted “>50K” for 1835 people, out of which 1383 was correctly predicted, and 452 was incorrectly.
* Out of the 9816 predictions, the model correctly predicted the outcome 7043 + 1383 = 8426 times.
* Out of the 9816 predictions, the model incorrectly predicted the outcome 938 + 452 = 1390 times

```{r}
confusionMatrix(data = predict_random_forest, reference = actual_test)
```

We identify the following:

* **Accuracy:** overall the classifier is correct 85.84% of the time
* **Misclassification rate:** overall the classifier is incorrect 14.16% of the time
* **Sensitivity:** the model correctly classifies positive records 93.97% of the time
* **Specificity:** the model correctly classifies negative records 59.59% of the time

<h3>n=100</h3>

```{r}
random_forest_100 = randomForest( formula = formula, data = train_set, ntree = 100 )
varImpPlot( random_forest_100 )
predict_random_forest_100 = predict( random_forest_100, test_set )
```

```{r fig.height = 3, fig.width = 3}
conf.mat( predict_random_forest_100, actual_test )

conf.mat.plot( predict_random_forest_100, actual_test, main = "Random Forest n=100" )

(mse( predict_random_forest_100, actual_test ))
```

The classifier

* predicted “<=50K” for 8002 people, out of which 7060 was correctly predicted, while 942 was incorrectly.
* predicted “>50K” for 1814 people, out of which 1379 was correctly predicted, and 435 was incorrectly.
* Out of the 9816 predictions, the model correctly predicted the outcome 7060 + 1379 = 8439 times.
* Out of the 9816 predictions, the model incorrectly predicted the outcome 942 + 435 = 1377 times


```{r}
confusionMatrix(data = predict_random_forest_100, reference = actual_test)
```

* **Accuracy:** overall the classifier is correct 85.97% of the time
* **Misclassification rate:** overall the classifier is incorrect 14.03% of the time
* **Sensitivity:** the model correctly classifies positive records 94.20% of the time
* **Specificity:** the model correctly classifies negative records 59.41% of the time


<h3>Conclusion</h3>

| | n=10 | n=100 |
| :- | :-: | :-: |
|MSE | 0.1416 | 0.1403 |
|Accuracy |85.84% | 85.97%|
|Misclassification rate | 14.16% | 14.03% |
|Sensitivity |93.97% | 94.20% |
|Specificity |59.59% | 59.41% |

Based on the above summary we can conclude the following:

* The random forest with n=10 bears with slightly higher error rate, than the model with n=100. Between competing models, the one with lower error rate is preferred, that is, n=100.
* The accuracy rate of the model with n=10 is again slightly lower than that of n=100. Given, then that the misspecification rate is the complement of accuracy, the model with n=10 has a higher misspecification rate. The higher accuracy and lower misspecification is preferred, therefore, the model with n=100.
* The model with n=10 has lower sensitivity than that of n=100. That is, the former model predicts the positive records less than its other model, n=100. Hence, the latter is preferred.
* In terms of specificity, the model with n=10 performs better, however, the margin is only approximately 0.2%. Therefore, the model with n=10 is preferred.

Lastly, we plot the error rate of the random forest as follows:

```{r}
plot(random_forest_100)
```

We can conclude from the above plot, that `ntree >= 30` the error rate is approximately constant, meaning that a larger `ntree`, e.g., a 100 predicts about as well as `ntree = 30`. From the metrics comparison, we can conclude that the model with n=100 shows a slightly better prediction metrics than the model with n=10. Since the margin is little to non-significant, if the larger `n` value comes at the cost of computational complexity, and hence computational time, the model with the smaller `n` is preferred. However, if the larger `n` does not cause any computational difficulties, the larger `n` is more optimal. Still, `ntree = 100` does not seem to be reasonable.

</details>



## Model Evaluation

So far we've applied three different classification algorithms (*CART*, *C5.0*, and *random forest*) for the *adult* dataset. Now, you may ask "well, which one is more suable for this dataset?". In another word, which model has more accuracy? To answer this question, we evaluate the performance of the decision trees in parts 1.4, 1.5, and 1.6. Basically, by using the training dataset, we want to estimate (predict) whether or not a person’s *income* in the test set is less (higher) than $50K. We evaluate the accuracy of the predictions by reporting:

* Confusion Matrix,
* MSE,
* ROC curve,
* AUC (Area Under the ROC curve).

* We run the **CART algorithm**, using the same *formula* input as before:

```{r fig.height = 3, fig.width = 3}
formula = income ~ age + education.num + capital.gain + capital.loss + 
                   hours.per.week + marital.status + workclass + race + gender

tree_cart = rpart( formula = formula, data = train_set, method = "class" )

predict_cart = predict( tree_cart, test_set, type = "class" )

conf.mat( predict_cart, actual_test )
conf.mat.plot( predict_cart, actual_test )

( mse_cart = mse( predict_cart, actual_test ) )
```

* We run the **C5.0 algorithm**, using the same *formula* input as before:

```{r fig.height=3, fig.width=3}
tree_C50 = C5.0( formula = formula, data = train_set, type = "class" ) 

predict_C50 = predict( tree_C50, test_set, type = "class" )

conf.mat( predict_C50, actual_test )
conf.mat.plot( predict_C50, actual_test )

( mse_C50 = mse( predict_C50, actual_test ) )
```

* We run the **random forest**, using the same *formula* input as before:

```{r fig.height=3, fig.width=3}
random_forest = randomForest( formula = formula, data = train_set, ntree = 100 )

predict_random_forest = predict( random_forest, test_set )

conf.mat( predict_random_forest, actual_test )
conf.mat.plot( predict_random_forest, actual_test )

( mse_random_forest = mse( predict_random_forest, actual_test ) )
```

Here we report the ROC curves as well as AUC for the above classification algorithm as follows:

```{r}
prob_cart = predict( tree_cart, test_set, type = "prob" )[ , 1 ]
prob_C50 = predict( tree_C50, test_set, type = "prob" )[ , 1 ]
prob_random_forest = predict( random_forest, test_set, type = "prob" )[ , 1 ]

roc_cart = roc( actual_test, prob_cart )
roc_C50 = roc( actual_test, prob_C50 )
roc_random_forest = roc( actual_test, prob_random_forest )

ggroc( list( roc_cart, roc_C50, roc_random_forest ), size = 0.8 ) + 
    theme_minimal() + ggtitle( "ROC plots with AUC for 3 outcomes") +
  scale_color_manual( values = 1:3, 
    labels = c( paste( "CART; AUC=", round( auc( roc_cart ), 3 ) ), 
                paste( "C50; AUC=", round( auc( roc_C50 ), 3 ) ), 
                paste( "Random Forest; AUC=", round( auc( roc_random_forest ), 3 ) ) ) ) +
  theme( legend.title = element_blank() ) +
  theme( legend.position = c( .7, .3 ), text = element_text( size = 17 ) )
```

In the above plot **black** curve is for CART algorithm, <span style="color:red">**red**</span> curve is for C50 algorithm, and <span style="color:green">**green**</span> curve is for random forest algorithm. 

**Based on the result of above four model evaluaiton reports (Confusion Matrix, MSE, ROC cuve, and UCA), what conclusion you will draw.**


<details>
  <summary>Answer</summary>

In order to compare the competing models, we run the following code to report the accuracy, misclassification rate, sensitivity and specificity.

```{r}
confusionMatrix(data = predict_cart, reference = actual_test)
confusionMatrix(data = predict_C50, reference = actual_test)
confusionMatrix(data = predict_random_forest, reference = actual_test)
```

| | CART | C50 | Random Forest| 
| :- | :-: | :-: | :-:|
|MSE | 0.1519 | 0.1391 |0.1391|
|Accuracy |0.8481 | 0.8609 |0.8609 |
|Misclassification rate | 0.1519 | 0.1391 | 0.1391 |
|Sensitivity | 0.9428 | 0.9429  |0.9454 | 
|Specificity |0.5424 | 0.5963  | 0.5881 |
|AUC | 0.8550 | 0.8950 | 0.8800|

Based on the above summary we can conclude the following:

* The Random forest and the C50 algorithm have equally low Mean Squared Error, and they are lower than that of CART's. Meaning, that on average the former two algorithms produce a better prediction than the former.
* The random forest and the C50 algorithms happen to have equal accuracies as well, and they are both higher than CART's. Again, C50 and the random forest outperform CART in terms of prediction accuracy.
* In terms of sensitivity, the random forest algorithm has the highest rate, so this model is preferred over the others.
* In terms of specificity, the C50 algorithm has the highest rate, so as a single metrics, this model would be preferred over the others.
* AUC, which is the area under the ROC curve, is the most accurate measure to evaluate competing models. It is because the ROC curve computes the sensitivity and specificity over different splits. Based on that, C50 comes out as the best predictor compared to the other two algorithms, therefore it is deemed to be a superior model.

</details>

# Decision Tree analysis for churn dataset (60 points)

We want to apply the decision tree analysis to the [*churn*](https://rdrr.io/cran/liver/man/churn.html) dataset that is available in the **R** package [**liver**](https://CRAN.R-project.org/package=liver). We want to classify whether or not a customer leaving the service of one company in favor of another company. Use the code from the questions in Part 2.

The *churn* dataset has 19 predictors but we are not going to use all of the predictors. We know based on the lecture of week 2, we should use only the predictors that have a relationship with the target variable. So, here we use the following predictors:

`account.length`, `voice.plan`, `voice.messages`, `intl.plan`, `intl.mins`, `day.mins`, `eve.mins`, `night.mins`, and `customer.calls`.

For this classification task, we want to apply the following algorithms:

* *CART* algorithm,
* *C5.0* algorithm,
* *Random Forest* algorithm,
* *kNN* algorithm.

Ultimately, **we want to see which of the above classification algorithms are more suitable here**, by evaluating the accuracy of the predictions with:

* Confusion Matrix,
* MSE,
* ROC curve,
* AUC (Area Under the ROC curve).

## Data Preparation

After importing the *churn* dataset in R, partition the *churn* dataset randomly into two groups as a train set (80%) and a test set (20%). Here, for the partition, you could use the `partition()` function from the *liver* package. You should use the `set.seed()` function in R; similar to the data preparation in section 1 for adult dataset.

<details>
  <summary>Answer</summary>
  
```{r}
# load `churn` dataset
data( churn )

# set seed of 5 for reproducibility
set.seed( 5 )

# partition the dataset into an 80-20% parts
data_sets = partition( data = churn, prob = c( 0.8, 0.2 ) )

# assign the 80% part to train_set and the 20% to test_set
train_set = data_sets $ part1
test_set  = data_sets $ part2

# pick the target variable from the test_set to test against it
actual_test  = test_set $ churn
```

</details>

## Applying Decision Tree algorithms

For the classification task, by using the training dataset, run the following algorithms:

* *CART algorithm* using the `rpart()` function in the **rpart** R package and plot the decision tree using the `rpart.plot()` function in the **rpart.plot** R package; Similar to part 1.3.

* *C5.0 algorithm* using the `C5.0()` function in the R package **C50**; Similar to part 1.4.

* *Random Forest* using the `randomForest()` function from the R package **randomForest**; Similar to part 1.5.


Based on the training dataset and the above models predict for the test set. For the prediction, you could use the `predict()` function; Similar to part 1.6.

<details>
  <summary>Answer</summary>

<h3>Selecting the variables</h3>
```{r}

# formula to be used for the different predictions
formula = churn ~ account.length + voice.plan + voice.messages + intl.plan +
  intl.mins + day.mins + eve.mins + night.mins + customer.calls
```

<h3>CART</h3>

```{r}
# Cart prediction
tree_cart = rpart( formula = formula, data = train_set, method = "class" )
predict_cart = predict( tree_cart, test_set, type = "class" )
```

<h3>C50</h3>

```{r}
# C50 prediction
tree_C50 = C5.0( formula=formula, data = train_set ) 
predict_C50 = predict( tree_C50, test_set, type = "class" )
```

<h3>Random forest</h3>

```{r}
# Random forest prediction
random_forest = randomForest( formula = formula, data = train_set, ntree = 10 )
predict_random_forest = predict( random_forest, test_set, type = "class" )
```

</details>

## Applying kNN algorithm

Find the k-nearest neighbor for the test set, based on the training dataset, for the case k = 13. For the kNN algorithm, use min-max normalization to transfer the predictors, similar to the exercises of week 4.

<details class="answer_panel">
  <summary>Answer</summary>

```{r}
# KNN prediction
predict_knn = kNN( formula, train = train_set, test = test_set, transform = "minmax", k = 13 )
```  
  
</details>

## Model Evaluation

Based on your results so far, which of the four classification algorithms is more suitable here for the *churn* dataset based on:

* Confusion Matrix,
* MSE,
* ROC curve,
* AUC (Area Under the ROC curve).

<details>
  <summary>Answer</summary>

<h3>Confusion Matrix</h3>

```{r, fig.show="hold", out.width="50%", fig.width=12, fig.align="default"}
# Confusion matrix plotting for all 4 predictions
conf.mat.plot( predict_cart, actual_test, main = "CART Prediction")
conf.mat.plot( predict_C50, actual_test, main = "C5.0 Prediction" )
conf.mat.plot( predict_random_forest, actual_test, main = "Random Forest Prediction" )
conf.mat.plot( predict_knn, actual_test, main = "KNN Prediction" )
```

```{r}
# Confusion matrix metrics reports for all 4 predictions
confusionMatrix(data = predict_cart, reference = actual_test)
confusionMatrix(data = predict_C50, reference = actual_test)
confusionMatrix(data = predict_random_forest, reference = actual_test)
confusionMatrix(data = predict_knn, reference = actual_test)
```

<h3>MSE</h3>

```{r}
# MSE reporting for all 4 predictions
( mse_cart = mse( predict_cart, actual_test ) )
( mse_C50 = mse( predict_C50, actual_test ) )
( mse_random_forest = mse( predict_random_forest, actual_test ) )
( mse_knn = mse( predict_knn, actual_test ) )
```

<h3>ROC & AUC</h3>

```{r}
# predict model fitting
prob_cart = predict( tree_cart, test_set, type = "prob" )[ , 1 ]
prob_C50 = predict( tree_C50, test_set, type = "prob" )[ , 1 ]
prob_random_forest = predict( random_forest, test_set, type = "prob" )[ , 1 ]
prob_knn = kNN( formula, train = train_set, test = test_set, transform = "minmax", k = 13, type = "prob" )[ , 1 ]

# build ROC curves
roc_cart = roc( actual_test, prob_cart )
roc_C50 = roc( actual_test, prob_C50 )
roc_random_forest = roc( actual_test, prob_random_forest )
roc_knn = roc( actual_test, prob_knn )

# plot ROC Curves, and calculate AUCs
ggroc( list( roc_cart, roc_C50, roc_random_forest, roc_knn), size = 0.8 ) + 
    theme_minimal() + ggtitle( "ROC plots with AUC for 4 outcomes") +
  scale_color_manual( values = 1:5, 
    labels = c( paste( "CART; AUC=", round( auc( roc_cart ), 3 ) ), 
                paste( "C50; AUC=", round( auc( roc_C50 ), 3 ) ), 
                paste( "Random Forest; AUC=", round( auc( roc_random_forest ), 3 ) ),
                paste( "KNN; AUC=", round( auc( roc_knn ), 3 ) )) ) +
  theme( legend.title = element_blank() ) +
  theme( legend.position = c( .7, .3 ), text = element_text( size = 17 ) )
```

<h3>Conclusion</h3>

| | CART | C50 | Random Forest | KNN |
|:- | :-: | :-: | :-: | :-: |
| MSE | 0.0566 | 0.0595 | 0.0557 | 0.0898 |
| Accuracy | 0.9434 | 0.9404 | 0.9443 | 0.9102|
| Misspecification rate | 0.0566 | 0.0596 | 0.0557| 0.0898|
| Sensitivity | 0.6815 | 0.6815 | 0.7333 | 0.4222 |
| Specificity | 0.9831 | 0.9797 | 0.9763 | 0.9843 |
| AUC | 0.907 | 0.908 | 0.928 | 0.918 |

Based on the above summary, we can conclude the following:

* In terms of MSE, CART, C50, and the Random Forest algorithm produce similar MSE values. The KNN algorithm is approx 2-2.5% higher in prediciton error. Based on this single metrics, the least erroneous prediction is the optimal, that is the random forest.
* The most accurate algorithm, in terms of accuracy rate, is the random forest, and hence also the one with the smallest misspecification rate. CART and C50 produce similar accuracy and misspecification rate than the random forest, however, KNN is a bit less accurate, approximately 3% behind the competing models. Based on this single metrics, Random forest is the optimal algorithm to use.
* In terms of sensitivity, the random forest comes out as superior model by a good 5-6%, compared to the other models, hence this predictive model is the most preferred based on this single metrics.
* In terms of specificity all 4 models produce similar results, but KNN bears with the highest value. Therefore, by judging this single metrics, we would prefer to use KNN over the other algorithms.
* In terms of ROC and AUC, the random forest algorithm encloses the largest area under the curve.

In most metrics, the random forest came out as the most accurate in terms of predictability, however, we attach the highest weight in our model evaluation to the AUC value. This is because, AUC incorporates the specificity and sensitivity rate across multiple splits, and hence is deemed the best evaluation metrics out of the above. Therefore, the random forest is the most preferred algorithm to use for the churn dataset.

</details>

# **Bonus**: Applying the Decision Tree and Random Forest for your own dataset (30 points)

In this part, similar to the above sections, apply the following algorithms for your own dataset:

* *CART* algorithm,
* *C5.0* algorithm,
* *Random Forest* algorithm,
* *kNN* algorithm.

Check which of the above classification algorithms are more suitable for your dataset, by evaluating the accuracy of the predictions with:

* Confusion Matrix,
* MSE,
* ROC curve,
* AUC (Area Under the ROC curve).

You could consider to follow these steps:

1. Load your dataset in RStudio environment and select the predictors (See the slide of Week 1);
2. Partition the dataset for modeling and validate the partition (Similar to part 1.2);
3. Apply the *CART*, *C5.0*, *Random Forest*, *kNN* algorithms (Similar to parts 1.3, 1.4, and 1.5);
4. Evaluate the models by reporting *Confusion Matrix*, *MSE*, *ROC curve*, and the value of *AUC* (Similar to part 1.6).

*Note*: to apply the classification algorithms to your own dataset, the target variable has to be categorical, preferably Binary, similar to the above examples.
   