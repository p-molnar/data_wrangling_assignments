---
title: '<center> The Exercises of Week 5 - Decision Trees <center>'
author: '<center> Reza Mohammadi <center>'
date: '<center> `r Sys.Date()` <center>'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 5
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include = FALSE}
knitr::opts_chunk $ set( echo = TRUE, message = FALSE, warning = FALSE, 
                         comment = " ", error = FALSE, fig.align = 'center'  )
```

```{css, echo=FALSE}
.answer_panel { margin-left: 40px; }

.sub_details { margin-left: 60px; }
```

**Full Name:** 

* Peter Molnar (11759216)
   
**Online Assignment**: There is a new online-assignment at the [DataCamp](https://www.datacamp.com) with the name “*Chapter 4: Classification Trees*” which is a part of the online course “Supervised Learning in R: Classification” at the DataCamp. *The online-assignments at the DataCamp are not mandatory*.

**Your task** is to answer the following questions in *Part 1* and *Part 2* in this R-markdown file. Please upload both your R-markdown ( .Rmd file) and the HTML files separately on Canvas. 

# Who can earn more than 50K per year? (40 points)

We want to explore the Income Prediction problem associated with the Adult Income Census dataset which is available in the [**liver**](https://CRAN.R-project.org/package=liver) package as the *adult* dataset. The prediction task is to determine whether a person makes over $50K a year. For this classification task, we are going to apply the *Decision Tree* using the *CART* and *C5.0* algorithms as well as the *Random Forest* algorithm by using the following R packages:

* **rpart**: we use the `rpart()` function in this package for the *CART* algorithm.
* **rpart.plot**: we use the `rpart.plot()` function in this package to plotting a decision tree.
* **C50**: we use the `C5.0()` function in this package for the *C5.0* algorithm.
* **randomForest**: we use the `randomForest()` function in this package for the *Random Forest* algorithm.
* **liver**: the *adult* dataset is in this package. We also use the `partition()` function in this package.
* **pROC**: to create ROC curve with AUC, we use the `plot.roc()` function in this package.

If it’s needed, install these packages on your computer. Here we load them:

```{r}
library( rpart )         # For the "CART" algorithm
library( rpart.plot )    # To plot decision trees
library( C50 )           # For the "C5.0" algorithm
library( randomForest )  # For the "Random Forest" algorithm
library( liver )         # For the "adult" dataset & the "partition" function
library( pROC )          # For ROC plot using "plot.roc" function
library( ggplot2 )       # For ggroc plot
library( caret )
```

## Data Understanding

The *adult* dataset is from the [US Census Bureau](https://www.census.gov) with the primary task to predict whether a given adult makes more than $50K a year based on attributes such as education, hours of work per week, etc. The target feature is *income* with two levels "`<=50K`" and "`>50K`", and the remaining 14 variables are predictors.

We import the dataset and report the structure of the dataset:

```{r}
data( adult ) 

str( adult )
```

It shows the dataset contains `r nrow( adult )` records and `r ncol( adult )` variables/features. The dataset has `r ncol( adult ) - 1` predictors along with a target variable `income` as a binary variable with two levels "`<=50K`" and "`>50K`". The variables/features (columns) are:

* `age`: age in years (numerical).
* `workclass`: a factor with 6 levels (categorical-nominal). 
* `demogweight`: the demographics to describe a person (categorical-nominal).
* `education`: a factor with 16 levels (categorical-nominal).
* `education.num`: number of years of education (numerical-discrete).
* `marital.status`: a factor with 5 levels (categorical-nominal).
* `occupation`: a factor with 15 levels (categorical-nominal).
* `relationship`: a factor with 6 levels (categorical-nominal).
* `race`: a factor with 5 levels (categorical-nominal).
* `gender`: a factor with levels "Female","Male" (categorical-binary).
* `capital.gain`: capital gains  (numerical-discrete).
* `capital.loss`: capital losses  (numerical-discrete).
* `hours.per.week`: number of hours of work per week (numerical-discrete).
* `native.country`: a factor with 42 levels (categorical-nominal).
* `income`: yearly income as a factor with levels "`<=50K`" and "`>50K`" (categorical-binary).

You can find more information related to this dataset at:

[https://www.rdocumentation.org/packages/liver/versions/1.3/topics/adult](https://www.rdocumentation.org/packages/liver/versions/1.3/topics/adult)

## Data Preparation

We partition the *adult* dataset randomly into two groups as a train set (80%) and a test set (20%). Here, we use the `partition()` function from the *liver* package:

```{r}
set.seed( 6 )

data_sets = partition( data = adult, prob = c( 0.8, 0.2 ) )

train_set = data_sets $ part1
test_set  = data_sets $ part2

actual_test  = test_set $ income
```

Note that here we are using the `set.seed()` function to create reproducible results. 

## Decision tree using CART algorithm

Here, we want to classify whether or not a person’s income is less than $50K, based on the following set of predictor fields: 

`age`, `education.num`, `capital.gain`, `capital.loss`, `hours.per.week`, `marital.status`, `workclass`, `race`, and `gender`. 

So, we produce a decision tree based on the CART algorithm. Here, we use the `rpart()` function from the [**rpart**](https://CRAN.R-project.org/package=rpart) package:

```{r}
formula = income ~ age + education.num + capital.gain + capital.loss + 
                   hours.per.week + marital.status + workclass + race + gender

tree_cart = rpart( formula = formula, data = train_set, method = "class" )

print( tree_cart )
```

To plot the decision tree, we use the `rpart.plot()` function from the [**rpart.plot**](https://CRAN.R-project.org/package=rpart.plot) package:

```{r fig.height = 6, fig.width = 10}
rpart.plot( tree_cart, type = 4, extra = 104 )
```

Based on the output, answer the following questions: 

a. **What is the number of decision nodes? What is the number of leaves?** 

<details class="answer_panel">
  <summary>Answer</summary>

* Number of decision nodes: 6
* Number of decision leaves: 7

</details>

b. **Interpret the first leaf on the left (bottom left).**

<details class="answer_panel">
  <summary>Answer</summary>

The left most leaf represents 53% of the whoel dataset and classifies as low income with 96% accuracy, and 4% error rate. This subgroup is of unmarried, and has capital gain less than $7056.
  
</details>

c. **In general, how do you interpret the above decision tree?**

<details class="answer_panel">
  <summary>Answer</summary>

The above decision tree is constructed by the use of CART algorithm.

The following binary splits are made:

* The root node splits on `marital.status`, and 76% have income less than \$50K.
  * 53% of the whole dataset is of unmarried, and splits on `capital.gain`. 94% have income less than \$50k, while the rest 6% have income more than \$50k
    * 52% of the whole dataset is of unmarried with capital gain less than \$7056, and 95% have less than \$50k income, while the rest 5% have more than \$50k.
    * 1 % of the whole dataset is of unmarried with capital gain more than \$7056, and 97% of them have more than \$50K income, while the rest 3% have less than \$50K
  * 47% of the whole dataset is of married, and splits on `education.num`. 57% have income less than \$50K and 43% have income more than \$50K
    * 33% of the whole dataset have less than 13 years of education, and splits on `capital.gain`. 68% have less than $50K, and 32% have more than \$50K
      * 32% of the whole dataset has `capital.gain` less than $5096 and splits on `education.num`. 71% of them have \$50K income while the rest 29% have more than \$50K.
        * 6% of the whole dataset have years in education less than 9 years, and 90% of them earn less than \$50K per year, while the rest 10% earn more than \$50k.
        * 26% of the whole dataset spent more than 9 years in education and splits on `capital.loss`. 67% of them earn less than \$50K and the rest 33% earn more than that.
          * 25% of the whole dataset suffered less than \$1821 of capital loss. 60% of them earns less than \$50K a year, while the rest 31% earns more than that. 
          * 1% of the whole dataset lost registered \$1821 as capital loss. 75% of them makes more than \$50K a year, while the rest 25% makes less than that.
    * 2% of the whole dataset has capital gains over $5096. 2% of them have income less than \$50K income while the rest, 98% have income more than \$50k income.
    * 14% of the whole dataset have years in education more than 13 years. 30% of them, have less than \$50K of income and the rest 70% has more than \$50k
    

</details>

## Decision tree using C5.0 algorithm

By using the C5.0 algorithm, we want to classify whether or not a person’s income is less than $50K. Here, first, for simplicity, we use only two predictors: `marital.status` and `education.num`. We produce a decision tree based on the C5.0 algorithm by using the `C5.0()` function from the [**C50**](https://CRAN.R-project.org/package=C50) package:

```{r}
tree_C50_small = C5.0( income ~ marital.status + education.num, data = train_set ) 

plot( tree_C50_small )
```

Based on the output, answer the below questions:

**What is the number of decision nodes? What is the number of leaves?**

<details class="answer_panel">
  <summary>Answer</summary>
* Number of decision nodes: 2
* Number of leaves: 3
  
</details>

**Interpret the first leaf on the right (bottom right).**

<details class="answer_panel">
  <summary>Answer</summary>
* 5306 observations belong to the `married` group with at least 13 years of education, out of which 70% makes more than \$50K while the rest 30% makes less than that.
  
</details>

**In general, how do you interpret the above decision tree?**

<details class="answer_panel">
  <summary>Answer</summary>

* The root node splits on `marital.status`. 20543 observations are of unmarried, out of which approximately 95% makes less than \$50K a year, while the rest 5% makes more than that.

* Those of married splits on `education.num`. 12933 observations spent maximum 12 years in education, out of which 70% makes less than \$50k a year, while the rest 30% makes more than that.

* 5306 observations spent at least 13 years of education, out of which 70% makes more than \$50K while the rest 30% makes less than that.
  
  
</details>

## Random Forest

*CART* and *C5.0* algorithms both produce a single decision tree based on all of the records, and the specified variables, in the training data set. On the other hand, *random forest* algorithm builds a series of decision trees and combine the trees disparate classifications of each record into one final classification. 

Here, we want to classify whether or not a person’s income is less than $50K, based on the following set of predictor fields: `age`, `education.num`, `capital.gain`, `capital.loss`, `hours.per.week`, `marital.status`, `workclass`, `race`, and `gender`. By considering these set of predictors, we run the *random forest* algorithm, using the `randomForest()` function from the [**randomForest**](https://CRAN.R-project.org/package=randomForest) package:

```{r}
random_forest = randomForest( formula = formula, data = train_set, ntree = 10 )
```

We can visualize the dot-chart of variable importance as measured by the *random forest* algorithm as follow

```{r}
varImpPlot( random_forest )
```

```{r  fig.height = 3, fig.width = 3}
predict_random_forest = predict( random_forest, test_set )

conf.mat( predict_random_forest, actual_test )

conf.mat.plot( predict_random_forest, actual_test, main = "Random Forest" )

mse( predict_random_forest, actual_test )
```

Based on the output, answer the following questions: 

**You see that in the `randomForest()` function we set the number of trees to 10 (`ntree = 10`). Change this value to 100 and run the code for this case (`ntree = 100`). Explain what conclusion you will draw.**

<details>
  <summary>Answer</summary>

* There are 2 possible predicted classes: “<=50K” and “>50K”
* “<=50K” meaning that the model predicted that the person earns maximum of $50.000 annually.
* “>50K” meaning that the model predicted that the person earns more than$50.000 annually.
* In total the classifier made 9816 predictions


<h3>n=10</h3>

The classifier

* predicted “<=50K” for 8008 people, out of which 7064 was correctly predicted, while 944 was incorrectly.
* predicted “>50K” for 1808 people, out of which 1377 was correctly predicted, and 431 was incorrectly.
* Out of the 9816 predictions, the model correctly predicted the outcome 7064 + 1377 = 8441 times.
* Out of the 9816 predictions, the model incorrectly predicted the outcome 944 + 431 = 1375 times

```{r}
confusionMatrix(data = predict_random_forest, reference = actual_test)
```

We identify the following:

* **Accuracy:** overall the classifier is correct 85.84% of the time
* **Misclassification rate:** overall the classifier is incorrect 14.16% of the time
* **Sensitivity:** the model correctly classifies positive records 93.97% of the time
* **Specificity:** the model correctly classifies negative records 59.59% of the time

<h3>n=100</h3>

```{r}
random_forest_100 = randomForest( formula = formula, data = train_set, ntree = 100 )
varImpPlot( random_forest_100 )
predict_random_forest_100 = predict( random_forest_100, test_set )
```

```{r fig.height = 3, fig.width = 3}
conf.mat( predict_random_forest_100, actual_test )

conf.mat.plot( predict_random_forest_100, actual_test, main = "Random Forest" )

mse( predict_random_forest_100, actual_test )
```

The classifier

* predicted “<=50K” for 8002 people, out of which 7060 was correctly predicted, while 942 was incorrectly.
* predicted “>50K” for 1814 people, out of which 1379 was correctly predicted, and 435 was incorrectly.
* Out of the 9816 predictions, the model correctly predicted the outcome 7060 + 942 = 8002 times.
* Out of the 9816 predictions, the model incorrectly predicted the outcome 944 + 431 = 1814 times


```{r}
confusionMatrix(data = predict_random_forest_100, reference = actual_test)
```

* **Accuracy:** overall the classifier is correct 85.97% of the time
* **Misclassification rate:** overall the classifier is incorrect 14.03% of the time
* **Sensitivity:** the model correctly classifies positive records 94.20% of the time
* **Specificity:** the model correctly classifies negative records 59.41% of the time


<h3>Conclusion</h3>

| | n=10 | n=100 |
| :- | :-: | :-: |
|MSE | 0.1416 | 0.1402 |
|Accuracy |85.84% | 85.97%|
|Misclassification rate | 14.16% | 14.03% |
|Sensitivity |93.97% | 94.20% |
|Specificity |59.59% | 59.41% |

Based on the above summary we can conclude the following:

* The random forest with n=10 bears with slightly higher error rate, than the model with n=100. Between competing models, the one with lower error rate is preferred, that is, n=100.
* The accuracy rate of the model with n=10 is again slightly lower than that of n=100. Given, then that the misspecification rate is the complement of accuracy, the model with n=10 has a higher misspecification rate. The higher accuracy and lower misspecification is preferred, therefore, the model with n=100.
* The model with n=10 has lower sensitivity than that of n=100. That is, the former model predicts the positive records less than its competitor model, n=100. Hence, the latter is preferred.
* In terms of specificity, the model with n=10 performs better, however, the margin is very little, i.e., small enough and insignificant to still prefer the model with n=100, since it outcompeted in the rest of the metrics.


In conclusion, the model with n=100 shows a slightly better predictability than the model with n=10. Since the margin is so little, that it may still be preferred to use n=10, so that n=100 would not come at the cost of computational complexity.

</details>



## Model Evaluation

So far we've applied three different classification algorithms (*CART*, *C5.0*, and *random forest*) for the *adult* dataset. Now, you may ask "well, which one is more suable for this dataset?". In another word, which model has more accuracy? To answer this question, we evaluate the performance of the decision trees in parts 1.4, 1.5, and 1.6. Basically, by using the training dataset, we want to estimate (predict) whether or not a person’s *income* in the test set is less (higher) than $50K. We evaluate the accuracy of the predictions by reporting:

* Confusion Matrix,
* MSE,
* ROC curve,
* AUC (Area Under the ROC curve).

* We run the **CART algorithm**, using the same *formula* input as before:

```{r fig.height = 3, fig.width = 3}
formula = income ~ age + education.num + capital.gain + capital.loss + 
                   hours.per.week + marital.status + workclass + race + gender

tree_cart = rpart( formula = formula, data = train_set, method = "class" )

predict_cart = predict( tree_cart, test_set, type = "class" )

conf.mat( predict_cart, actual_test )
conf.mat.plot( predict_cart, actual_test )

( mse_cart = mse( predict_cart, actual_test ) )
```

* We run the **C5.0 algorithm**, using the same *formula* input as before:

```{r fig.height=3, fig.width=3}
tree_C50 = C5.0( formula = formula, data = train_set, type = "class" ) 

predict_C50 = predict( tree_C50, test_set, type = "class" )

conf.mat( predict_C50, actual_test )
conf.mat.plot( predict_C50, actual_test )

( mse_C50 = mse( predict_C50, actual_test ) )
```

* We run the **random forest**, using the same *formula* input as before:

```{r fig.height=3, fig.width=3}
random_forest = randomForest( formula = formula, data = train_set, ntree = 100 )

predict_random_forest = predict( random_forest, test_set )

conf.mat( predict_random_forest, actual_test )
conf.mat.plot( predict_random_forest, actual_test )

( mse_random_forest = mse( actual_test, predict_random_forest ) )
```

Here we report the ROC curves as well as AUC for the above classification algorithm as follows:

```{r}
prob_cart = predict( tree_cart, test_set, type = "prob" )[ , 1 ]
prob_C50 = predict( tree_C50, test_set, type = "prob" )[ , 1 ]
prob_random_forest = predict( random_forest, test_set, type = "prob" )[ , 1 ]

roc_cart = roc( actual_test, prob_cart )
roc_C50 = roc( actual_test, prob_C50 )
roc_random_forest = roc( actual_test, prob_random_forest )

ggroc( list( roc_cart, roc_C50, roc_random_forest ), size = 0.8 ) + 
    theme_minimal() + ggtitle( "ROC plots with AUC for 3 outcomes") +
  scale_color_manual( values = 1:3, 
    labels = c( paste( "CART; AUC=", round( auc( roc_cart ), 3 ) ), 
                paste( "C50; AUC=", round( auc( roc_C50 ), 3 ) ), 
                paste( "Random Forest; AUC=", round( auc( roc_random_forest ), 3 ) ) ) ) +
  theme( legend.title = element_blank() ) +
  theme( legend.position = c( .7, .3 ), text = element_text( size = 17 ) )
```

In the above plot **black** curve is for CART algorithm, <span style="color:red">**red**</span> curve is for C50 algorithm, and <span style="color:green">**green**</span> curve is for random forest algorithm. 

**Based on the result of above four model evaluaiton reports (Confusion Matrix, MSE, ROC cuve, and UCA), what conclusion you will draw.**


<details>
  <summary>Answer</summary>

In order to compare the competing models, we run the following code to report the accuracy, misclassification rate, sensitivity and specificity.

```{r}
confusionMatrix(data = predict_random_forest, reference = actual_test)
confusionMatrix(data = predict_cart, reference = actual_test)
confusionMatrix(data = predict_C50, reference = actual_test)
```

| | CART | C50 | Random Forest| 
| :- | :-: | :-: | :-:|
|MSE | 0.1519 | 0.1391 |0.1390|
|Accuracy |0.8481 | 0.8609 |0.8609 |
|Misclassification rate | 0.1519 | 0.1391 | 0.1391 |
|Sensitivity | 0.9428 | 0.9429  |0.9454 | 
|Specificity |0.5424 | 0.5963  | 0.5881 |
|AUC | 0.8550 | 0.8950 | 0.8800|

Based on the above summary we can conclude the following:

* Random forest has the lowest Mean Squared Error, that is, it bears with the lower error on average
* C50 and the random forest has the same level accuracy, they are preferred over CART. The conclusion is the same for the misspecification rate.
* The random forest algorithm has the highest rate of sensitivity, it is preferred over others
* the C50 algorithm has the highest specificity rate, it is preferred over other
* C50 has the highest AUC, therefore it is deemed to be a superior model to others.


In conclusion, the C50 algorithm is the preferred model.
  

</details>

# Decision Tree analysis for churn dataset (60 points)

We want to apply the decision tree analysis to the [*churn*](https://rdrr.io/cran/liver/man/churn.html) dataset that is available in the **R** package [**liver**](https://CRAN.R-project.org/package=liver). We want to classify whether or not a customer leaving the service of one company in favor of another company. Use the code from the questions in Part 2.

The *churn* dataset has 19 predictors but we are not going to use all of the predictors. We know based on the lecture of week 2, we should use only the predictors that have a relationship with the target variable. So, here we use the following predictors:

`account.length`, `voice.plan`, `voice.messages`, `intl.plan`, `intl.mins`, `day.mins`, `eve.mins`, `night.mins`, and `customer.calls`.

For this classification task, we want to apply the following algorithms:

* *CART* algorithm,
* *C5.0* algorithm,
* *Random Forest* algorithm,
* *kNN* algorithm.

Ultimately, **we want to see which of the above classification algorithms are more suitable here**, by evaluating the accuracy of the predictions with:

* Confusion Matrix,
* MSE,
* ROC curve,
* AUC (Area Under the ROC curve).

## Data Preparation

After importing the *churn* dataset in R, partition the *churn* dataset randomly into two groups as a train set (80%) and a test set (20%). Here, for the partition, you could use the `partition()` function from the *liver* package. You should use the `set.seed()` function in R; similar to the data preparation in section 1 for adult dataset.

## Applying Decision Tree algorithms

For the classification task, by using the training dataset, run the following algorithms:

* *CART algorithm* using the `rpart()` function in the **rpart** R package and plot the decision tree using the `rpart.plot()` function in the **rpart.plot** R package; Similar to part 1.3.

* *C5.0 algorithm* using the `C5.0()` function in the R package **C50**; Similar to part 1.4.

* *Random Forest* using the `randomForest()` function from the R package **randomForest**; Similar to part 1.5.

Based on the training dataset and the above models predict for the test set. For the prediction, you could use the `predict()` function; Similar to part 1.6.

## Applying kNN algorithm

Find the k-nearest neighbor for the test set, based on the training dataset, for the case k = 13. For the kNN algorithm, use min-max normalization to transfer the predictors, similar to the exercises of week 4.

## Model Evaluation

Based on your results so far, which of the four classification algorithms is more suitable here for the *churn* dataset based on:

* Confusion Matrix,
* MSE,
* ROC curve,
* AUC (Area Under the ROC curve).

# **Bonus**: Applying the Decision Tree and Random Forest for your own dataset (30 points)

In this part, similar to the above sections, apply the following algorithms for your own dataset:

* *CART* algorithm,
* *C5.0* algorithm,
* *Random Forest* algorithm,
* *kNN* algorithm.

Check which of the above classification algorithms are more suitable for your dataset, by evaluating the accuracy of the predictions with:

* Confusion Matrix,
* MSE,
* ROC curve,
* AUC (Area Under the ROC curve).

You could consider to follow these steps:

1. Load your dataset in RStudio environment and select the predictors (See the slide of Week 1);
2. Partition the dataset for modeling and validate the partition (Similar to part 1.2);
3. Apply the *CART*, *C5.0*, *Random Forest*, *kNN* algorithms (Similar to parts 1.3, 1.4, and 1.5);
4. Evaluate the models by reporting *Confusion Matrix*, *MSE*, *ROC curve*, and the value of *AUC* (Similar to part 1.6).

*Note*: to apply the classification algorithms to your own dataset, the target variable has to be categorical, preferably Binary, similar to the above examples.
   